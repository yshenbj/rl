{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import random\n",
    "from collections import defaultdict\n",
    "from rendering_utils import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model-based vs Model-free"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model-based reinforcement learning need to **know the model**; in particular, we have access to $P_a(s' \\mid s)$ and $r(s,a,s')$.\n",
    "\n",
    "While in model-free reinforcement learning, we don't know the transitions and the rewards?!* We **learn through experience** by trying actions and seeing what the results is, making this machine learning problem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MDP:\n",
    "    \"\"\"Return all states of this MDP\"\"\"\n",
    "\n",
    "    def get_states(self):\n",
    "        pass\n",
    "\n",
    "    \"\"\" Return all actions with non-zero probability from this state \"\"\"\n",
    "\n",
    "    def get_actions(self, state):\n",
    "        pass\n",
    "\n",
    "    \"\"\" Return all non-zero probability transitions for this action\n",
    "        from this state, as a list of (state, probability) pairs\n",
    "    \"\"\"\n",
    "\n",
    "    def get_transitions(self, state, action):\n",
    "        pass\n",
    "\n",
    "    \"\"\" Return the reward for transitioning from state to\n",
    "        nextState via action\n",
    "    \"\"\"\n",
    "\n",
    "    def get_reward(self, state, action, next_state):\n",
    "        pass\n",
    "\n",
    "    \"\"\" Return true if and only if state is a terminal state of this MDP \"\"\"\n",
    "\n",
    "    def is_terminal(self, state):\n",
    "        pass\n",
    "\n",
    "    \"\"\" Return the discount factor for this MDP \"\"\"\n",
    "\n",
    "    def get_discount_factor(self):\n",
    "        pass\n",
    "\n",
    "    \"\"\" Return the initial state of this MDP \"\"\"\n",
    "\n",
    "    def get_initial_state(self):\n",
    "        pass\n",
    "\n",
    "    \"\"\" Return all goal states of this MDP \"\"\"\n",
    "\n",
    "    def get_goal_states(self):\n",
    "        pass\n",
    "\n",
    "    \"\"\" Return a new state and a reward for executing action in state,\n",
    "    based on the underlying probability. This can be used for\n",
    "    model-free learning methods, but requires a model to operate.\n",
    "    Override for simulation-based learning\n",
    "    \"\"\"\n",
    "\n",
    "    def execute(self, state, action):\n",
    "        rand = random.random()\n",
    "        cumulative_probability = 0.0\n",
    "        for (new_state, probability) in self.get_transitions(state, action):\n",
    "            if cumulative_probability <= rand <= probability + cumulative_probability:\n",
    "                reward = self.get_reward(state, action, new_state)\n",
    "                return (new_state, reward, self.is_terminal(new_state))\n",
    "            cumulative_probability += probability\n",
    "            if cumulative_probability >= 1.0:\n",
    "                raise (\n",
    "                    \"Cumulative probability >= 1.0 for action \"\n",
    "                    + str(action)\n",
    "                    + \" from \"\n",
    "                    + str(state)\n",
    "                )\n",
    "\n",
    "        raise BaseException(\n",
    "            \"No outcome state in simulation for action \"\n",
    "            + str(action)\n",
    "            + \" from \"\n",
    "            + str(state)\n",
    "        )\n",
    "\n",
    "    \"\"\" \n",
    "    Execute a policy on this mdp for a number of episodes.\n",
    "    \"\"\"\n",
    "\n",
    "    def execute_policy(self, policy, episodes=100, max_step=100):\n",
    "        cumulative_rewards = []\n",
    "        states = set()\n",
    "        for _ in range(episodes):\n",
    "            cumulative_reward = 0.0\n",
    "            state = self.get_initial_state()\n",
    "            step = 0\n",
    "            while not self.is_terminal(state):\n",
    "                actions = self.get_actions(state)\n",
    "                action = policy.select_action(state, actions)\n",
    "                (next_state, reward, done) = self.execute(state, action)\n",
    "                cumulative_reward += reward * (self.discount_factor ** step)\n",
    "                state = next_state\n",
    "                step += 1\n",
    "                if step > max_step:\n",
    "                    break\n",
    "            cumulative_rewards += [cumulative_reward]\n",
    "        return cumulative_rewards"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class QFunction:\n",
    "\n",
    "    \"\"\" Update the Q-value of (state, action) by delta \"\"\"\n",
    "\n",
    "    def update(self, state, action, delta):\n",
    "        pass\n",
    "\n",
    "    \"\"\" Get a Q value for a given state-action pair \"\"\"\n",
    "\n",
    "    def get_q_value(self, state, action):\n",
    "        pass\n",
    "\n",
    "    \"\"\" Save a policy to a specified filename \"\"\"\n",
    "    def save_policy(self, filename):\n",
    "        pass\n",
    "\n",
    "    \"\"\" Load a policy from a specified filename \"\"\"\n",
    "    def load_policy(self, filename):\n",
    "        pass\n",
    "\n",
    "    \"\"\" Return the action with the maximum Q-value \"\"\"\n",
    "    def get_argmax_q(self, state, actions):\n",
    "        (argmax_q, max_q) = self.get_max_pair(state, actions)\n",
    "        return argmax_q\n",
    "\n",
    "    \"\"\" Return the maximum Q-value in this Q-function \"\"\"\n",
    "    def get_max_q(self, state, actions):\n",
    "        (argmax_q, max_q) = self.get_max_pair(state, actions)\n",
    "        return max_q\n",
    "\n",
    "    \"\"\" Return a pair containing the action and Q-value, where the\n",
    "        action has the maximum Q-value in state\n",
    "    \"\"\"\n",
    "    def get_max_pair(self, state, actions):\n",
    "        arg_max_q = None\n",
    "        max_q = float(\"-inf\")\n",
    "        for action in actions:\n",
    "            value = self.get_q_value(state, action)\n",
    "            if max_q < value:\n",
    "                arg_max_q = action\n",
    "                max_q = value\n",
    "        return (arg_max_q, max_q)\n",
    "\n",
    "\n",
    "class QTable(QFunction):\n",
    "    def __init__(self, alpha=0.1, default_q_value=0.0):\n",
    "        self.qtable = defaultdict(lambda: default_q_value)\n",
    "        self.alpha = alpha\n",
    "\n",
    "    def update(self, state, action, delta):\n",
    "        self.qtable[(state, action)] = self.qtable[(state, action)] + self.alpha * delta\n",
    "\n",
    "    def get_q_value(self, state, action):\n",
    "        return self.qtable[(state, action)]\n",
    "\n",
    "    def save(self, filename):\n",
    "        with open(filename, \"w\") as file:\n",
    "            serialised = {str(key): value for key, value in self.qtable.items()}\n",
    "            json.dump(serialised, file)\n",
    "\n",
    "    def load(self, filename, default=0.0):\n",
    "        with open(filename, \"r\") as file:\n",
    "            serialised = json.load(file)\n",
    "            self.qtable = defaultdict(\n",
    "                lambda: default,\n",
    "                {tuple(eval(key)): value for key, value in serialised.items()},\n",
    "            )\n",
    "\n",
    "\n",
    "class Policy:\n",
    "    def select_action(self, state, action):\n",
    "        abstract\n",
    "\n",
    "\n",
    "class DeterministicPolicy(Policy):\n",
    "    def update(self, state, action):\n",
    "        pass\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiArmedBandit():\n",
    "\n",
    "    \"\"\" Select an action for this state given from a list given a Q-function \"\"\"\n",
    "\n",
    "    def select(self, state, actions, qfunction):\n",
    "        pass\n",
    "\n",
    "    \"\"\" Reset a multi-armed bandit to its initial configuration \"\"\"\n",
    "\n",
    "    def reset(self):\n",
    "        self.__init__()\n",
    "\n",
    "\n",
    "class EpsilonGreedy(MultiArmedBandit):\n",
    "    def __init__(self, epsilon=0.1):\n",
    "        self.epsilon = epsilon\n",
    "\n",
    "    def reset(self):\n",
    "        pass\n",
    "\n",
    "    def select(self, state, actions, qfunction):\n",
    "        # Select a random action with epsilon probability\n",
    "        if random.random() < self.epsilon:\n",
    "            return random.choice(actions)\n",
    "        arg_max_q = qfunction.get_argmax_q(state, actions)\n",
    "        return arg_max_q"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q-learning: Off-policy Temporal-difference Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ModelFreeLearner:\n",
    "    def execute(self, eposodes=2000):\n",
    "        pass\n",
    "\n",
    "\n",
    "class TemporalDifferenceLearner(ModelFreeLearner):\n",
    "    def __init__(self, mdp, bandit, qfunction):\n",
    "        self.mdp = mdp\n",
    "        self.bandit = bandit\n",
    "        self.qfunction = qfunction\n",
    "\n",
    "    def execute(self, episodes=2000):\n",
    "\n",
    "        rewards = []\n",
    "        for episode in range(episodes):\n",
    "            state = self.mdp.get_initial_state()\n",
    "            actions = self.mdp.get_actions(state)\n",
    "            action = self.bandit.select(state, actions, self.qfunction)\n",
    "\n",
    "            episode_reward = 0.0\n",
    "            step = 0\n",
    "            while not self.mdp.is_terminal(state):\n",
    "                (next_state, reward, done) = self.mdp.execute(state, action)\n",
    "                actions = self.mdp.get_actions(next_state)\n",
    "                next_action = self.bandit.select(next_state, actions, self.qfunction)\n",
    "\n",
    "                delta = self.get_delta(reward, state, action, next_state, next_action)\n",
    "                self.qfunction.update(state, action, delta)\n",
    "                \n",
    "                state = next_state\n",
    "                action = next_action\n",
    "                episode_reward += reward * (self.mdp.discount_factor ** step)\n",
    "                step += 1\n",
    "            \n",
    "            rewards.append(episode_reward)\n",
    "\n",
    "        return rewards\n",
    "    \n",
    "    \"\"\" Calculate the delta for the update \"\"\"\n",
    "\n",
    "    def get_delta(self, reward, state, action, next_state, next_action):\n",
    "        q_value = self.qfunction.get_q_value(state, action)\n",
    "        next_state_value = self.state_value(next_state, next_action)\n",
    "        delta = reward + self.mdp.discount_factor * next_state_value - q_value\n",
    "        return delta\n",
    "    \n",
    "    \"\"\" Get the value of a state \"\"\"\n",
    "    \n",
    "    def state_value(self, state, action):\n",
    "        pass\n",
    "\n",
    "\n",
    "class QLearning(TemporalDifferenceLearner):\n",
    "    def state_value(self, state, action):\n",
    "        max_q_value = self.qfunction.get_max_q(state, self.mdp.get_actions(state))\n",
    "        return max_q_value"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### GridWorld Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GridWorld(MDP):\n",
    "    # labels for terminate action and terminal state\n",
    "    TERMINAL = (-1, -1)\n",
    "    TERMINATE = 0\n",
    "    LEFT = 1\n",
    "    UP = 2\n",
    "    RIGHT = 3\n",
    "    DOWN = 4\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        noise=0.1,\n",
    "        width=4,\n",
    "        height=3,\n",
    "        discount_factor=0.9,\n",
    "        blocked_states=[(1, 1)],\n",
    "        action_cost=0.0,\n",
    "        initial_state=(0, 0),\n",
    "        goals=None,\n",
    "    ):\n",
    "        self.noise = noise\n",
    "        self.width = width\n",
    "        self.height = height\n",
    "        self.blocked_states = blocked_states\n",
    "        self.discount_factor = discount_factor\n",
    "        self.action_cost = action_cost\n",
    "        self.initial_state = initial_state\n",
    "        if goals is None:\n",
    "            self.goal_states = dict(\n",
    "                [((width - 1, height - 1), 1), ((width - 1, height - 2), -1)]\n",
    "            )\n",
    "        else:\n",
    "            self.goal_states = dict(goals)\n",
    "\n",
    "        # A list of lists that records all rewards given at each step\n",
    "        # for each episode of a simulated gridworld\n",
    "        self.rewards = []\n",
    "\n",
    "        # A list of cumulative rewards for each episode\n",
    "        self.cumulative_rewards = []\n",
    "    \n",
    "        # The rewards for the current episode\n",
    "        self.episode_rewards = []\n",
    "\n",
    "\n",
    "    def get_states(self):\n",
    "        states = [self.TERMINAL]\n",
    "        for x in range(self.width):\n",
    "            for y in range(self.height):\n",
    "                if not (x, y) in self.blocked_states:\n",
    "                    states.append((x, y))\n",
    "        return states\n",
    "\n",
    "    def get_actions(self, state=None):\n",
    "\n",
    "        actions = [self.TERMINATE, self.LEFT, self.UP, self.RIGHT, self.DOWN]\n",
    "        if state is None:\n",
    "            return actions\n",
    "\n",
    "        valid_actions = []\n",
    "        for action in actions:\n",
    "            for (new_state, probability) in self.get_transitions(state, action):\n",
    "                if probability > 0:\n",
    "                    valid_actions.append(action)\n",
    "                    break\n",
    "        return valid_actions\n",
    "\n",
    "    def get_initial_state(self):\n",
    "        self.episode_rewards = []\n",
    "        return self.initial_state\n",
    "\n",
    "    def get_goal_states(self):\n",
    "        return self.goal_states\n",
    "\n",
    "    def valid_add(self, state, new_state, probability):\n",
    "        # If the next state is blocked, stay in the same state\n",
    "        if probability == 0.0:\n",
    "            return []\n",
    "\n",
    "        if new_state in self.blocked_states:\n",
    "            return [(state, probability)]\n",
    "\n",
    "        # Move to the next space if it is not off the grid\n",
    "        (x, y) = new_state\n",
    "        if x >= 0 and x < self.width and y >= 0 and y < self.height:\n",
    "            return [((x, y), probability)]\n",
    "\n",
    "        # If off the grid, state in the same state\n",
    "        return [(state, probability)]\n",
    "\n",
    "    def get_transitions(self, state, action):\n",
    "        transitions = []\n",
    "\n",
    "        if state == self.TERMINAL:\n",
    "            if action == self.TERMINATE:\n",
    "                return [(self.TERMINAL, 1.0)]\n",
    "            else:\n",
    "                return []\n",
    "\n",
    "        # Probability of not slipping left or right\n",
    "        straight = 1 - (2 * self.noise)\n",
    "\n",
    "        (x, y) = state\n",
    "        if state in self.get_goal_states().keys():\n",
    "            if action == self.TERMINATE:\n",
    "                transitions += [(self.TERMINAL, 1.0)]\n",
    "\n",
    "        elif action == self.UP:\n",
    "            transitions += self.valid_add(state, (x, y + 1), straight)\n",
    "            transitions += self.valid_add(state, (x - 1, y), self.noise)\n",
    "            transitions += self.valid_add(state, (x + 1, y), self.noise)\n",
    "\n",
    "        elif action == self.DOWN:\n",
    "            transitions += self.valid_add(state, (x, y - 1), straight)\n",
    "            transitions += self.valid_add(state, (x - 1, y), self.noise)\n",
    "            transitions += self.valid_add(state, (x + 1, y), self.noise)\n",
    "\n",
    "        elif action == self.RIGHT:\n",
    "            transitions += self.valid_add(state, (x + 1, y), straight)\n",
    "            transitions += self.valid_add(state, (x, y - 1), self.noise)\n",
    "            transitions += self.valid_add(state, (x, y + 1), self.noise)\n",
    "\n",
    "        elif action == self.LEFT:\n",
    "            transitions += self.valid_add(state, (x - 1, y), straight)\n",
    "            transitions += self.valid_add(state, (x, y - 1), self.noise)\n",
    "            transitions += self.valid_add(state, (x, y + 1), self.noise)\n",
    "\n",
    "        # Merge any duplicate outcomes\n",
    "        merged = defaultdict(lambda: 0.0)\n",
    "        for (state, probability) in transitions:\n",
    "            merged[state] = merged[state] + probability\n",
    "\n",
    "        transitions = []\n",
    "        for outcome in merged.keys():\n",
    "            transitions += [(outcome, merged[outcome])]\n",
    "\n",
    "        return transitions\n",
    "\n",
    "    def get_reward(self, state, action, new_state):\n",
    "        reward = 0.0\n",
    "        if state in self.get_goal_states().keys() and new_state == self.TERMINAL:\n",
    "            reward = self.get_goal_states().get(state)\n",
    "        else:\n",
    "            reward = self.action_cost\n",
    "        step = len(self.episode_rewards)\n",
    "        self.episode_rewards += [reward * (self.discount_factor ** step)]\n",
    "        return reward\n",
    "\n",
    "    def get_discount_factor(self):\n",
    "        return self.discount_factor\n",
    "\n",
    "    def is_terminal(self, state):\n",
    "        if state == self.TERMINAL:\n",
    "            return True\n",
    "        return False\n",
    "\n",
    "    \"\"\"\n",
    "        Returns a list of lists, which records all rewards given at each step\n",
    "        for each episode of a simulated gridworld\n",
    "    \"\"\"\n",
    "\n",
    "    def get_rewards(self):\n",
    "        return self.rewards\n",
    "    \n",
    "\n",
    "    \"\"\"\n",
    "        Returns a list of all cumulative rewards\n",
    "        for each episode of a simulated gridworld\n",
    "    \"\"\"\n",
    "\n",
    "    def get_cumulative_rewards(self):\n",
    "        return self.cumulative_rewards\n",
    "\n",
    "    \"\"\"\n",
    "        Create a gridworld from an array of strings: one for each line\n",
    "        - First line is rewards as a dictionary from cell to value: {'A': 1, ...}\n",
    "        - space is an empty cell\n",
    "        - # is a blocked cell\n",
    "        - @ is the agent (initial state)\n",
    "        - new 'line' is a new row\n",
    "        - a letter is a cell with a reward for transitioning\n",
    "          into that cell. The reward defined by the first line.\n",
    "    \"\"\"\n",
    "\n",
    "    @staticmethod\n",
    "    def create(string):\n",
    "        # Parse the reward on the first line\n",
    "        import ast\n",
    "\n",
    "        rewards = ast.literal_eval(string[0])\n",
    "\n",
    "        width = 0\n",
    "        height = len(string) - 1\n",
    "\n",
    "        blocked_cells = []\n",
    "        initial_state = (0, 0)\n",
    "        goals = []\n",
    "        row = 0\n",
    "        for next_row in string[1:]:\n",
    "            column = 0\n",
    "            for cell in next_row:\n",
    "                if cell == \"#\":\n",
    "                    blocked_cells += [(column, row)]\n",
    "                elif cell == \"@\":\n",
    "                    initial_state = (column, row)\n",
    "                elif cell.isalpha():\n",
    "                    goals += [((column, row), rewards[cell])]\n",
    "                column += 1\n",
    "            width = max(width, column)\n",
    "            row += 1\n",
    "        return GridWorld(\n",
    "            width=width,\n",
    "            height=height,\n",
    "            blocked_states=blocked_cells,\n",
    "            initial_state=initial_state,\n",
    "            goals=goals,\n",
    "        )\n",
    "\n",
    "    @staticmethod\n",
    "    def open(file):\n",
    "        file = open(file, \"r\")\n",
    "        string = file.read().splitlines()\n",
    "        file.close()\n",
    "        return GridWorld.create(string)\n",
    "\n",
    "    @staticmethod\n",
    "    def matplotlib_installed():\n",
    "        try:\n",
    "            import matplotlib as mpl\n",
    "            import matplotlib.pyplot as plt\n",
    "            return True\n",
    "        except ModuleNotFoundError:\n",
    "            return False\n",
    "\n",
    "    \"\"\" Visualise a Grid World problem \"\"\"\n",
    "\n",
    "    def visualise(self, agent_position=None, title=\"\", grid_size=1.0, gif=False):\n",
    "        if self.matplotlib_installed():\n",
    "            return self.visualise_as_image(agent_position=agent_position, title=title, grid_size=grid_size, gif=gif)\n",
    "        else:\n",
    "            print(self.to_string(title=title))\n",
    "\n",
    "    \"\"\" Visualise a Grid World value function \"\"\"\n",
    "    def visualise_value_function(self, value_function, title=\"\", grid_size=1.0, gif=False):\n",
    "        if self.matplotlib_installed():\n",
    "            return self.visualise_value_function_as_image(value_function, title=title, grid_size=grid_size, gif=gif)\n",
    "        else:\n",
    "            print(self.value_function_to_string(value_function, title=title))\n",
    "\n",
    "    def visualise_q_function(self, qfunction, title=\"\", grid_size=1.5, gif=False):\n",
    "        if self.matplotlib_installed():\n",
    "            return self.visualise_q_function_as_image(qfunction, title=title, grid_size=grid_size, gif=gif)\n",
    "        else:\n",
    "            print(self.q_function_to_string(qfunction, title=title))\n",
    "\n",
    "    def visualise_policy(self, policy, title=\"\", grid_size=1.0, gif=False):\n",
    "        if self.matplotlib_installed():\n",
    "            return self.visualise_policy_as_image(policy, title=title, grid_size=grid_size, gif=gif)\n",
    "        else:\n",
    "            print(self.policy_to_string(policy, title=title))\n",
    "\n",
    "    def visualise_stochastic_policy(self, policy, title=\"\", grid_size=1.0, gif=False):\n",
    "        if self.matplotlib_installed():\n",
    "            return self.visualise_stochastic_policy_as_image(policy, title=title, grid_size=grid_size, gif=gif)\n",
    "        else:\n",
    "            # TODO make a stochastic policy to string\n",
    "            pass\n",
    "\n",
    "    \"\"\" Visualise a grid world problem as a formatted string \"\"\"\n",
    "    def to_string(self, title=\"\"):\n",
    "        left_arrow = \"\\u25C4\"\n",
    "        up_arrow = \"\\u25B2\"\n",
    "        right_arrow = \"\\u25BA\"\n",
    "        down_arrow = \"\\u25BC\"\n",
    "\n",
    "\n",
    "        space = \" |              \"\n",
    "        block = \" | #############\"\n",
    "\n",
    "        line = \"  \"\n",
    "        for x in range(self.width):\n",
    "            line += \"--------------- \"\n",
    "        line += \"\\n\"\n",
    "\n",
    "        result = \" \" + title + \"\\n\"\n",
    "        result += line\n",
    "        for y in range(self.height - 1, -1, -1):\n",
    "            for x in range(self.width):\n",
    "                if (x, y) in self.get_goal_states().keys():\n",
    "                    result += space\n",
    "                elif (x, y) in self.blocked_states:\n",
    "                    result += block\n",
    "                else:\n",
    "                    result += \" |       {}      \".format(up_arrow)\n",
    "            result += \" |\\n\"\n",
    "\n",
    "            for x in range(self.width):\n",
    "                if (x, y) == self.get_initial_state():\n",
    "                    result += \" |     _____    \"\n",
    "                elif (x, y) in self.blocked_states:\n",
    "                    result += block\n",
    "                else:\n",
    "                    result += space\n",
    "            result += \" |\\n\"\n",
    "\n",
    "            for x in range(self.width):\n",
    "                if (x, y) == self.get_initial_state():\n",
    "                    result += \" |    ||o  o|   \"\n",
    "                elif (x, y) in self.blocked_states:\n",
    "                    result += block\n",
    "                else:\n",
    "                    result += space\n",
    "            result += \" |\\n\"\n",
    "\n",
    "            for x in range(self.width):\n",
    "                if (x, y) == self.get_initial_state():\n",
    "                    result += \" | {}  ||  * |  {}\".format(left_arrow, right_arrow)\n",
    "                elif (x, y) in self.blocked_states:\n",
    "                    result += block\n",
    "                elif (x, y) in self.get_goal_states().keys():\n",
    "                    result += \" |     {:+0.2f}    \".format(\n",
    "                        self.get_goal_states()[(x, y)]\n",
    "                    )\n",
    "                else:\n",
    "                    result += \" | {}           {}\".format(left_arrow, right_arrow)\n",
    "            result += \" |\\n\"\n",
    "\n",
    "            for x in range(self.width):\n",
    "                if (x, y) == self.get_initial_state():\n",
    "                    result += \" |    ||====|   \".format(left_arrow, right_arrow)\n",
    "                elif (x, y) in self.blocked_states:\n",
    "                    result += block\n",
    "                else:\n",
    "                    result += space\n",
    "            result += \" |\\n\"\n",
    "\n",
    "            for x in range(self.width):\n",
    "                if (x, y) == self.get_initial_state():\n",
    "                    result += \" |     -----    \"\n",
    "                elif (x, y) in self.blocked_states:\n",
    "                    result += block\n",
    "                else:\n",
    "                    result += space\n",
    "            result += \" |\\n\"\n",
    "\n",
    "            for x in range(self.width):\n",
    "                if (x, y) in self.get_goal_states().keys():\n",
    "                    result += space\n",
    "                elif (x, y) in self.blocked_states:\n",
    "                    result += block\n",
    "                else:\n",
    "                    result += \" |       {}      \".format(down_arrow)\n",
    "            result += \" |\\n\"\n",
    "            result += line\n",
    "        return result\n",
    "\n",
    "    \"\"\" Convert a grid world value function to a formatted string \"\"\"\n",
    "\n",
    "    def value_function_to_string(self, values, title=\"\"):\n",
    "        line = \" {:-^{n}}\\n\".format(\"\", n=len(\" | +0.00\") * self.width + 1)\n",
    "        result = \" \" + title + \"\\n\"\n",
    "        result += line\n",
    "        for y in range(self.height - 1, -1, -1):\n",
    "            for x in range(self.width):\n",
    "                if (x, y) in self.blocked_states:\n",
    "                    result += \" | #####\"\n",
    "                else:\n",
    "                    result += \" | {:+0.2f}\".format(values.get_value((x, y)))\n",
    "            result += \" |\\n\"\n",
    "            result += line\n",
    "\n",
    "        return result\n",
    "\n",
    "    \"\"\" Convert a grid world Q function to a formatted string \"\"\"\n",
    "\n",
    "    def q_function_to_string(self, qfunction, title=\"\"):\n",
    "        left_arrow = \"\\u25C4\"\n",
    "        up_arrow = \"\\u25B2\"\n",
    "        right_arrow = \"\\u25BA\"\n",
    "        down_arrow = \"\\u25BC\"\n",
    "\n",
    "        space = \" |               \"\n",
    "\n",
    "        line = \"  \"\n",
    "        for x in range(self.width):\n",
    "            line += \"---------------- \"\n",
    "        line += \"\\n\"\n",
    "\n",
    "        result = \" \" + title + \"\\n\"\n",
    "        result += line\n",
    "        for y in range(self.height - 1, -1, -1):\n",
    "            for x in range(self.width):\n",
    "                if (x, y) in self.blocked_states or (\n",
    "                    x,\n",
    "                    y,\n",
    "                ) in self.get_goal_states().keys():\n",
    "                    result += space\n",
    "                else:\n",
    "                    result += \" |       {}       \".format(up_arrow)\n",
    "            result += \" |\\n\"\n",
    "\n",
    "            for x in range(self.width):\n",
    "                if (x, y) in self.blocked_states or (\n",
    "                    x,\n",
    "                    y,\n",
    "                ) in self.get_goal_states().keys():\n",
    "                    result += space\n",
    "                else:\n",
    "                    result += \" |     {:+0.2f}     \".format(\n",
    "                        qfunction.get_q_value((x, y), self.UP)\n",
    "                    )\n",
    "            result += \" |\\n\"\n",
    "\n",
    "            for x in range(self.width):\n",
    "                result += space\n",
    "            result += \" |\\n\"\n",
    "\n",
    "            for x in range(self.width):\n",
    "                if (x, y) in self.blocked_states:\n",
    "                    result += \" |     #####     \"\n",
    "                elif (x, y) in self.get_goal_states().keys():\n",
    "                    result += \" |     {:+0.2f}     \".format(\n",
    "                        self.get_goal_states()[(x, y)]\n",
    "                    )\n",
    "                else:\n",
    "                    result += \" | {}{:+0.2f}  {:+0.2f}{}\".format(\n",
    "                        left_arrow,\n",
    "                        qfunction.get_q_value((x, y), self.LEFT),\n",
    "                        qfunction.get_q_value((x, y), self.RIGHT),\n",
    "                        right_arrow,\n",
    "                    )\n",
    "            result += \" |\\n\"\n",
    "\n",
    "            for x in range(self.width):\n",
    "                result += space\n",
    "            result += \" |\\n\"\n",
    "\n",
    "            for x in range(self.width):\n",
    "                if (x, y) in self.blocked_states or (\n",
    "                    x,\n",
    "                    y,\n",
    "                ) in self.get_goal_states().keys():\n",
    "                    result += space\n",
    "                else:\n",
    "                    result += \" |     {:+0.2f}     \".format(\n",
    "                        qfunction.get_q_value((x, y), self.DOWN)\n",
    "                    )\n",
    "            result += \" |\\n\"\n",
    "\n",
    "            for x in range(self.width):\n",
    "                if (x, y) in self.blocked_states or (\n",
    "                    x,\n",
    "                    y,\n",
    "                ) in self.get_goal_states().keys():\n",
    "                    result += space\n",
    "                else:\n",
    "                    result += \" |       {}       \".format(down_arrow)\n",
    "            result += \" |\\n\"\n",
    "            result += line\n",
    "        return result\n",
    "\n",
    "    \"\"\" Convert a grid world policy to a formatted string \"\"\"\n",
    "    def policy_to_string(self, policy, title=\"\"):\n",
    "        arrow_map = {self.UP:'\\u25B2',\n",
    "                     self.DOWN:'\\u25BC',\n",
    "                     self.LEFT:'\\u25C4',\n",
    "                     self.RIGHT:'\\u25BA',\n",
    "                    }\n",
    "        line = \" {:-^{n}}\\n\".format(\"\", n=len(\" |  N \") * self.width + 1)\n",
    "        result = \" \" + title + \"\\n\"\n",
    "        result += line\n",
    "        for y in range(self.height - 1, -1, -1):\n",
    "            for x in range(self.width):\n",
    "                if (x, y) in self.blocked_states:\n",
    "                    result += \" | ###\"\n",
    "                elif policy.select_action((x, y), self.get_actions((x, y))) == self.TERMINATE:\n",
    "                    result += \" | {:+0d} \".format(self.goal_states[(x, y)])\n",
    "                else:\n",
    "                    result += \" |  \" + arrow_map[policy.select_action((x, y), self.get_actions((x, y)))] + \" \"\n",
    "            result += \" |\\n\"\n",
    "            result += line\n",
    "\n",
    "        return result\n",
    "\n",
    "\n",
    "    \"\"\" Initialise a gridworld grid \"\"\"\n",
    "    def initialise_grid(self, grid_size=1.0):\n",
    "        fig = plt.figure(figsize=(self.width * grid_size, self.height * grid_size))\n",
    "\n",
    "        # Trim whitespace \n",
    "        plt.subplots_adjust(top=0.92, bottom=0.01, right=1, left=0, hspace=0, wspace=0)\n",
    "        ax = fig.add_subplot(1, 1, 1)\n",
    "\n",
    "        # Initialise the map to all white\n",
    "        img = [[COLOURS['white'] for _ in range(self.width)] for _ in range(self.height)]\n",
    "\n",
    "        # Render the grid\n",
    "        for y in range(0, self.height):\n",
    "            for x in range(0, self.width):\n",
    "                if (x, y) in self.goal_states:\n",
    "                    img[y][x] = COLOURS['red'] if self.goal_states[(x, y)] < 0 else COLOURS['green']\n",
    "                elif (x, y) in self.blocked_states:\n",
    "                    img[y][x] = COLOURS['grey']\n",
    "\n",
    "        ax.xaxis.set_ticklabels([])  # clear x tick labels\n",
    "        ax.axes.yaxis.set_ticklabels([])  # clear y tick labels\n",
    "        ax.tick_params(which='both', top=False, left=False, right=False, bottom=False)\n",
    "        ax.set_xticks([w - 0.5 for w in range(0, self.width, 1)])\n",
    "        ax.set_yticks([h - 0.5 for h in range(0, self.height, 1)])\n",
    "        ax.grid(color='lightgrey')\n",
    "        return fig, ax, img\n",
    "\n",
    "    \"\"\" visualise the gridworld problem as a matplotlib image \"\"\"\n",
    "\n",
    "    def visualise_as_image(self, agent_position=None, title=\"\", grid_size=1.0, gif=False):\n",
    "        fig, ax, img = self.initialise_grid(grid_size=grid_size)\n",
    "        current_position = (\n",
    "            self.get_initial_state() if agent_position is None else agent_position\n",
    "        )\n",
    "\n",
    "        # Render the grid\n",
    "        for y in range(0, self.height):\n",
    "            for x in range(0, self.width):\n",
    "                if (x, y) == current_position:\n",
    "                    ax.scatter(x, y, s=2000, marker='o', edgecolors='none')\n",
    "                elif (x, y) in self.goal_states:\n",
    "                    plt.text(\n",
    "                        x,\n",
    "                        y,\n",
    "                        f\"{self.get_goal_states()[(x, y)]:+0.2f}\",\n",
    "                        fontsize=\"x-large\",\n",
    "                        horizontalalignment=\"center\",\n",
    "                        verticalalignment=\"center\",\n",
    "                    )\n",
    "        im = plt.imshow(img, origin=\"lower\")\n",
    "        plt.title(title)\n",
    "        if gif:\n",
    "            return fig, ax, im\n",
    "        else:\n",
    "            return fig\n",
    "\n",
    "    \"\"\"Render each tile individually depending on the current state of the cell\"\"\"\n",
    "\n",
    "    def render_tile(self, x, y, tile_size, img, tile_type=None):\n",
    "        ymin = y * tile_size\n",
    "        ymax = (y + 1) * tile_size\n",
    "        xmin = x * tile_size\n",
    "        xmax = (x + 1) * tile_size\n",
    "\n",
    "        for i in range(ymin, ymax):\n",
    "            for j in range(xmin, xmax):\n",
    "                if i == ymin or i == ymax - 1 or j == xmin or j == xmax + 1:\n",
    "                    draw_grid_lines(i, j, img)\n",
    "                else:\n",
    "                    if tile_type == \"goal\":\n",
    "                        render_goal(\n",
    "                            i,\n",
    "                            j,\n",
    "                            img,\n",
    "                            reward=self.goal_states[(x, y)],\n",
    "                            reward_max=max(self.get_goal_states().values()),\n",
    "                            reward_min=min(self.get_goal_states().values()),\n",
    "                        )\n",
    "                    elif tile_type == \"blocked\":\n",
    "                        render_blocked_tile(i, j, img)\n",
    "                    elif tile_type == \"agent\":\n",
    "                        render_agent(\n",
    "                            i,\n",
    "                            j,\n",
    "                            img,\n",
    "                            center_x=xmin + tile_size / 2,\n",
    "                            center_y=ymin + tile_size / 2,\n",
    "                            radius=tile_size / 4,\n",
    "                        )\n",
    "                    elif tile_type == \"empty\":\n",
    "                        img[i][j] = [255, 255, 255]\n",
    "                    else:\n",
    "                        raise ValueError(\"Invalid tile type\")\n",
    "\n",
    "    \"\"\" Visualise the value function \"\"\"\n",
    "\n",
    "    def visualise_value_function_as_image(self, value_function, title=\"\", grid_size=1.0, gif=False):\n",
    "        if not gif:\n",
    "            fig, ax, img = self.initialise_grid(grid_size=grid_size)\n",
    "        texts = []\n",
    "        for y in range(self.height):\n",
    "            for x in range(self.width):\n",
    "                value = value_function.get_value((x, y))\n",
    "                if (x, y) not in self.blocked_states:\n",
    "                    text = plt.text(\n",
    "                        x,\n",
    "                        y,\n",
    "                        f\"{float(value):+0.2f}\",\n",
    "                        fontsize=\"medium\",\n",
    "                        horizontalalignment=\"center\",\n",
    "                        verticalalignment=\"center\",\n",
    "                        color='lightgrey' if value == 0.0 else 'black',\n",
    "                    )\n",
    "                    texts.append(text)\n",
    "        if gif:\n",
    "            return texts\n",
    "        else:\n",
    "            ax.imshow(img, origin=\"lower\")\n",
    "            plt.title(title, fontsize=\"large\")\n",
    "            plt.show()\n",
    "\n",
    "    \"\"\" Visualise the value function using a heat-map where green is high value and\n",
    "    red is low value\n",
    "    \"\"\"\n",
    "\n",
    "    def visualise_value_function_as_heatmap(self, value_function, title=\"\"):\n",
    "        values = [[0 for _ in range(self.width)] for _ in range(self.height)]\n",
    "        fig, ax = self.initialise_grid()\n",
    "        for y in range(self.height):\n",
    "            for x in range(self.width):\n",
    "                if (x, y) in self.blocked_states:\n",
    "                    plt.text(\n",
    "                        x,\n",
    "                        y,\n",
    "                        \"#\",\n",
    "                        horizontalalignment=\"center\",\n",
    "                        verticalalignment=\"center\",\n",
    "                    )\n",
    "                else:\n",
    "                    values[y][x] = value_function.get_value((x, y))\n",
    "                    plt.text(\n",
    "                        x,\n",
    "                        y,\n",
    "                        f\"{values[y][x]:.2f}\",\n",
    "                        horizontalalignment=\"center\",\n",
    "                        verticalalignment=\"center\",\n",
    "                    )\n",
    "        plt.imshow(values, origin=\"lower\", cmap=make_red_white_green_cmap())\n",
    "        plt.title(title)\n",
    "        plt.show()\n",
    "\n",
    "    \"\"\" Visualise the Q-function with matplotlib \"\"\"\n",
    "\n",
    "    def visualise_q_function_as_image(self, qfunction, title=\"\", grid_size=1.5, gif=False):\n",
    "        if not gif:\n",
    "            fig, ax, img = self.initialise_grid(grid_size=grid_size)\n",
    "        texts = []\n",
    "        for y in range(self.height):\n",
    "            for x in range(self.width):\n",
    "                if (x, y) in self.goal_states:\n",
    "                    # gif player handles goal state rendering\n",
    "                    if not gif:\n",
    "                        texts.append(plt.text(\n",
    "                            x,\n",
    "                            y,\n",
    "                            f\"{self.get_goal_states()[(x,y)]:+0.2f}\",\n",
    "                            fontsize=\"large\",\n",
    "                            horizontalalignment=\"center\",\n",
    "                            verticalalignment=\"center\",\n",
    "                        ))\n",
    "                elif (x, y) not in self.blocked_states:\n",
    "                    up_value = qfunction.get_q_value((x, y), self.UP)\n",
    "                    down_value = qfunction.get_q_value((x, y), self.DOWN)\n",
    "                    left_value = qfunction.get_q_value((x, y), self.LEFT)\n",
    "                    right_value = qfunction.get_q_value((x, y), self.RIGHT)\n",
    "                    texts.append(plt.text(\n",
    "                        x,\n",
    "                        y + 0.35,\n",
    "                        f\"{up_value:+0.2f}\",\n",
    "                        fontsize=\"medium\",\n",
    "                        horizontalalignment=\"center\",\n",
    "                        verticalalignment=\"top\",\n",
    "                        color='lightgrey' if up_value == 0.0 else 'black',\n",
    "                    ))\n",
    "                    texts.append(plt.text(\n",
    "                        x,\n",
    "                        y - 0.35,\n",
    "                        f\"{down_value:+0.2f}\",\n",
    "                        fontsize=\"medium\",\n",
    "                        horizontalalignment=\"center\",\n",
    "                        verticalalignment=\"bottom\",\n",
    "                        color='lightgrey' if down_value == 0.0 else 'black',\n",
    "                    ))\n",
    "                    texts.append(plt.text(\n",
    "                        x - 0.45,\n",
    "                        y,\n",
    "                        f\"{left_value:+0.2f}\",\n",
    "                        fontsize=\"medium\",\n",
    "                        horizontalalignment=\"left\",\n",
    "                        verticalalignment=\"center\",\n",
    "                        color='lightgrey' if left_value == 0.0 else 'black'\n",
    "                    ))\n",
    "                    texts.append(plt.text(\n",
    "                        x + 0.45,\n",
    "                        y,\n",
    "                        f\"{right_value:+0.2f}\",\n",
    "                        fontsize=\"medium\",\n",
    "                        horizontalalignment=\"right\",\n",
    "                        verticalalignment=\"center\",\n",
    "                        color='lightgrey' if right_value == 0.0 else 'black'\n",
    "                    ))\n",
    "                    plt.plot([x-0.5, x+0.5], [y-0.5, y+0.5], ls='-', lw=1, color='lightgrey')\n",
    "                    plt.plot([x + 0.5, x - 0.5], [y - 0.5, y + 0.5], ls='-', lw=1, color='lightgrey')\n",
    "        if gif:\n",
    "            return texts\n",
    "        ax.imshow(img, origin=\"lower\")\n",
    "        plt.title(title)\n",
    "        plt.show()\n",
    "\n",
    "    \"\"\" Visualise the Q-function with a matplotlib visual\"\"\"\n",
    "\n",
    "    def visualise_q_function_rendered(self, q_values, title=\"\", tile_size=32, show_text=False):\n",
    "        width_px = self.width * tile_size\n",
    "        height_px = self.height * tile_size\n",
    "        img = [[[0, 0, 0] for _ in range(width_px)] for _ in range(height_px)]\n",
    "\n",
    "        # provide these to scale the colours between the highest and lowest value\n",
    "        reward_max = max(self.get_goal_states().values())\n",
    "        reward_min = min(self.get_goal_states().values())\n",
    "        # Render the grid\n",
    "        for y in range(0, self.height):\n",
    "            for x in range(0, self.width):\n",
    "                # Draw in the blocked states as a black and white mesh\n",
    "                if (x, y) in self.blocked_states:\n",
    "                    render_full_blocked_tile(\n",
    "                        x * tile_size, y * tile_size, tile_size, img\n",
    "                    )\n",
    "                    continue\n",
    "                # Draw goal states\n",
    "                if (x, y) in self.goal_states:\n",
    "                    render_full_goal_tile(\n",
    "                        x * tile_size,\n",
    "                        y * tile_size,\n",
    "                        tile_size,\n",
    "                        img,\n",
    "                        reward=self.goal_states[(x, y)],\n",
    "                        rewardMax=reward_max,\n",
    "                        rewardMin=reward_min,\n",
    "                    )\n",
    "                    continue\n",
    "\n",
    "                # Draw the action value for action available in each cell\n",
    "                # Break the grid up into 4 sections, using triangles that meet\n",
    "                # in the middle. The base of the triangle points toward the\n",
    "                # direction of the action\n",
    "                render_action_q_value(\n",
    "                    tile_size,\n",
    "                    x,\n",
    "                    y,\n",
    "                    self.UP,\n",
    "                    q_values,\n",
    "                    img,\n",
    "                    show_text,\n",
    "                    v_text_offset=8,\n",
    "                    rewardMax=reward_max,\n",
    "                    rewardMin=reward_min,\n",
    "                )\n",
    "                render_action_q_value(\n",
    "                    tile_size,\n",
    "                    x,\n",
    "                    y,\n",
    "                    self.DOWN,\n",
    "                    q_values,\n",
    "                    img,\n",
    "                    show_text,\n",
    "                    v_text_offset=-8,\n",
    "                    rewardMax=reward_max,\n",
    "                    rewardMin=reward_min,\n",
    "                )\n",
    "                render_action_q_value(\n",
    "                    tile_size,\n",
    "                    x,\n",
    "                    y,\n",
    "                    self.LEFT,\n",
    "                    q_values,\n",
    "                    img,\n",
    "                    show_text,\n",
    "                    h_text_offset=-8,\n",
    "                    rewardMax=reward_max,\n",
    "                    rewardMin=reward_min,\n",
    "                )\n",
    "                render_action_q_value(\n",
    "                    tile_size,\n",
    "                    x,\n",
    "                    y,\n",
    "                    self.RIGHT,\n",
    "                    q_values,\n",
    "                    img,\n",
    "                    show_text,\n",
    "                    h_text_offset=8,\n",
    "                    rewardMax=reward_max,\n",
    "                    rewardMin=reward_min,\n",
    "                )\n",
    "\n",
    "        ax.imshow(img, origin=\"lower\", interpolation=\"bilinear\")\n",
    "        plt.title(title)\n",
    "        plt.axis(\"off\")\n",
    "        plt.show()\n",
    "\n",
    "    \"\"\" Visualise the policy of the agent with a matplotlib visual \"\"\"\n",
    "\n",
    "    def visualise_policy_as_image(self, policy, title=\"\", grid_size=1.0, gif=False):\n",
    "        # Map from action names to prettier arrows\n",
    "        arrow_map = {self.UP:'\\u2191',\n",
    "                     self.DOWN:'\\u2193',\n",
    "                     self.LEFT:'\\u2190',\n",
    "                     self.RIGHT:'\\u2192',\n",
    "                    }\n",
    "        if not gif:\n",
    "            fig, ax, img = self.initialise_grid(grid_size=grid_size)\n",
    "        texts = []\n",
    "        for y in range(self.height):\n",
    "            for x in range(self.width):\n",
    "                if (x, y) not in self.blocked_states and (x, y) not in self.goal_states:\n",
    "                    if policy.select_action((x, y), self.get_actions((x, y))) != self.TERMINATE:\n",
    "                        action = arrow_map[policy.select_action((x, y), self.get_actions((x, y)))]\n",
    "                        fontsize = \"xx-large\"\n",
    "                    texts.append(plt.text(\n",
    "                                x,\n",
    "                                y,\n",
    "                                action,\n",
    "                                fontsize=fontsize,\n",
    "                                horizontalalignment=\"center\",\n",
    "                                verticalalignment=\"center\",\n",
    "                            ))\n",
    "                elif (x, y) in self.goal_states:\n",
    "                    # gif player handles goal state rendering\n",
    "                    if not gif:\n",
    "                        plt.text(\n",
    "                            x,\n",
    "                            y,\n",
    "                            f\"{self.get_goal_states()[(x, y)]:+0.2f}\",\n",
    "                            fontsize=\"x-large\",\n",
    "                            horizontalalignment=\"center\",\n",
    "                            verticalalignment=\"center\",\n",
    "                        )\n",
    "        if gif:\n",
    "            return texts\n",
    "        ax.imshow(img, origin=\"lower\")\n",
    "        plt.title(title)\n",
    "        plt.show()\n",
    "\n",
    "    def execute(self, state, action):\n",
    "        if state in self.goal_states:\n",
    "            self.rewards += [self.episode_rewards]\n",
    "            self.cumulative_rewards += [sum(self.episode_rewards)]\n",
    "            return MDP.execute(self, state=state, action=self.TERMINATE)\n",
    "        return super().execute(state, action)\n",
    "\n",
    "    def visualise_stochastic_policy_as_image(self, policy, title=\"\", grid_size=1.0, gif=False):\n",
    "        if not gif:\n",
    "            fig, ax, img = self.initialise_grid(grid_size=grid_size)\n",
    "        texts = []\n",
    "\n",
    "        # Render the grid\n",
    "        for y in range(0, self.height):\n",
    "            for x in range(0, self.width):\n",
    "                prob_up = 0.0\n",
    "                prob_down = 0.0\n",
    "                prob_left = policy.get_probability((x, y), self.LEFT)\n",
    "                prob_right = policy.get_probability((x, y), self.RIGHT)\n",
    "                if self.height > 1:\n",
    "                    prob_up = policy.get_probability((x, y), self.UP)\n",
    "                    prob_down = policy.get_probability((x, y), self.DOWN)\n",
    "                # Normalise to account for the 'terminate' action that is not visualised\n",
    "                total = prob_left + prob_right + prob_down + prob_up\n",
    "                if total != 0:\n",
    "                    prob_left = prob_left / total\n",
    "                    prob_right = prob_right / total\n",
    "                    prob_down = prob_down / total\n",
    "                    prob_up = prob_up / total\n",
    "                if (x, y) in self.goal_states:\n",
    "                    # gif player handles goal state rendering\n",
    "                    if not gif:\n",
    "                        plt.text(\n",
    "                            x,\n",
    "                            y,\n",
    "                            f\"{self.get_goal_states()[(x, y)]:+0.2f}\",\n",
    "                            fontsize=\"x-large\",\n",
    "                            horizontalalignment=\"center\",\n",
    "                            verticalalignment=\"center\",\n",
    "                        )\n",
    "                elif (x, y) not in self.blocked_states:\n",
    "                    left_triangle = '\\u25C4'\n",
    "                    up_triangle = '\\u25B2'\n",
    "                    right_triangle = '\\u25BA'\n",
    "                    down_triangle = '\\u25BC'\n",
    "                    if self.height > 1:\n",
    "                        texts.append(plt.text(\n",
    "                            x,\n",
    "                            y,\n",
    "                            f\"{prob_up:0.2f}\\n{up_triangle}\\n{prob_left:0.2f}{left_triangle} {right_triangle}{prob_right:0.2f}\\n{down_triangle}\\n{prob_down:0.2f}\",\n",
    "                            fontsize=\"medium\",\n",
    "                            horizontalalignment=\"center\",\n",
    "                            verticalalignment=\"center\",\n",
    "                        ))\n",
    "                    else:\n",
    "                        texts.append(plt.text(\n",
    "                            x,\n",
    "                            y,\n",
    "                            f\"{prob_left:0.2f}{left_triangle} {right_triangle}{prob_right:0.2f}\",\n",
    "                            fontsize=\"medium\",\n",
    "                            horizontalalignment=\"center\",\n",
    "                            verticalalignment=\"center\",\n",
    "                        ))\n",
    "        if gif:\n",
    "            return texts\n",
    "        ax.imshow(img, origin=\"lower\")\n",
    "        plt.title(title)\n",
    "        plt.show()\n",
    "        return fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAjYAAAHDCAYAAAA3AVACAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjguMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8g+/7EAAAACXBIWXMAAA9hAAAPYQGoP6dpAABtX0lEQVR4nO3dfVyUBb7///cMgzAIAwwKSCjeUIFZrYsnw0ox3SQ7rR05eTTsxmW9aWPb9Jw9242b1W52vqutre6WeSqtX7Z1tJtNd3Oz1GyT0KUwBaJUEAUG0eFG5G6Ymd8fdl0xAgPMzDXX3fv5ePDYZeaa4brGi1efmeuaweB2u90gIiIi0gCj3CtAREREFCgcbIiIiEgzONgQERGRZnCwISIiIs3gYENERESawcGGiIiINIODDREREWkGBxsiIiLSDA42REREpBkcbIhItbKyspCVlSX3ahCRgnCwIdKAkpISLFy4EJdddhnCwsKQlJSEhQsXorS0dMD3YTAYev1KTEyUcM37V1paiieeeAKVlZWyrgcRqYOBfyuKSN3eeecdLFiwAFarFXl5eRgzZgwqKyvx8ssvw26346233sKcOXP6vR+DwYAf/ehHuOeeezwuN5vNyMnJkWr1+7V9+3bceeed2Lt3b49XZzo7OwEAQ4YMkWHNiEiJTHKvABH57vjx47j77rsxduxY7N+/H8OHDxev+8UvfoGbbroJCxcuxFdffYUxY8b0e39XXHEFFi5cKOUqBxQHGiK6FA9FEanYmjVr0Nraik2bNnkMNQAwbNgwvPjii2hpacGaNWv8/ln33XcfRo8e3ePyJ554AgaDweMyg8GA/Px8vPfee5gwYQLCwsJw1VVXYdeuXT1uX11djby8PCQlJSEsLAxjxozB/fffj87OTmzZsgV33nknAGD69Oni4bF9+/YB6P0cmzNnziAvLw8JCQkIDw/Htddei1dffdVjmcrKShgMBqxduxabNm3CuHHjEBYWhn/5l3/BoUOHfH+QiEh2fMWGSMV27NiB0aNH46abbur1+qlTp2L06NHYsWMHnn/++X7vr729HWfPnvW4LCoqCmFhYYNet3/84x9455138LOf/QxRUVFYv349cnJyUFVVhbi4OABATU0NrrvuOjQ2NmLJkiVIS0tDdXU1tm/fjtbWVkydOhUPPvgg1q9fj0cffRTp6ekAIP7vpdra2pCVlYVjx44hPz8fY8aMwbZt23DfffehsbERv/jFLzyWf+ONN3D+/HksXboUBoMBv/vd7zB37lycOHECoaGhg95mIlIANxGpUmNjoxuAe86cOV6X+/GPf+wG4G5ubva6HIBevzZv3ux2u93ue++9152SktLjdqtWrXJfmhIA7iFDhriPHTsmXnb48GE3APeGDRvEy+655x630Wh0Hzp0qMf9ulwut9vtdm/bts0NwL13794ey0ybNs09bdo08fvnnnvODcD9+uuvi5d1dna6MzMz3ZGRkeJjUFFR4QbgjouLc9vtdnHZv/zlL24A7h07dvT9QBGRovEVGyKVOn/+PICLr6h4I1x//vz5fpedM2cO8vPzPS676qqrfFq/mTNnYty4ceL311xzDSwWC06cOAEAcLlceO+993D77bdj0qRJPW5/6eGtgfjb3/6GxMRELFiwQLwsNDQUDz74IBYsWIBPPvkE//qv/ype9x//8R+IjY0Vvxde+RLWkYjUh4MNkUp1H1i8OX/+PAwGA4YNGwa73S6+kwi4+I6n6Oho8fvk5GTMnDkzIOs3atSoHpfFxsaioaEBAFBfX4/m5mZMmDAhID8PAE6ePInLL78cRqPn6YPCoauTJ096XUdhyBHWkYjUhycPE6lUdHQ0kpKS8NVXX3ld7quvvkJycjKGDBmCuXPnYsSIEeLXpeeceNPXKyhOp7PXy0NCQnq93K2gT5hQwzoS0eDwFRsiFbv99tvx4osv4h//+AduvPHGHtd/+umnqKysxIoVKwAAzz77rMerEUlJSQP+WbGxsWhsbOxx+aWvggzU8OHDYbFYcPToUa/LDeaQVEpKCr766iu4XC6PV22+/vpr8Xoi0ja+YkOkYv/1X/+FiIgILF26FOfOnfO4zm63Y9myZbBYLOJ5MxkZGZg5c6b4NX78+AH/rHHjxqGpqcnjFaLa2lq8++67Pq270WjEHXfcgR07duCf//xnj+uFV02GDh0KAL0OVZeaPXs2bDYb3nrrLfGyrq4ubNiwAZGRkZg2bZpP60pE6sFXbIhULDU1Fa+99hoWLFiAq6++uscnDzc0NODNN98c0Ifz9Wf+/Pn41a9+hX/7t3/Dgw8+iNbWVrzwwgu44oor8MUXX/h0n6tXr8aHH36IadOmYcmSJUhPT0dtbS22bduGf/zjH4iJicEPfvADhISE4P/9v/+HpqYmhIWF4eabb0Z8fHyP+1uyZAlefPFF3HfffSgqKsLo0aOxfft2fPbZZ3juuef6PXmaiNSPgw2RyuXk5OCLL77AM888g5deeglnzpyBy+VCeHg4ioqKBvWqjDdxcXF49913sWLFCvz3f/83xowZg2eeeQbffvutz4PNZZddhsLCQvz617/G1q1b0dzcjMsuuwy33norIiIiAACJiYnYuHEjnnnmGeTl5cHpdGLv3r29DjZmsxn79u3Dww8/jFdffRXNzc248sorsXnzZtx3333+bD4RqQT/VhSRBr322mu47777sHDhQrz22mtyrw4RUdDwFRsiDbrnnntQW1uLhx9+GMnJyVi9erXcq0REFBR8xYaIiIg0g++KIiIiIs3gYENERESawcGGiIiINIODDREREWnGgN4V5XK5UFNTg6ioKJ/+4i4RERGRr9xuN86fP4+kpKQef+T2UgMabGpqajBy5MiArBwRERGRL06dOoXk5GSvywxosBE+hnzfvn2IjIxESkoKhgwZ4v8akqrV19ejvr4ew4cPh9VqRXl5OYCLf9xw+PDhMq8dya2zs1P8A5kjR47EiRMnEBoaCgBsCAHwbMjjnzyOn4//OTaUboDD5ZB71UhhHG0OvPfgewP6sygDGmyEw0/p6eloaGjAuXPnMGbMGIZJx86cOYO2tjaMHTsW8fHxcDqdiIyMxPDhw1FfX4/29vZeP/Ke9KGzsxO1tbWIjIzEmDFjEBISgjNnziA1NRUnT55kQ6hHQ4YcGoLIyEgMiRgCuOReO1KqgZwOM6iTh0NDQ8U/pldRUYHOzk7f1oxU7cyZMzhz5gzi4+N7DC/Dhg1DfHy8uAzpT2dnJyoqKgCgx/DChhDgvSFE/hr0u6KGDBnCMOnYQIIkXMfhRn+8DTUCNkTfONSQ1Hx6uzfDpE+DCRKHG/0ZyFAjYEP0iUMNBYPPn2PDMOmLL0HicKMfgxlqBGyIvnCooWDx6wP6GCZ98CdIHG60z5ehRsCG6AOHGgomvz95mGHStkAEicONdvkz1AjYEG3jUEPBFpA/qcAwaVMgg8ThRnsCMdQI2BBt4lBDcgjY34pimLRFiiBxuNGOQA41AjZEWzjUkFwC+kcwGSZtkDJIHG7UT4qhRsCGaAOHGpJTwP+6N8OkbsEIEocb9ZJyqBGwIerGoYbkFvDBBmCY1CqYQeJwoz7BGGoEbIg6caghJZBksAEYJrWRI0gcbtQjmEONgA1RFw41pBSSDTYAw6QWcgaJw43yyTHUCNgQdeBQQ0oi6WADMExKp4QgcbhRLjmHGgEbomxKaAhRd5IPNgDDpFRKChKHG+VRwlAjYEOUSUkNIRIEZbABGCalUWKQONwoh5KGGgEboixKbAgREMTBBmCYlELJQeJwIz8lDjUCNkQZlNwQoqAONgDDJDc1BInDjXyUPNQI2BB5qaEhpG9BH2wAhkkuagoSh5vgU8NQI2BD5KGmhpB+yTLYAMoPk91uR25uLiwWC2JiYpCXl4eWlhavt9m0aROysrJgsVhgMBjQ2NgYkPsNBDUGScnDjRT7R2VlJfLy8jBmzBiYzWaMGzcOq1atCsrvhpqGGoHWGmK32/Hzn/8cV155JcxmM0aNGoUHH3wQTU1NvS5/7tw5JCcn99maQFNjQ0ifZBtsAPnDlJWVhS1btvR6XW5uLkpKSrB7927s3LkT+/fvx5IlS7zeX2trK7Kzs/Hoo4/2uYwv9+svNQdJzuEm2PvH119/DZfLhRdffBElJSVYt24dNm7c6HV/CgQ1DjUCLTWkpqYGNTU1WLt2LY4ePYotW7Zg165dyMvL63X5vLw8XHPNNYHYjH6puSGkPya5V0AIU0VFBSoqKhQR1rKyMuzatQuHDh3CpEmTAAAbNmzA7NmzsXbtWiQlJfV6u4ceeggAsG/fvoDerz+0ECRhvYXBRu7tkGr/yM7ORnZ2tvj92LFjUV5ejhdeeAFr164N6DYI1DzUCLTSkAkTJuDtt98Wvx83bhyefvppLFy4EF1dXTCZvs/1Cy+8gMbGRjz++OP44IMPJN0WLTSE9EXWV2wEcj/rulRBQQFiYmLEIAHAzJkzYTQaUVhYqLj77YuWgqSkw1LB/HdsamqC1WoN6H0KtDDUCLTakKamJlgsFo+hprS0FE899RRee+01GI3SJlxLDSH9UMRgAygrTDabrccvsclkgtVqhc1mU9z99kaLQVLKcBOsf8djx45hw4YNWLp0acDuU6CloUagtYacPXsWv/nNbzwOX3V0dGDBggVYs2YNRo0aFdB1vpQWG0L6oJjBBpA+TKtXr0ZkZKT49emnn2LZsmUel1VVVQX0Z8pBy0GScrhR0v5RXV2N7Oxs3HnnnVi8eHFA71uLQ41AKw1pbm7GbbfdhvHjx+OJJ54QL3/kkUeQnp6OhQsX+v0zvNFyQ0j7ZD/H5lJSHi9ftmwZ5s2bJ36fm5uLnJwczJ07V7wsKSkJiYmJPf6j2dXVBbvdjsTERJ9/vlT3250egiTVOTdy7x+CmpoaTJ8+HVOmTMGmTZv8vr/utDzUCNTekPPnzyM7OxtRUVF49913ERoaKl63Z88eHDlyBNu3bwcAuN1uAMCwYcPw2GOP4cknn/R7G/XQENI2xQ02gHRhslqtHucrmM1mxMfHIzU11WO5zMxMNDY2oqioCBkZGQAuBsXlcmHy5Mk+/3yp7legpyBJMdzIvX8AF1+pmT59OjIyMrB58+aAnkOhh6FGoNaGNDc3Y9asWQgLC8P777+P8PBwj+vffvtttLW1id8fOnQIP/nJT/Dpp59i3Lhxfm+fnhpC2qWoQ1HdyXm8PD09HdnZ2Vi8eDEOHjyIzz77DPn5+Zg/f774bobq6mqkpaXh4MGD4u1sNhuKi4tx7NgxAMCRI0dQXFwMu90+4Pv1lR6DJNc5N1LtH9XV1cjKysKoUaOwdu1a1NfXw2azBeS8HT0NNQK1NaS5uRm33HILLly4gJdffhnNzc3iv7/T6QRw8Z1SEyZMEL+E7UtPT/f7916PDSFtUuxgA8gbpq1btyItLQ0zZszA7NmzceONN3ocFnA4HCgvL0dra6t42caNGzFx4kTxnIipU6di4sSJeP/99wd8v77Qc5DkGm6k2D92796NY8eO4eOPP0ZycjJGjBghfvlDj0ONQE0N+eKLL1BYWIgjR44gNTXV49//1KlTkq6rnhtC2mNwCwdpvWhubkZ0dDTsdjtiY2ODsV4e9Bzm/iglSE6nE2VlZUhPT0dISEjQf75SHgelUcrvjtz7h1IeByVSyu/OojcX4T8n/CeePfosOl3K+hRpkp+j1YFti7eJH4HgjaJfsREo6W2cSqKUICmBUt4KriT8j/n32JDesSGkRaoYbACG6VIMUk8cbr7HoaYnNsQTG0JapZrBBmCYBAxS3zjccKjxhg25iA0hLVPVYAMwTAxS//Q83HCo6R8bwoaQtqlusAH0GyYGaeD0ONxwqBk4NoQNIe1S5WAD6C9MDNLg6Wm44VAzeGwIkTapdrAB9BMmBsl3ehhuONT4jg0h0h5VDzaA9sPEIPlPy8MNhxr/sSFE2qL6wQbQbpgYpMDR4nDDoSZw2BAi7dDEYANoL0wMUuBpabjhUBN4bAiRNmhmsAG0EyYGSTpaGG441EiHDSFSP00NNoD6w8QgSU/Nww2HGumxIUTqprnBBlBvmBik4FHjcMOhJnjYECL10uRgA6gvTAxS8KlpuOFQE3xsCJE6aXawAdQTJgZJPmoYbjjUyIcNIVIfTQ82gPLDxCDJT8nDDYca+bEhROqi+cEGUG6YGCTlUOJww6FGOdgQIvXQxWADKC9MDJLyKGm44VCjPGwIkTroZrABlBMmBkm5lDDccKhRLjaESPl0NdgA8oeJQVI+OYcbDjXKx4YQKZvuBhtAvjAxSOohx3DDoUY92BAi5dLlYAMEP0wMkvoEc7jhUKM+bAiRMul2sAGCFyYGSb2CMdxwqFEvNoRIeXQ92ADSh4lBUj8phxsONerHhhApi+4HG0C6MDFI2iHFcMOhRjvYECLl4GDznUCHiUHSnkAONxxqtIcNIVIGDjbdBCpMDJJ2BWK44VCjXWwIkfw42FzC3zAxSNrnz3DDoUb72BAieZnkXgElEsJUUVGBioqKAf8HiEHSD+HfVxhsBvLvzaFGP9gQ6ktbQxvK/16Os8fOwl5hR1d7F2Y8NgMJ4xMGfB+t9lZ88foXqD1SC7fLjYTxCci4OwOR8ZE9lj2+7zjK/lqGlvoWRFgjcOWsK3HlrCsDuUmKw1ds+jDYZ10Mkv4M5pUbDjX6w4ZQb5prm1G6oxRtDW2IGRkz6Ns72h34+OmPcabsDK768VW45t+vQcPJBnz0m4/Qcb7DY9lvP/4Whf9biOjLojHpnkkYdvkwFL1WhNIdpQHaGmWSZbCx2+3Izc2FxWJBTEwM8vLy0NLS4vU27e3teOCBBxAXF4fIyEjk5OSgrq6ux3JbtmzBNddcg/DwcMTHx+OBBx7weT0HGiY5guTLYwgABQUFuPnmmzF06FBYLBZMnToVbW1tAIDKykrk5eVhzJgxMJvNGDduHFatWiXL38PxZfs2bdqErKwsWCwWGAwGNDY29ljm6aefxpQpUxAREYGYmBi/13Mgw40cQ81gH7/KykoYDIZev7Zt2wYAOHz4MBYsWICRI0fCbDYjPT0df/jDHyTflt5ItX8AwF//+ldMnjwZZrMZsbGxuOOOO3xeT601xGaz4e6770ZiYiKGDh2KH/7wh3j77bfF65XUELl89NuPULCxoM/rrWOsyHkxB7c/ezvSbk0b9P1/u/tbnLedx7T/mobxt49H2q1pmP7wdLQ1tqHsb2Xicl2dXfjq/75C0g+ScNNDNyH15lRMuX8KRt8wGkffPYrOC9r9N5FssMnKysKWLVt6vS43NxclJSXYvXs3du7cif3792PJkiVe72/58uXYsWMHtm3bhk8++QQ1NTWYO3euxzK///3v8dhjj+Hhhx9GSUkJPvroI8yaNcuv7egvTFIGKdCPYUFBAbKzs3HLLbfg4MGDOHToEPLz82E0XtwNvv76a7hcLrz44osoKSnBunXrsHHjRjz66KMB3S5BoLevtbUV2dnZXte3s7MTd955J+6//35/Vt2Dt+FGyqEmkI/fyJEjUVtb6/H15JNPIjIyErfeeisAoKioCPHx8Xj99ddRUlKCxx57DI888gj++Mc/BmybupNj/3j77bdx9913Y9GiRTh8+DA+++wz3HXXXf5shqYacs8996C8vBzvv/8+jhw5grlz52LevHn48ssvAQS/IWoUag5FWGSYz7evOlgF61gr4sbFiZdFJ0Uj4aoEVBVWiZfVldaho6UDl//oco/bX/6jy9HV0YXqL6t9XgelC/o5NmVlZdi1axcOHTqESZMmAQA2bNiA2bNnY+3atUhKSupxm6amJrz88st44403cPPNNwMANm/ejPT0dHz++ee4/vrr0dDQgJUrV2LHjh2YMWOGeNtrrrnG73Xu63i5XC8d+/IYAheHwwcffBAPP/yweNmVV35/rDU7OxvZ2dni92PHjkV5eTleeOEFrF27VqKt6cnX7XvooYcAAPv27evzvp988kkA6DP2vurtnBu5Dj/58viFhIQgMTHR47J3330X8+bNQ2TkxeP2P/nJTzyuHzt2LAoKCvDOO+8gPz9foq3pSar9o6urC7/4xS+wZs0a5OXliZePHz/e73XWSkMOHDiAF154Addddx0AYOXKlVi3bh2KioowceJExTREq9wuNxpPNWLctHE9rosbFwfbERscbQ6EmkPRUNlw8fIxcR7LWcdYYTAY0FDZgDE3jgnKegdb0A9FFRQUICYmRvxlAoCZM2fCaDSisLCw19sUFRXB4XBg5syZ4mVpaWkYNWoUCgouvuS3e/duuFwuVFdXIz09HcnJyZg3bx5OnToVkPW+9FlXbW2tbMfDfXkMz5w5g8LCQsTHx2PKlClISEjAtGnT8I9//MPrz2pqaoLVag3o+vfHl+1Tgu6v3NTW1sp2Tk0gHr+ioiIUFxd7/Ae+N1raP7744gtUV1fDaDRi4sSJGDFiBG699VYcPXo0EKut+oYAwJQpU/DWW2/BbrfD5XLhzTffRHt7O7Kysvq8jRz7iFZ1XOiAy+FCeEx4j+vMMWYAF09OBoC2xjYYjAaER3suG2IKwZCoIWhrbJN+hWUS9MHGZrP1+CU2mUywWq2w2Wx93mbIkCE9zolISEgQb3PixAm4XC6sXr0azz33HLZv3w673Y4f/ehHATu+K4TJ6XTi3LlziIuLk+UkP18ewxMnTgAAnnjiCSxevBi7du3CD3/4Q8yYMQPffvttr7c5duwYNmzYgKVLlwZ2A/rhy/YpRXx8POLi4nDu3Dk4nU5ZThQOxOP38ssvIz09HVOmTOlzmQMHDuCtt97q9/BFoEm1f3T/HVm5ciV27tyJ2NhYZGVlwW63+7XOAjU3BAD+7//+Dw6HA3FxcQgLC8PSpUvx7rvvIjU1tdfl5WpIsLi6XGg/3+7x5epy9Xq52+X2++c5O50ALg4nlwoJDfFYxtnphNHU+3/iQ0JDxOW0KGCDzerVqxEZGSl+ffrpp1i2bJnHZVVVVf3fkY9cLhccDgfWr1+PWbNm4frrr8ef//xnfPvtt9i7d2/Afk5jYyNcLheMRiOam5sDelKclI+hy+UCACxduhSLFi3CxIkTsW7dOlx55ZV45ZVXeixfXV2N7Oxs3HnnnVi8eLFf2yWQex8Jhs7OTjQ3N8NoNMLlcvV5gqovgvX4tbW14Y033vD6as3Ro0cxZ84crFq1CrfccovfPxOQf/8Qfkcee+wx5OTkICMjA5s3b/Y4gToQ1NoQAPj1r3+NxsZGfPTRR/jnP/+JFStWYN68eThy5EiPZaVoiNLUf1OPd5a94/F19tuzOFlwssflF85d8PvnhQz5bnjp6jmUOB1Oj2VChoTA1eXq9X6cDqe4nBYF7BybZcuWYd68eeL3ubm5yMnJ8TjBNykpCYmJiT1OsOzq6oLdbu9xjF+QmJiIzs5ONDY2erxqU1dXJ95mxIgRADyPhw8fPhzDhg0LWAy7Hw+PiYkZ9GdU9EfKx7C3xwcA0tPTezw+NTU1mD59OqZMmYJNmzb5tU3dSbl9StD9nJrU1FQ0NjYO6nNu+hOsx2/79u1obW3FPffc0+v1paWlmDFjBpYsWYKVK1f6uDU9yb1/9PY7EhYWhrFjx7IhAI4fP44//vGPOHr0KK666ioAwLXXXotPP/0Uf/rTn7Bx40ZxWakaojSxKbG4+ZGbPS77YusXCI8Ox/h/9WytOdrs988LGxoGY6gR7Y3tPa4TDi2ZYy/+HHOMGW6XG+1N7R6Ho5xdTnSe7xQPXWlRwAYbq9XqcRzVbDYjPj6+x0uUmZmZaGxsRFFRETIyMgAAe/bsgcvlwuTJk3u974yMDISGhuLjjz9GTk4OAKC8vBxVVVXIzMwEANxwww3i5cnJyQAuvp3x7NmzSElJ8Xv7ejvJz5cP4PJGysdw9OjRSEpKQnl5ucfl33zzjfiuF+Dis6zp06eLz1aFd0wFgpTbJ7feThT25UP8vAnW4/fyyy/jxz/+MYYPH97jupKSEtx8882499578fTTT/u1PZeSe//IyMhAWFgYysvLceONNwIAHA4HKisr2RBcfFcZgB5NCAkJEV/tAqRtiNIMGToEiRMSe1xmjjH3uDwQDEYDYkbG4NyJcz2uO3fsHCLjIxFqDgVwcegCgHMV53DZDy4Tl7OfsMPtdovXa1HQ97j09HRkZ2dj8eLFOHjwID777DPk5+dj/vz54pn41dXVSEtLw8GDBwEA0dHRyMvLw4oVK7B3714UFRVh0aJFyMzMxPXXXw8AuOKKKzBnzhz84he/wIEDB3D06FHce++9SEtLw/Tp0/1a577euSDVX/Ttjy+PocFgwC9/+UusX78e27dvx7Fjx/DrX/8aX3/9tXjIobq6GllZWRg1ahTWrl2L+vp62Gy2oJ/X4sv2ARfPGyguLsaxY8cAAEeOHEFxcbHH+RFVVVUoLi5GVVUVnE4niouLUVxcPKDPAOqLt3c/SfFXwfvj6+MHXDwnYv/+/fjpT3/a436PHj2K6dOn45ZbbsGKFSvEfaO+vj4o2yWQav+wWCxYtmwZVq1ahQ8//BDl5eXixwLceeedfq2zFhqSlpaG1NRULF26FAcPHsTx48fx7LPPYvfu3eJn/SilIVpx4ewFNNU0eVw26rpRsJ+weww3zTXNqCutw6jJo8TLEq5KwJDIIfj2I89zKL/96FuEhIUgaWLv73zTAln+pMLWrVuRn5+PGTNmwGg0IicnB+vXrxevdzgcKC8vF58hAMC6devEZTs6OjBr1iw8//zzHvf72muvYfny5bjttttgNBoxbdo07Nq1C6GhoT6va39vx/T1o9P95ctj+NBDD6G9vR3Lly+H3W7Htddei927d2PcuItvHdy9ezeOHTuGY8eOia96Cdxu/098Gwxftm/jxo3i27kBYOrUqQAufjTAfffdBwB4/PHH8eqrr4rLTJw4EQCwd+9er+/s6MtA3tId6FduBsKXxw8AXnnlFSQnJ/d63sz27dtRX1+P119/Ha+//rp4eUpKCiorKyXblt5ItX+sWbMGJpMJd999N9ra2jB58mTs2bMHsbG+P7vVSkNCQ0Pxt7/9DQ8//DBuv/12tLS0IDU1Fa+++ipmz54NQFkNUbKj7158p11T9cWhpeIfFagvv/gEYcK/TRCXK9hYgDNlZ3DX1u8/S+nymZfj2N5j+GTNJ0i7LQ3GECO+/uBrhEeHI2329x/4ZxpiwjX/fg3+ueWf+PQPn2LENSNQX16Pys8qce28a/36LB2lM7gHsLc1NzcjOjoadrvdr19wtRnMZ0zo/SPznU4nysrKkJ6ejpAQ7Z6U1t1g/831/JH5etw/ADZkMBa9uQj/OeE/8ezRZ9HpUu+n4n70248wdNhQZC7L7HOZN3Lf6PO67kPMR7/9qMdgAwCt51pR9HoRbEdscLvdiE+PR8bCDEQlRvW4v2N7juHrv3198W9FxUXgih9dgSuzr4TBYPBh6+TjaHVg2+JtaGpqgsVi8bos/whmHwb7HyG5nnWRPHz5j5Acr9yQfNgQfZq5cma/y1w6qAz2viLiInDTL24a0H2k3pyK1Jt7fzu+Vmn3rC4/+PrMWq7j5RRc/jyzluOcGwo+NoRIPhxsLuHv4QKGSdsCcbiAw422sSFE8uJg002gzoFgmLQpkOdAcLjRJjaESH4cbL4T6BM7GSZtkeLETg432sKGECkDBxtI924VhkkbpHy3CocbbWBDiJRD94ON1G/BZZjULRhvweVwo25sCJGy6HqwCdbnijBM6hTMzxXhcKNObAiR8uh2sAn2h6UxTOoix4elcbhRFzaESJl0OdjI9QmwDJM6yPkJsBxu1IENIVIu3Q02cn+sPcOkbEr4WHsON8rGhhApm64GG7mDJGCYlEkJQ42Aw40ysSFEyqebwUYpQRIwTMqipKFGwOFGWdgQInXQxWCjtCAJGCZlUOJQI+BwowxsCJF6aH6wUWqQBAyTvJQ81Ag43MiLDSFSF00PNkoPkoBhkocahhoBhxt5sCFE6qPZwUYtQRIwTMGlpqFGwOEmuNgQInXS5GCjtiAJGKbgUONQI+BwExxsCJF6aW6wUWuQBAyTtNQ81Ag43EiLDSFSN00NNmoPkoBhkoYWhhoBhxtpsCFE6qeZwUYrQRIwTIGlpaFGwOEmsNgQIm3QxGCjtSAJGKbA0OJQI+BwExhsCJF2qH6w0WqQBAyTf7Q81Ag43PiHDSHSFlUPNloPkoBh8o0ehhoBhxvfsCFE2qPawUYvQRIwTIOjp6FGwOFmcNgQNoS0SZWDjd6CJGCYBkaPQ42Aw83AsCFsCGmX6gYbvQZJwDB5p+ehRsDhxjs2hA0hbVPVYKP3IAkYpt5xqPkeh5vesSEXsSGkZaoZbBgkTwyTJw41PXG48cSGeGJDSKtUMdjIESS73Y7c3FxYLBbExMQgLy8PLS0tXm+zadMmZGVlwWKxwGAwoLGxMSD32xeG6SI5hprB/jva7Xb8/Oc/x5VXXgmz2YxRo0bhwQcfRFNTU6/Lnzt3DsnJyX3uRwPF4eYiNqR3bAhpkeIHGymDlJWVhS1btvR6XW5uLkpKSrB7927s3LkT+/fvx5IlS7zeX2trK7Kzs/Hoo4/2uYwv9+uN3sMk5VATyP2jpqYGNTU1WLt2LY4ePYotW7Zg165dyMvL63X5vLw8XHPNNYHYDN0PN2yId3pvCGmPSe4V8Eaul47Lysqwa9cuHDp0CJMmTQIAbNiwAbNnz8batWuRlJTU6+0eeughAMC+ffsCer/9EcJUUVGBiooK3RyKkevwky//jhMmTMDbb78tfj9u3Dg8/fTTWLhwIbq6umAyff+r+MILL6CxsRGPP/44Pvjgg4Css/D7Iww2ejkUw4YMjF4bQtqk2Fds5DweXlBQgJiYGDEcADBz5kwYjUYUFhYq7n4B/T3rkvOcmkD9OzY1NcFisXgMNaWlpXjqqafw2muvwWgM7K+n3l65YUMGR28NIe1S5GAj90l+Nputx881mUywWq2w2WyKu1+BXsIk94nCgfh3PHv2LH7zm994HELo6OjAggULsGbNGowaNSqg6yzQy3DDhvhGLw0hbVPcYCNlkFavXo3IyEjx69NPP8WyZcs8Lquqqgrozww2rYdJyqEmWPtHc3MzbrvtNowfPx5PPPGEePkjjzyC9PR0LFy40O+f4Y3Whxs2xD9abwhpn6LOsZH6WdayZcswb9488fvc3Fzk5ORg7ty54mVJSUlITEzsEfyuri7Y7XYkJib6/POlut9LafV4udSv1ARj/zh//jyys7MRFRWFd999F6GhoeJ1e/bswZEjR7B9+3YAgNvtBgAMGzYMjz32GJ588km/t1Gg1XNu2JDA0GpDSB8UM9gE46Vjq9UKq9Uqfm82mxEfH4/U1FSP5TIzM9HY2IiioiJkZGQAuPgfHZfLhcmTJ/v886W6395oLUzBOPwk9f7R3NyMWbNmISwsDO+//z7Cw8M9rn/77bfR1tYmfn/o0CH85Cc/waeffopx48YFYhM9aG24YUPYECJAIYei5D4efqn09HRkZ2dj8eLFOHjwID777DPk5+dj/vz54rsOqqurkZaWhoMHD4q3s9lsKC4uxrFjxwAAR44cQXFxMex2+4DvN5C08pKy3OfUXMqX/aO5uRm33HILLly4gJdffhnNzc2w2Wyw2WxwOp0ALr5TasKECeKX8G+Xnp4u2e+FVg5LsSFsCJFA9sFGaUESbN26FWlpaZgxYwZmz56NG2+8EZs2bRKvdzgcKC8vR2trq3jZxo0bMXHiRCxevBgAMHXqVEycOBHvv//+gO830NQeJqUNNYLB7h9ffPEFCgsLceTIEaSmpmLEiBHi16lTp+TaDADqH27YEDaEqDuDWziQ70VzczOio6Nht9sRGxsbsB+u1CBpkdQDgtPpRFlZGdLT0xESEhKQ+1TqUKNVUv4+SrF/AGxIMEn9+7jozUX4zwn/iWePPotOF4cn8uRodWDb4m3ix2R4I9srNgxScKntWReHmuBT2ys3bEhwqa0hpF+yDDYMkjzUEiYONfJRy3DDhshDLQ0hfQv6YMMgyUvpYeJQIz+lDzdsiLyU3hCioA42DJIyKDVMHGqUQ6nDDRuiDEptCBEQxMGGQVIWpYWJQ43yKG24YUOURWkNIRIEZbBhkJRJKWHiUKNcShlu2BBlUkpDiLqTfLBhkJRN7jBxqFE+uYcbNkTZ5G4I0aUkHWwYJHWQK0wcatRDruGGDVEHDjekJJINNgySugQ7TBxq1CfYww0boi4cbkgpJBlsGCR1ClaYONSoV7CGGzZEnTjckBIEfLBhkNRN6jBxqFE/qYcbNkTdONyQ3AI62DBI2iBVmDjUaIdUww0bog0cbkhOARtsGCRtCXSYONRoT6CHGzZEWzjckFwCMtgwSNoUqDBxqNGuQA03bIg2cbghOfg92DBI2uZvmDjUaJ+/ww0bom0cbijY/BpsGCR98DVMHGr0w9fhhg3RBw43FEw+DzYMkr4MNkwcavRnsMMNG6IvHG4oWHwabBgkfRpomDjU6NdAhxs2RJ843FAwDHqwYZD0rb8wORwODjU6199ww4boG4cbktqgBptz584xSOQ1TCdPngTAoUbv+hpuzp49y4YQhxuS1KAGm7NnzzJIBKBnmFpbW8XrONQQ4DncnD17FgBQX1/PhhCAng2JCo2SeY1IK0yDWdhqtSIuLg5Op1Oq9SEVCQkJQUpKCioqKsRXapKTkxESEsJ9hAAAcXFxcLvdqK+vF79nQ0ggNKSyshI/ufwnAIAhRj4pol4M4mUYg9vtdve3UHNzM6Kjo1FQUIDIyEh/Vo2IiIhoUFpaWpCZmYmmpiZYLBavyw7qFRsAGD58OIYNG+bzypF2OBwO8ZWagwcPYuLEiSgsLOSzceohJCQEkydPBsCG0Pe6N6TpsccQ8cQTuPCLXwDt7TKvGSlNa1fXgJcd1GAzbNgw1NfXw2Aw8Bi5znV2dnqcKPzJJ58AAJxOJwcb6tPw4cPZEALQsyFf1tZevKK9nYMN9TSI/64MarCJi4uDw+EQ3+XAMOkTP6eGfDVs2DAYDAY2ROfYEJLSoA9FCSFimPSJQSJ/sSH6xoaQ1AY92AAMk14xSBQobIg+sSEUDD4NNgDDpDcMEgUaG6IvbAgFi8+DDcAw6QWDRFJhQ/SBDaFg8muwARgmrWOQSGpsiLaxIRRsfg82AMOkVQwSBQsbok1sCMkhIIMNwDBpDYNEwcaGaAsbQnIJ2GADMExawSCRXNgQbWBDSE4BHWwAhkntGCSSGxuibmwIyS3ggw3AMKkVg0RKwYaoExtCSiDJYAMwTGrDIJHSsCHqwoaQUkg22AAMk1owSKRUbIg6sCGkJJIONgDDpHQMEikdG6JsbAgpjeSDDcAwKRWDRGrBhigTG0JKFJTBBmCYlIZBIrVhQ5SFDSGlCtpgAzBMSsEgkVqxIcrAhpCSBXWwARgmuTFIpHZsiLzYEFK6oA82AMMkFwaJtIINkQcbQmpglOsHx8fHIz4+HmfOnBHjpCR2ux25ubmwWCyIiYlBXl4eWlpavN4mKysLBoPB42vZsmXi9efOnUN2djaSkpIQFhaGkSNHIj8/H83NzVJvDoNEmqPFhgjcbjduvfVWGAwGvPfeex7XXdoYg8GAN998U4It8MSGkFrINtgA8ocpKysLW7Zs6fW63NxclJSUYPfu3di5cyf279+PJUuW9HufixcvRm1trfj1u9/9TrzOaDRizpw5eP/99/HNN99gy5Yt+OijjzyGHykwSKRVWmwIADz33HMwGAx9Xr9582aPztxxxx0+rP3AsSGkJrIciupOiS8pl5WVYdeuXTh06BAmTZoEANiwYQNmz56NtWvXIikpqc/bRkREIDExsdfrYmNjcf/994vfp6Sk4Gc/+xnWrFkT2A3ohkEirdNaQ4qLi/Hss8/in//8J0aMGNHrMjExMX12JtDYEFIbWV+xEcj9rOtSBQUFiImJEYMEADNnzoTRaERhYaHX227duhXDhg3DhAkT8Mgjj6C1tbXPZWtqavDOO+9g2rRpAVv37hgk0gutNKS1tRV33XUX/vSnP3kdXB544AEMGzYM1113HV555RW43e6Arr+ADSE1kv0VG4GSnnXZbLYeP99kMsFqtcJms/V5u7vuugspKSlISkrCV199hV/96lcoLy/HO++847HcggUL8Je//AVtbW24/fbb8dJLLwV8Gxgk0hstNGT58uWYMmUK5syZ0+cyTz31FG6++WZERETgww8/xM9+9jO0tLTgwQcfDNj6A2wIqZdiBhtA+jCtXr0aq1evFr9va2vD559/jvz8fPGy0tJSn++/+/Hzq6++GiNGjMCMGTNw/PhxjBs3Trxu3bp1WLVqFb755hs88sgjWLFiBZ5//nmff+6lGCTSKzU35P3338eePXvw5Zdfel3u17/+tfj/J06ciAsXLmDNmjUBHWzYEFIzRQ02gLRhWrZsGebNmyd+n5ubi5ycHMydO1e8LCkpCYmJiT1ezu7q6oLdbh/Uce3JkycDAI4dO+Yx2CQmJiIxMRFpaWmwWq246aab8Otf/7rP4+mDwSCR3qm1IXv27MHx48cRExPjcXlOTg5uuukm7Nu3r9fbTZ48Gb/5zW/Q0dGBsLAw3zasGzaE1E5xgw0gXZisViusVqv4vdlsRnx8PFJTUz2Wy8zMRGNjI4qKipCRkQHgYnRcLpc4rAxEcXExAHgdWFwuFwCgo6NjwPfbFwaJ6CI1NuThhx/GT3/6U4/Lrr76aqxbtw633357n+tUXFyM2NhYDjVE31HkYAPIe7w8PT0d2dnZWLx4MTZu3AiHw4H8/HzMnz9ffDdDdXU1ZsyYgddeew3XXXcdjh8/jjfeeAOzZ89GXFwcvvrqKyxfvhxTp07FNddcAwD429/+hrq6OvzLv/wLIiMjUVJSgl/+8pe44YYbMHr0aL/WmUEi8qS2hgiv5F5q1KhRGDNmDABgx44dqKurw/XXX4/w8HDs3r0bq1evxn/913/5vc5sCGmFYgcbQN4wbd26Ffn5+ZgxYwaMRiNycnKwfv168XqHw4Hy8nLxXU9DhgzBRx99hOeeew4XLlzAyJEjkZOTg5UrV4q3MZvN+N///V8sX74cHR0dGDlyJObOnYuHH37Yr3VlkIh6p6aGDERoaCj+9Kc/Yfny5XC73UhNTcXvf/97LF682K91ZUNISwzuAbxPsLm5GdHR0bDb7YiNjQ3GenkQ3sIpvKWTvqeUIG3atAlTpkzBgQMH4HQ6ZVkHUq6QkBBMmTIF6enpCAkJCfrPZ0P6ppSGFN5wA4a++CIuLF0KtLfLsg6kXBecTsw4fBhNTU2wWCxel1X0KzYCJb2NU0mUEiQipWNDeseGkBapYrABGKZLMUhEg8OGeGJDSKtUM9gADJOAQSLyDRtyERtCWqaqwQZgmBgkIv+wIWwIaZvqBhtAv2FikIgCgw1hQ0i7VDnYAPoLE4NEFFhsCBtC2qTawQbQT5gYJCJpsCFE2qPqwQbQfpgYJCJpsSFE2qL6wQbQbpgYJKLgYEOItEMTgw2gvTAxSETBxYYQaYNmBhtAO2FikIjkwYYQqZ+mBhtA/WFikIjkxYYQqZvmBhtAvWFikIiUgQ0hUi9NDjaA+sLEIBEpCxtCpE6aHWwA9YSJQSJSJjaESH00PdgAyg8Tg0SkbGwIkbpofrABlBsmBolIHdgQIvXQxWADKC9MDBKRurAhROqgm8EGUE6YGCQidWJDiJRPV4MNIH+YGCQidWNDiJRNd4MNIF+YGCQibWBDiJRLl4MNEPwwMUhE2sKGECmTbgcbIHhhYpCItIkNIVIeXQ82gPRhYpCItI0NIVIW3Q82gHRhYpCI9IENIVIODjbfCXSYGCQifWFDiJSBg003gQoTg0SkT2wIkfw42FzC3zAxSET6xoYQyYuDTS98DRODREQAG0LfO+tw4K0zZ1By4QK+bm1Fq8uFP11+OTKiogZ8H2c6O/GH06dReP48XG43MqKi8FByMi4LC+ux7Ptnz2JrXR1qOzsRP2QI5g0fjnkK+dtmwWKUewWUKj4+HvHx8Thz5owYJ28YJCLqjg0hADjZ3o7/r64O9Q4HxpnNg759q9OJB779Fl+0tODehAQsHjEC37S24v5vvkFTV5fHsu/W12N1VRXGms1YMXIkrh46FL8/fRqv2WyB2hxVkGWwsdvtyM3NhcViQUxMDPLy8tDS0uL1Nps2bUJWVhYsFgsMBgMaGxt7LPP0009jypQpiIiIQExMjN/rOdAwyREkqR7DH//4xxg1ahTCw8MxYsQI3H333aipqZFoK4h848v+397ejgceeABxcXGIjIxETk4O6urqPJapqqrCbbfdhoiICMTHx+OXv/wlui75j8dgKLkhbrcbjz/+OEaMGAGz2YyZM2fi22+/7fd2f/rTnzB69GiEh4dj8uTJOHjwoMf1S5cuxbhx42A2mzF8+HDMmTMHX3/9tVSboXhpERH4+zXXYNtVV2GBD6+cvF1fj1MdHXh23DjcnZiIBQkJ+MPll+Ocw4E3uu2/7S4XNtbU4AaLBc+MHYs7hg3DqtGjMSs2FpttNjT7sR+rjWSDTVZWFrZs2dLrdbm5uSgpKcHu3buxc+dO7N+/H0uWLPF6f62trcjOzsajjz7a5zKdnZ248847cf/99/uz6h76C5OUQZLjMZw+fTr+7//+D+Xl5Xj77bdx/Phx/Pu//7s/m0Hkk0Dv/8uXL8eOHTuwbds2fPLJJ6ipqcHcuXPF651OJ2677TZ0dnbiwIEDePXVV7FlyxY8/vjjfm2HnA3x5ne/+x3Wr1+PjRs3orCwEEOHDsWsWbPQ3t7e523eeustrFixAqtWrcIXX3yBa6+9FrNmzfLYroyMDGzevBllZWX4+9//DrfbjVtuuQVOpzMYm6U4Q0NCEG3y/ayPvY2NGB8RgfFDh4qXjQ4Px6SoKHzc7cnpF+fPo8npRM7w4R63//fhw9HmcuGzpiaf10Ftgn6OTVlZGXbt2oVDhw5h0qRJAIANGzZg9uzZWLt2LZKSknq93UMPPQQA2LdvX5/3/eSTTwJAnzH0VV/Hy+UKkpSP4fLly8X/n5KSgocffhh33HEHHA4HQkNDA7YNRL7yZf9vamrCyy+/jDfeeAM333wzAGDz5s1IT0/H559/juuvvx4ffvghSktL8dFHHyEhIQE/+MEP8Jvf/Aa/+tWv8MQTT/j1+620hrjdbjz33HNYuXIl5syZAwB47bXXkJCQgPfeew/z58/v9Xa///3vsXjxYixatAgAsHHjRvz1r3/FK6+8gocffhgAPAbM0aNH47e//S2uvfZaVFZWYty4cRJvmba43G4ca2vDv8bF9bhu/NChKDx/HhecTgwNCUF5ayuAi68QdZcWEQEjgG/a2nBrMFZaAYJ+KKqgoAAxMTFikABg5syZMBqNKCwsDPbqDNilz7rkPB4erMfQbrdj69atmDJlCocaUgxf9v+ioiI4HA7MnDlTvCwtLQ2jRo1CQUGBeL9XX301EhISxGVmzZqF5uZmlJSU+L3eSmpIRUUFbDabx+MRHR2NyZMni4/HpTo7O1FUVORxG6PRiJkzZ/Z5mwsXLmDz5s0YM2YMRo4cGdiN0IFmpxOdbjeG9dLfuO8uO+twAADOdXUhBID1kmVDjUZEm0zicnoQ9MHGZrP1eIeAyWSC1WqFTeEnOHUP07FjxwDIc5Kf1I/hr371KwwdOhRxcXGoqqrCX/7yF7/vkyhQfNn/bTYbhgwZ0uPcu4SEBPE2NpvNY6gRrheuCwQlNQRAr9vb17aePXsWTqdzQLd5/vnnERkZicjISHzwwQfYvXs3T4b2QYfLBQAINRh6XBf23WXCMh0uF0y9LAcAQwwGcTk9CNhgs3r1anFHjoyMxKeffoply5Z5XFZVVRWoHyebmJgYGI1GuFwuWCyWgP6yKuUx/OUvf4kvv/wSH374IUJCQnDPPffA7XZL/nNJ35Sy/0tNyob0ZevWrR6Po0PiZ++5ubn48ssv8cknn+CKK67AvHnzvJ67owUOlwvnHA6PL6ef3QwzXvxPtKOX++n47jJhmTCjEV19/LxOt1tcTg8Cdo7NsmXLMG/ePPH73Nxc5OTkeJycl5SUhMTExB4n0HV1dcFutyMxMTFQqyMJ4aXjkJAQxMbG4ty5cwgJCQnY34VRymM4bNgwDBs2DFdccQXS09MxcuRIfP7558jMzPT7von6IuX+n5iYiM7OTjQ2Nnq8alNXVyfeJjExscc7fIR3TQWqTVI3pC8//vGPMXnyZPH7jo4OABe3b8SIEeLldXV1+MEPftDrfQwbNgwhISE93knW/TEUREdHIzo6Gpdffjmuv/56xMbG4t1338WCBQsCtEXK89WFC3jgkneVvXPVVUjq5bNmBsoSEoIhBkOvh5HOfXeZcJgqzmSCE4Dd4fA4HOVwudDU1dXr4SytCthgY7VaYbVaxe/NZjPi4+ORmprqsVxmZiYaGxtRVFSEjIwMAMCePXvgcrk8fvGUprfj4SEhIQH9o3dKfAxdwsuc34WQSCpS7v8ZGRkIDQ3Fxx9/jJycHABAeXk5qqqqxIE9MzMTTz/9NM6cOSP+Pu/evRsWiwXjx4/3e/uC0ZC+REVFIarbB8K53W4kJibi448/FgeZ5uZmFBYW9vmu0iFDhiAjIwMff/wx7rjjDgAX+/Dxxx8jPz+/z5/tdrvhdrs135DLzWasv2RfjfNzmDAaDBhnNuPr704M7q7kwgVcNmQIhoaEAACu+O6k4a9bWzElOlpcrqy1FS4AV/jwGTpqFfTXptLT05GdnY3Fixfj4MGD+Oyzz5Cfn4/58+eL72aorq5GWlqax7Mnm82G4uJi8bj0kSNHUFxcDLvdLi5TVVWF4uJiVFVVwel0ori4GMXFxf1+vkV/+jrJb7AfwBUoUj2GhYWF+OMf/4ji4mKcPHkSe/bswYIFCzBu3Di+WkOK4cv+Hx0djby8PKxYsQJ79+5FUVERFi1ahMzMTFx//fUAgFtuuQXjx4/H3XffjcOHD+Pvf/87Vq5ciQceeABhfjzrBpTXEIPBgIceegi//e1v8f777+PIkSO45557kJSUJA4tADBjxgz88Y9/FL9fsWIF/vd//xevvvoqysrKcP/99+PChQviu6ROnDiBZ555BkVFRaiqqsKBAwdw5513wmw2Y/bs2UHbPjlYTCZcZ7F4fA328I+tsxOVlxyymx4Tg9LWVpRduCBedrK9HUXnz+Pm2FjxsoyoKFhCQvB2fb3H7d85exbhRqPHsKN1svxJha1btyI/Px8zZsyA0WhETk4O1q9fL17vcDhQXl6O1m5T6saNG8W3cwPA1KlTAVx8y+Z9990HAHj88cfx6quvistMnDgRALB3715kZWX5tK79vXMh0H/Rd6CkeAwjIiLwzjvvYNWqVbhw4QJGjBiB7OxsrFy50u+wEwWSL/v/unXrxGU7Ojowa9YsPP/88+L1ISEh2LlzJ+6//35kZmZi6NChuPfee/HUU0/5ta5Kbch///d/48KFC1iyZAkaGxtx4403YteuXQgPDxeXOX78OM6ePSt+/x//8R+or6/H448/DpvNhh/84AfYtWuXeEJxeHg4Pv30Uzz33HNoaGhAQkICpk6digMHDgRtu5ToldpaAEDFd0PLLrsdh797wv2TbocCn6ysxJctLfj8hz8UL8sZPhzvnzuHFcePIzchASaDAX+uq4M1NBR3dXtMw41GLElKwtpTp/DoiROYbLHgcEsLdtntWJaU5Ndn6aiNwT2As0Kbm5sRHR0Nu92O2G4TotYN5u2YwjMu4RmY3mzatAlTpkzBgQMHdPtBXNS3kJAQTJkyBenp6Qj57qVzPWBDBq7whhsw9MUXcWHpUkBjJxpf/8UXfV7XfYi5/5tvegw2wMW/FfXc6dMobG6GG8DEyEg8lJyMkd2GUMF7Z8/iz3V1qOnsRMKQIfj34cPxH8OHw9DHO6bU4oLTiRmHD6OpqQkWi8XrsvoZ4QZpsJ8xIdezLiJSJjaEBJcOKn154Yorer08fsgQrB47dkD3ccewYbhj2LABr5sWcbDpha8fnMUwERHAhhDJiYPNJfz9NFCGiUjf2BAieXGw6SZQH3HOMBHpExtCJD8ONt8J9N9tYZiI9IUNIVIGDjaQ7i/sMkxE+sCGECmH7gcbqf/CLsNEpG1sCJGy6HqwkTpIAoaJSJvYECLl0e1gE6wgCRgmIm1hQ4iUSZeDTbCDJGCYiLSBDSFSLt0NNnIFScAwEakbG0KkbLoabOQOkoBhIlInNoRI+XQz2CglSAKGiUhd2BAiddDFYKO0IAkYJiJ1YEOI1EPzg41SgyRgmIiUjQ0hUhdNDzZKD5KAYSJSJjaESH00O9ioJUgCholIWdgQInXS5GCjtiAJGCYiZWBDiNRLc4ONWoMkYJiI5MWGEKmbpgYbtQdJwDARyYMNIVI/zQw2WgmSgGEiCi42hEgbNDHYaC1IAoaJKDjYECLtUP1go9UgCRgmImmxIUTaourBRutBEjBMRNJgQ4i0R7WDjV6CJGCYiAKLDWFDSJtUOdjoLUgChokoMNgQNoS0S3WDjV6DJGCYiPzDhrAhpG2qGmz0HiQBw0TkGzbkIjaEtEw1gw2D5IlhIhocNsQTG0JapYrBhkHqHcNENDBsSO/YENIio9wr0B+5gmS325GbmwuLxYKYmBjk5eWhpaXF6202bdqErKwsWCwWGAwGNDY29lhm9OjRMBgMHl//8z//4/N6xsfHIz4+HmfOnBHjRETfk6shXV1dOHXqFEpLS1FaWorTp0/D6XR6vY3L5UJNTQ3KyspQWlqKqqoqdHV1eSzT2dmJyspKlJSUoKysDDabDW632+f1ZENIaxQ92EgdpKysLGzZsqXX63Jzc1FSUoLdu3dj586d2L9/P5YsWeL1/lpbW5GdnY1HH33U63JPPfUUamtrxa+f//znvm4CAIaJqC9SN+TEiRNoaGjo9brTp0+jo6MDo0ePRkpKClpbW1FTU+P1/mw2G86fP4+RI0dizJgxcDgcqKqqEq93u904efIk3G43xo4di+TkZDQ0NKCurs6v7WBDSEsUeyhKzpeOy8rKsGvXLhw6dAiTJk0CAGzYsAGzZ8/G2rVrkZSU1OvtHnroIQDAvn37vN5/VFQUEhMTA7nKfEmZ6BJyNqS9vR0tLS0YN24czGYzAGDEiBE4efIkEhMTERoa2uM2TqcTDQ0NSE5ORmRkJAAgOTkZ3377LVpbWxEREYGWlhZ0dHRgzJgxMJku5jshIQE2mw3x8fEwGn1/rsqGkFYo8hUbuY+HFxQUICYmRhxqAGDmzJkwGo0oLCz0+/7/53/+B3FxcZg4cSLWrFnT46VmX/FZF9FFcjekra0NRqNRHGoAiMNKW1tbn7dxu93icgAQFhaG0NBQtLa2Arj4qnB4eLg41Aj363K50NHR4fd6syGkBYp7xUbuIAEQn/10ZzKZYLVaYbPZ/LrvBx98ED/84Q9htVpx4MABPPLII6itrcXvf/97v+5XwGddpHdKaIjD4fAYPgDAYDAgJCQEDoej19t0dXWJy3RnMpnEJz9dXV097lf4PpBPkAA2hNRLUYON1EFavXo1Vq9eLX7f1taGzz//HPn5+eJlpaWlAf2Zl1qxYoX4/6+55hoMGTIES5cuxTPPPIOwsLCA/AyGifRK6oacOXMGZ8+eFb93uVxoa2tDbW2teFlqampAf6Yc2BBSM8UMNsF4lrVs2TLMmzdP/D43Nxc5OTmYO3eueFlSUhISExN7vAzb1dUFu90e8HNjJk+ejK6uLlRWVuLKK68M2P0yTKQ3wWiI1WpFdHS0+P3p06dhsVhgsVjEy0JDQxEaGtrjFRS32w2n09nr+TXAxVdehGW6v2rT/VUak8nU41CW8HMufSXHX2wIqZUiBptgvXRstVphtVrF781mM+Lj43s8w8rMzERjYyOKioqQkZEBANizZw9cLhcmT54c0HUqLi6G0WiUJBoME+lFsBpiMpk8BgiDwQCTydTj1Vaz2Sy+miOcZyN8XET3824uvY3BYEBLS4s4PHV0dMDhcCAiIgIAEBERgfr6eo9hp6WlBUajMWCv+HbHhpAayT7YKOF4+KXS09ORnZ2NxYsXY+PGjXA4HMjPz8f8+fPFd0RVV1djxowZeO2113DdddcBuHhujs1mw7FjxwAAR44cQVRUFEaNGgWr1YqCggIUFhZi+vTpiIqKQkFBAZYvX46FCxciNjZWkm1hmEjrlNiQ8PBwREZGorq6GklJSXC73aitrUV0dLT4io3D4UBFRQWSk5MRERGBkJAQxMbGwmazISQkBCEhIaipqYHZbBYHm8jISISFheH06dNISEhAV1cX6urqYLVa/XpHlDdsCKmNrIONEoMk2Lp1K/Lz8zFjxgwYjUbk5ORg/fr14vUOhwPl5eXiuxUAYOPGjXjyySfF76dOnQoA2Lx5M+677z6EhYXhzTffxBNPPCG+ZXP58uUe591IgWEirVJyQ5KTk1FbW4vKykoAgMViwYgRI8Tr3W43Ojs74XK5xMuEQ92nTp2Cy+VCVFSUx20MBgNSUlJQU1ODEydOwGg0IiYmBgkJCZJuCxtCamJwD+AjK5ubmxEdHQ273R6wVxaUHCStEt7CKbylM5A2bdqEKVOm4MCBA/1+uirpT0hICKZMmYL09PQe7/rxFRsSfFI2pPCGGzD0xRdxYelSoL09oPdN6nfB6cSMw4fR1NTkcU5bb2R5xYZBkgefdZFWsCHyYENIDYI+2DBI8mKYSO3YEHmxIaR0QR1sGCRlYJhIrdgQZWBDSMmCNtgwSMrCMJHasCHKwoaQUgVlsGGQlIlhIrVgQ5SJDSElknywYZCUjWEipWNDlI0NIaWRdLBhkNSBYSKlYkPUgQ0hJZFssGGQ1IVhIqVhQ9SFDSGlkGSwYZDUiWEipWBD1IkNISUI+GDDIKkbw0RyY0PUjQ0huQV0sGGQtIFhIrmwIdrAhpCcAjbYMEjawjBRsLEh2sKGkFwCMtgwSNrEMFGwsCHaxIaQHPwebBgkbWOYSGpsiLaxIRRsfg02DJI+MEwkFTZEH9gQCiafBxsGSV8YJgo0NkRf2BAKFp8GGwZJnxgmChQ2RJ/YEAqGQQ82DJK+MUzkLzZE39gQktqgBhuHw8EgEcNEPnM4HDh58iQANkTP2BCS0qAGm1OnTiEyMpJBoh5hIhoIDjUkYENIKoM+FMUgkaB7mK688kqZ14aULDY2Vvz/bAgJujck7Gc/k3ltSNG6NaQ/gxps4uPjERISAqfTOeh1Im2Ki4tDc3Mz4uLiAAAhISEyrxEpzZAhQ5CWlgYASExMZEPIg9CQ9muvvXhBeLi8K0SKY4iNRfiyZcC+fQNb3u12u/tbqLm5GdHR0SgoKEBkZKS/60hEREQ0YC0tLcjMzERTUxMsFovXZQf1ik1oaChCQ0ORkpKC0NBQv1aS1O/s2bOor6/H8OHDERsbi2+++QYAMHz4cAwbNkzmtSO5dT9RODk5GRUVFWI32BAC2BDyrntDxo4dO+DbDWqwGTlyJBoaGnDy5EkeJ9e5M2fOoL6+HvHx8YiPjxcPLQwfPhz19fUwGAx8p4OOdXZ2epwoLByiTElJwcmTJ9kQYkPIq0sb0t7ePuDbGgfzg0JDQzFmzBgAQEVFBTo7Owdzc9KIM2fO4MyZM2KQuhs2bBji4+PFZUh/vH1ODRtCABtC3vn7WVeDGmyAiycCMkz65S1IAuE6hkl/BhIkNkTf2BDyJhAf4DnowQZgmPRqIEESMEz6M5ggsSH6xIaQN4H6VHKfBhuAYdKbwQRJwDDphy9BYkP0hQ0hbwL5p1Z8HmwAhkkvfAmSgGHSPn+CxIboAxtC3gT678f5NdgADJPW+RMkAcOkXYEIEhuibWwIeSPFH8X1e7ABGCatCkSQBAyT9gQySGyINrEh5I0UQw0QoMEGYJi0JpBBEjBM2iFFkNgQbWFDyBuphhoggIMNwDBphRRBEjBM6idlkNgQbWBDyBspGwIEeLABGCa1kzJIAoZJvaQOEsCGqB0bQt4EoyEBH2wAhkmtghEkAcOkPsEIkoANUSc2hLwJVkMkGWwAhkltghkkAcOkHsEcagRsiLqwIeRNMBsi2WADMExqIUeQBAyT8skx1AjYEHVgQ8ibYDdE0sEGYJiUTs4gCRgm5ZJzqBGwIcrGhpA3cjRE8sEGYJiUSglBEjBMyqOEoUbAhigTG0LeyNWQoAw2AMOkNEoKkoBhUg4lDTUCNkRZ2BDyRs6GBG2wARgmpVBikAQMk/yUONQI2BBlYEPIG7kbEtTBBmCY5KbkIAkYJvnIHaSBYEPkxYaQN0poSNAHG4BhkosagiRgmIJPCUEaKDZEHmwIeaOUhsgy2ADKD5Pdbkdubi4sFgtiYmKQl5eHlpaWAd3W7Xbj1ltvhcFgwHvvvSdefvjwYSxYsAAjR46E2WxGeno6/vCHP0i0BZ7UFCSBksPU1dWFU6dOobS0FKWlpTh9+jScTqfX27hcLtTU1KCsrAylpaWoqqpCV1eXxzKdnZ2orKxESUkJysrKYLPZ4Ha7pdwU8ecqIUiDofSGaG0fYUMCS2v7h5IaIttgA8gfpqysLGzZsqXX63Jzc1FSUoLdu3dj586d2L9/P5YsWTKg+33uuedgMBh6XF5UVIT4+Hi8/vrrKCkpwWOPPYZHHnkEf/zjH/3ZjH6pMUgCOcN04sQJNDQ09Hrd6dOn0dHRgdGjRyMlJQWtra2oqanxen82mw3nz5/HyJEjMWbMGDgcDlRVVYnXu91unDx5Em63G2PHjkVycjIaGhpQV1cX0O26lJKCNFhyN0Qv+wgb4hu97B9Ka4isgw0gf5h6U1ZWhl27duGll17C5MmTceONN2LDhg148803+93xiouL8eyzz+KVV17pcd1PfvIT/OEPf8C0adMwduxYLFy4EIsWLcI777wj1aaoOkgCpT3ram9vR0tLCy677DJERERg6NChGDFiBJqamuBwOHq9jdPpRENDAxITExEZGQmz2Yzk5GS0traitbUVANDS0oKOjg7xFb2oqCgkJCTAbrfD5XJJsi1KC5IvlNgQLe0jbEjgaWn/UGJDZB9sAOWFqaCgADExMZg0aZJ42cyZM2E0GlFYWNjn7VpbW3HXXXfhT3/6ExITEwf0s5qammC1Wv1e595oIUgCJYWpra0NRqMRZrNZvCwyMlK8rq/buN1ucTkACAsLQ2hoqBil1tZWhIeHw2Qyedyvy+VCR0dHwLdDiUHyldIaopV9hA2Rhlb2D6U2RBGDDaCsMNlsth6/xCaTCVarFTabrc/bLV++HFOmTMGcOXMG9HMOHDiAt956a8CHuAZDS0ESKCVMDofDIxwAYDAYEBIS0uezra6uLnGZ7kwmk3iMvKurq8f9Ct9fehzdX0oNkj+U1BAt7CNsiHS0sH8ouSGm/hcJHiFMFRUVqKioCPiDtXr1aqxevVr8vq2tDZ9//jny8/PFy0pLS3267/fffx979uzBl19+OaDljx49ijlz5mDVqlW45ZZbfPqZfdFikATC9ghRCuT2nTlzBmfPnhW/d7lcaGtrQ21trXhZampqwH6eXJQcJH9J3RC97CNsiG/0sn8ovSGKGmwAacO0bNkyzJs3T/w+NzcXOTk5mDt3rnhZUlISEhMTe0zzXV1dsNvtfR5i2rNnD44fP46YmBiPy3NycnDTTTdh37594mWlpaWYMWMGlixZgpUrV/q/Yd1oOUgCqcJktVoRHR0tfn/69GlYLBZYLBbxstDQUISGhvZ49uN2u+F0OhEaGtrrfZtMJnGZ7s+4uj/DMplMPV6GFn7Opc/CfKX0IAWClA3Rwz7ChvhOD/uHGhqiuMEGkC5MVqvV43wWs9mM+Pj4HhN0ZmYmGhsbUVRUhIyMDAAXBxeXy4XJkyf3et8PP/wwfvrTn3pcdvXVV2PdunW4/fbbxctKSkpw8803495778XTTz/t9zZ1p4cgCaQIk8lk8vjlNxgMMJlMCAsL81jObDaLz8SEY+TCRwF0P2Z+6W0MBgNaWlrE8HV0dMDhcCAiIgIAEBERgfr6eo9QtbS0wGg09lgHX6ghSIEiVUO0vo+wIf7R+v6hloYo5hybS8l5vDw9PR3Z2dlYvHgxDh48iM8++wz5+fmYP38+kpKSAADV1dVIS0vDwYMHAQCJiYmYMGGCxxcAjBo1StyOo0ePYvr06bjllluwYsUK2Gw22Gw21NfX+73OegqSQK7j5eHh4YiMjER1dTVaW1tx4cIF1NbWIjo6Wny25XA48M0334gn9YWEhCA2NhY2mw0tLS1oa2vD6dOnYTabxShFRkYiLCwMp0+fRltbG86fP4+6ujpYrVYYjf79qqolSIEkZ0PUuI+wIWyIN2pqiCJfsRFIfbzcm61btyI/Px8zZsyA0WhETk4O1q9fL17vcDhQXl4u7nQDsX37dtTX1+P111/H66+/Ll6ekpKCyspKn9dVj0ESSHm83Jvk5GTU1taK/24WiwUjRowQr3e73ejs7PR4i6VwGPPUqVNwuVyIioryuI3BYEBKSgpqampw4sQJGI1GxMTEICEhwa91VVOQAk3OhqhpH2FD2BBv1NYQg3sAH0nY3NyM6Oho2O12xMbGBmO9PKjtQQ0mpQTJ6XSirKwM6enpPc7aDwalPA5Ko5TfHbn3D6U8DkqklN8dufcRpTwOSqOU3x1hDmlqavI4Z6k3ij0U1Z2S3sapJPxF/J5S3sapJEoJkhKwIb1jQ77HhvSk1oaoYrABGKZLMUg9MUzfU2uQpMSGeGJDemJDvqfmhqhmsAEYJgGD1DeGSd1BkhobchEb0jc2RP0NUdVgAzBMDFL/9BwmtQcpGNgQNqQ/bIi6G6K6wQbQb5gYpIHTY5i0EKRgYUPYkP6wIeptiCoHG0B/YWKQBk9PYdJKkIKJDaH+sCHqpNrBBtBPmBgk3+khTFoKUrCxIdQfNkR9VD3YANoPE4PkPy2HSWtBkgMbQv1hQ9RF9YMNoN0wMUiBo8UwaTFIcmFDqD9siHpoYrABtBcmBinwtBQmrQZJTmwI9YcNUQfNDDaAdsLEIElHC2HScpDkxoZQf9gQ5dPUYAOoP0wMkvTUHCatB0kJ2BDqDxuibJobbAD1holBCh41hkkPQVIKNoT6w4YolyYHG0B9YWKQgk9NYdJLkJSEDaH+sCHKpNnBBlBPmBgk+aghTHoKktKwIdQfNkR5ND3YAMoPE4MkPyWHSW9BUiI2hPrDhiiL5gcbQLlhYpCUQ4lh0mOQlIoNof6wIcqhi8EGUF6YGCTlUVKY9BokJWNDqD9siDLoZrABlBMmBkm5lBAmPQdJ6dgQ6g8bIj9dDTaA/GFikJRPzjDpPUhqwIZQf9gQeelusAHkCxODpB5yhIlBUg82hPrDhshHl4MNEPwwMUjqE8wwMUjqw4ZQf9gQeeh2sAGCFyYGSb2CESYGSb3YEOoPGxJ8uh5sAOnDxCCpn5RhYpDUjw2h/rAhwaX7wQaQLkwMknZIESYGSTvYEOoPGxI8HGy+E+gwMUjaE8gwMUjaw4ZQf9iQ4OBg002gwsQgaVcgwsQgaRcbQv1hQ6THweYS/oaJQdI+f8LEIGkfG0L9YUOkxcGmF76GiUHSD1/CxCDpBxtC/WFDpMPBpg+DDRODpD+DCRODpD9sCPWHDZGGLION3W5Hbm4uLBYLYmJikJeXh5aWFq+3aW9vxwMPPIC4uDhERkYiJycHdXV1vS577tw5JCcnw2AwoLGx0ef1HGiY5AiSVI9hVVUVbrvtNkRERCA+Ph6//OUv0dXVJeWm9MqX7du0aROysrJgsVi8/tv/9a9/xeTJk2E2mxEbG4s77rjD5/UcSJjkCFJXVxdOnTqF0tJSlJaW4vTp03A6nV5v43K5UFNTg7KyMpSWlqKqqqrHv31nZycqKytRUlKCsrIy2Gw2uN1uKTelV2rZ/5XcEK3vI2rZPjYk8PuHZINNVlYWtmzZ0ut1ubm5KCkpwe7du7Fz507s378fS5Ys8Xp/y5cvx44dO7Bt2zZ88sknqKmpwdy5c3tdNi8vD9dcc42/mwCg/zBJGaRgP4ZOpxO33XYbOjs7ceDAAbz66qvYsmULHn/88UBulijQ29fa2ors7Gw8+uijfS7z9ttv4+6778aiRYtw+PBhfPbZZ7jrrrv82QyvYZIySCdOnEBDQ0Ov150+fRodHR0YPXo0UlJS0NraipqaGq/3Z7PZcP78eYwcORJjxoyBw+FAVVWVeL3b7cbJkyfhdrsxduxYJCcno6Ghoc8nGP7Syv4vZ0O0vo9oZfvYkADvH+4BaGpqcgNw2+32gSzudrvd7mnTprk3b97c4/LS0lI3APehQ4fEyz744AO3wWBwV1dX93pfjY2N7tDQUPe2bdvEy8rKytwA3AUFBR7LPv/88+5p06a5P/74YzcAd0NDw4DX2ZuOjg73119/7f7666/dHR0dbrfb7a6rq3MfOXLEXVdXF5CfcalgP4Z/+9vf3Eaj0W2z2cRlXnjhBbfFYhG3uS9dXV3uI0eOuLu6umTZvu727t3b67+9w+FwX3bZZe6XXnppwOs4GJfuD73tM4F0/PjxXn8n29ra3EeOHHG3traKlzU3N7uPHDni7uzs7PW+urq63EePHnU3NjaKl7W3t7uPHDnivnDhgsd9OBwOcZlz5865S0pK3E6n0+u6yr1/SL3/D4QcDdH6PqKm7RsINqRvwhzS1NTU73YF/VBUQUEBYmJiMGnSJPGymTNnwmg0orCwsNfbFBUVweFwYObMmeJlaWlpGDVqFAoKCsTLSktL8dRTT+G1116D0RjYTbv0WVdtba1sx8OlegwLCgpw9dVXIyEhQVxm1qxZaG5uRklJiURb05Mv2zcQX3zxBaqrq2E0GjFx4kSMGDECt956K44ePRqI1fZ41lVbWyvb8fC2tjYYjUaYzWbxssjISPG6vm7jdrvF5QAgLCwMoaGhaG1tBXDxFbHw8HCYTCaP+3W5XOjo6JBiU3ql1v1fSQ3R+j6i1u1jQwIj6IONzWbr8UtsMplgtVphs9n6vM2QIUMQExPjcXlCQoJ4m46ODixYsABr1qzBqFGjJFl3IUxOpxPnzp1DXFycLCf5SfUY2mw2j6gL1wvXBYsv2zcQJ06cAAA88cQTWLlyJXbu3InY2FhkZWXBbrf7tc6C+Ph4xMXF4dy5c3A6nbKc5OdwODzCAQAGgwEhISFwOBy93qarq0tcpjuTySQeI+/q6upxv8L3wTwPS837v1IaovV9RM3bx4b4z9T/IgOzevVqrF69Wvy+ra0Nn3/+OfLz88XLSktLA/XjenjkkUeQnp6OhQsXSvYzAKCxsREulwtGoxHNzc2Ii4sL2E4n92MoNbm3z+VyAQAee+wx5OTkAAA2b96M5ORkbNu2DUuXLvX7Z3R2dqK5uRlGoxEulwuNjY0B+w/XmTNncPbsWfF7l8uFtrY21NbWipelpqYG5GfJQe79I1ikbIjW9xGtbx/AhgRCwAabZcuWYd68eeL3ubm5yMnJ8Tg5LykpCYmJiT1Ojurq6oLdbkdiYmKv952YmIjOzk40NjZ6POOqq6sTb7Nnzx4cOXIE27dvBwDxLOthw4bhsccew5NPPun3NnY/yS8mJgYVFRWoqKgI2EQt92OYmJiIgwcPetxOOKmrr/sdDCm3byBGjBgBABg/frx4WVhYGMaOHetxgpuvup/kl5qaisbGRnE7AhEmq9WK6Oho8fvTp0/DYrHAYrGIl4WGhiI0NLTHsx+32w2n04nQ0NBe79tkMonLdH/G1f0Zlslk6vEytPBzLn0W5gut7/+A9A3R+j6i9e1jQwIjYIeirFYrUlNTxS+z2Yz4+HiPy0wmEzIzM9HY2IiioiLxtnv27IHL5cLkyZN7ve+MjAyEhobi448/Fi8rLy9HVVUVMjMzAVx8t8vhw4dRXFyM4uJivPTSSwCATz/9FA888IDf23fpOxek+KN3cj+GmZmZOHLkiMd/NHbv3g2LxeIxDChx+wYiIyMDYWFhKC8vFy9zOByorKxESkqKX9vW2zsXAv1H70wmE8LCwsQvg8HQ62Vms1l8JiYQ3grd/Zh5d2azGQaDweMt0x0dHXA4HIiIiAAAREREoL293SN4LS0tMBqNCAsL83v7tL7/B6MhWt9HtLx9bIj/+4cg6OfYpKenIzs7G4sXL8bBgwfx2WefIT8/H/Pnz0dSUhIAoLq6GmlpaeKzp+joaOTl5WHFihXYu3cvioqKsGjRImRmZuL6668HAIwbNw4TJkwQv4RgpKen+z3p9vV2TKn+om9/pHoMb7nlFowfPx533303Dh8+jL///e9YuXIlHnjggYDudFJsH3DxPIji4mIcO3YMAHDkyBEUFxeL589YLBYsW7YMq1atwocffojy8nLcf//9AIA777zT5/X19nZMKf6ib3/Cw8MRGRmJ6upqtLa24sKFC6itrUV0dLT4bMvhcOCbb74RT+oLCQlBbGwsbDYbWlpa0NbWhtOnT8NsNotRioyMRFhYGE6fPo22tjacP38edXV1sFqtAT9Z3xs17v9Ka4jW9xG1bR8bEtj9I3Cv/QzC1q1bkZ+fjxkzZsBoNCInJwfr168Xr3c4HCgvLxcfMABYt26duGxHRwdmzZqF559/XvJ17e8zJoQwBfol5f5I8RiGhIRg586duP/++5GZmYmhQ4fi3nvvxVNPPSX59lzKl+3buHGjxyHHqVOnArh4Hs19990HAFizZg1MJhPuvvtutLW1YfLkydizZw9iY2N9Ws+BfMaEsN8E8iXl/iQnJ6O2thaVlZUALg51wqE44OLLyp2dneJ5R8D3h1tOnToFl8uFqKgoj9sYDAakpKSgpqYGJ06cgNFoRExMTI8TboNBTfu/Uhui9X1ELdvHhgR+/zC43f1/5F9zczOio6Nht9t9/g+AGg3mg7P0/nHXTqcTZWVlSE9P73FWvFYN9t9czx+Zr8f9A2BDBkOP+wgbMnDCHNLU1ORxTlBv+Lei+jDYHUiul5RJHr78R0iOl5RJPmwIecOGSIeDTS98nYoZJn3w55k1w6QPbAh5w4ZIi4PNJfx9qY9h0rZAHC5gmLSNDSFv2BDpcbDpJlDHLxkmbQrkORAMkzaxIeQNGxIcHGy+E+iTshgmbZHixE6GSVvYEPKGDQkeDjaQ7kxzhkkbpHy3CsOkDWwIecOGBJfuBxup3z7HMKlbMN6CyzCpGxtC3rAhwafrwSZYnwnAMKlTMD9XhGFSJzaEvGFD5KHbwSbYH3TEMKmLHB+WxjCpCxtC3rAh8tHlYCPXpzcyTOog5yfAMkzqwIaQN2yIvHQ32Mj9kdQMk7Ip4WPtGSZlY0PIGzZEfroabOQOkoBhUiYlBEmg9zApFRtC3rAhyqCbwUYpQRIwTMqipCAJ9BwmJWJDyBs2RDl0MdgoLUgChkkZlBgkgV7DpDRsCHnDhiiL5gcbpQZJwDDJS8lBEugxTErChpA3bIjyaHqwUXqQBAyTPNQQJIHewqQUbAh5w4Yok2YHG7UEScAwBZeagiTQU5iUgA0hb9gQ5dLkYKO2IAkYpuBQY5AEegmT3NgQ8oYNUTbNDTZqDZKAYZKWmoMk0EOY5MSGkDdsiPJparBRe5AEDJM0tBAkgdbDJBc2hLxhQ9RBM4ONVoIkYJgCS0tBEmg5THJgQ8gbNkQ9NDHYaC1IAoYpMLQYJIFWwxRsbAh5w4aoi+oHG60GScAw+UfLQRJoMUzBxIaQN2yI+qh6sNF6kAQMk2/0ECSB1sIULGwIecOGqJNqBxu9BEnAMA2OnoIk0FKYgoENYUO8YUPU2xBVDjZ6C5KAYRoYPQZJoJUwSY0NYUO8YUPU3RDVDTZ6DZKAYfJOz0ESaCFMUmJD2BBv2BD1N0RVg43egyRgmHrHIH1P7WGSChtyERvSOzbke2puiGoGGwbJE8PkiUHqSc1hkgIb4okN8cSG9KTWhqhisJEjSHa7Hbm5ubBYLIiJiUFeXh5aWlq83qa9vR0PPPAA4uLiEBkZiZycHNTV1Xksc+jQIcyYMQMxMTGIjY3FrFmzcPjwYZ/WkWG6SI4gdXV14dSpUygtLUVpaSlOnz4Np9Pp9TYulws1NTUoKytDaWkpqqqq0NXV5bFMZ2cnKisrUVJSgrKyMthsNrjdbp/XU61hCjQ5GqKGfYQNuYgN6ZsaG6L4wUbKIGVlZWHLli29Xpebm4uSkhLs3r0bO3fuxP79+7FkyRKv97d8+XLs2LED27ZtwyeffIKamhrMnTtXvL6lpQXZ2dkYNWoUCgsL8Y9//ANRUVGYNWsWHA6HT9ug9zBJGaQTJ06goaGh1+tOnz6Njo4OjB49GikpKWhtbUVNTY3X+7PZbDh//jxGjhyJMWPGwOFwoKqqSrze7Xbj5MmTcLvdGDt2LJKTk9HQ0NBjOB4sNYYpkKRsiBb2ETaEDemP2hqi6MFGrpeOy8rKsGvXLrz00kuYPHkybrzxRmzYsAFvvvlmnzteU1MTXn75Zfz+97/HzTffjIyMDGzevBkHDhzA559/DgD4+uuvYbfb8dRTT+HKK6/EVVddhVWrVqGurg4nT570eX31Gia5Xjpub29HS0sLLrvsMkRERGDo0KEYMWIEmpqa+hxQnU4nGhoakJiYiMjISJjNZiQnJ6O1tRWtra0ALg6+HR0dGDlyJMxmM6KiopCQkAC73Q6Xy+XXOqstTIEiV0PUto+wIWxIf9TUEMUONnIeDy8oKEBMTAwmTZokXjZz5kwYjUYUFhb2epuioiI4HA7MnDlTvCwtLQ2jRo1CQUEBAODKK69EXFwcXn75ZXR2dqKtrQ0vv/wy0tPTMXr0aL/WWW9hkvN4eFtbG4xGI8xms3hZZGSkeF1ft3G73eJyABAWFobQ0FAxSq2trQgPD4fJZPK4X5fLhY6ODr/XW01hCgQ5G6LGfYQNYUP6o5aGKHKwkfskP5vN1uPnmkwmWK1W2Gy2Pm8zZMgQxMTEeFyekJAg3iYqKgr79u3D66+/DrPZjMjISOzatQsffPCBx47oK72ESe6T/BwOR49/L4PBgJCQkD6fbXV1dYnLdGcymcRj5F1dXT3uV/j+0uPovlJLmPwld0PUuo+wIcGh1v0DUEdD/P+vaYBJGaTVq1dj9erV4vdtbW34/PPPkZ+fL15WWloa0J/ZXVtbG/Ly8nDDDTfgz3/+M5xOJ9auXYvbbrsNhw4d8pjefSWEqaKiAhUVFZo7u1/KIJ05cwZnz54Vv3e5XGhra0Ntba14WWpqasB+nlyE3yshSlp7h5CUDdHDPsKG+E4P+weg/IYoarCR+lnWsmXLMG/ePPH73Nxc5OTkeJzgm5SUhMTExB6TaFdXF+x2OxITE3u978TERHR2dqKxsdHjVZu6ujrxNm+88QYqKytRUFAAo9EoXhYbG4u//OUvmD9/fkC2U6thkvpZltVqRXR0tPj96dOnYbFYYLFYxMtCQ0MRGhra49mP2+2G0+lEaGhor/dtMpnEZbo/4+r+DMtkMvV4GVr4OYF4Ra87pYfJV1I3RC/7CBviG73sH4CyG6KYQ1HBeOnYarUiNTVV/DKbzYiPj/e4zGQyITMzE42NjSgqKhJvu2fPHrhcLkyePLnX+87IyEBoaCg+/vhj8bLy8nJUVVUhMzMTwMXjn0ajEQaDQVxG+N7fE7supbWXlIPx0rHJZEJYWJj4ZTAYer3MbDaLz8QEwkcB9PWqm9lshsFg8PjIgI6ODjgcDkRERAAAIiIi0N7e7hG8lpYWGI1GhIWFBXx71fCS8mAEoyF62kfYkMHT0/4BKLchihhs5D4efqn09HRkZ2dj8eLFOHjwID777DPk5+dj/vz5SEpKAgBUV1cjLS0NBw8eBABER0cjLy8PK1aswN69e1FUVIRFixYhMzMT119/PQDgRz/6ERoaGvDAAw+grKwMJSUlWLRoEUwmE6ZPnx7w7dBKmOQ+Hn6p8PBwREZGorq6Gq2trbhw4QJqa2sRHR0tPttyOBz45ptvxJP6QkJCEBsbC5vNhpaWFrS1teH06dMwm81ilCIjIxEWFobTp0+jra0N58+fR11dHaxWq/gKX6ApNUyDpbSGaGUfYUOkoZX9A1BmQ2Q/FKW0IAm2bt2K/Px8zJgxA0ajETk5OVi/fr14vcPhQHl5ubjTAcC6devEZTs6OjBr1iw8//zz4vVpaWnYsWMHnnzySWRmZsJoNGLixInYtWsXRowYIcl2qP0lZaUFSZCcnIza2lpUVlYCACwWi8e/odvtRmdnp8crccIhyVOnTsHlciEqKsrjNgaDASkpKaipqcGJEydgNBoRExODhIQESbdFyS8pD4RSG6KVfYQNkYZW9g9AeQ0xuAfwkYTNzc2Ijo6G3W5HbGxswH64UoOkRVL/cjudTpSVlSE9Pb3HWfu+UmqQtErK30cp9g+ADQkmNoT6I+XvozCHNDU1eZyz1BvZDkUxSMGltpeUGaTgU+JLyt6wIcHFhlB/lNIQWQYbBkkeagkTgyQfpYSpP2yIPNgQ6o8SGhL0wYZBkpfSw8QgyU8JYfKGDZEXG0L9kbshQR1sGCRlUGqYGCTlkDtMfWFDlIENof7I2ZCgDTYMkrIoLUwMkvIobbhhQ5SFDaH+yNWQoAw2DJIyKSVMDJJyKWW4YUOUiQ2h/sjREMkHGwZJ2eQOE4OkfHIPN2yIsrEh1J9gN0TSwYZBUge5wsQgqYdcww0bog5sCPUnmA2RbLBhkNQl2GFikNQn2MMNG6IubAj1J1gNkWSwYZDUKVhhYpDUK1hhYkPUiQ2h/gSjIQEfbBgkdZM6TAyS+kkdJjZE3dgQ6o/UDQnoYMMgaYNUYWKQtEOqMLEh2sCGUH+kHG4CNtgwSNoS6DAxSNoT6DCxIdrChlB/pBpuAjLYMEjaFKgwMUjaFagwsSHaxIZQf6QYbvwebBgkbfM3TAyS9vkbJjZE29gQ6k+ghxu/BhsGSR98DRODpB++hokN0Qc2hPoTyOHG58GGQdKXwYaJQdKfwYaJDdEXNoT6E6jhxqfBhkHSp4GGiUHSr4GGiQ3RJzaE+hOI4WbQgw2DpG/9hcnhcDBIOtdfmNgQfWNDqD/+DjeDGmzOnTvHIJHXMJ08eRIAg6R3fYXp7NmzbAixIdQvf4abQQ02Z8+eZZAIQM8wtba2itcxSAR4huns2bMAgPr6ejaEALAh1L/uDamvrx/w7UwDWcjtdgO4uCOGhoaioaHBt7UkzYmNjUVVVRVKSkoAACkpKbhw4QIuXLgg85qREoSGhiI8PFw8tGC1WtkQ8sCGkDdCQyorKwF8P494M6DB5vz58wCAjIwM39eOiIiIyA/nz59HdHS012UM7gGMPy6XCzU1NYiKioLBYAjYChIRERH1x+124/z580hKSoLR6P0smgENNkRERERqENC/7k1EREQkJw42REREpBkcbIiIiEgzONgQERGRZnCwISIiIs3gYENERESawcGGiIiINOP/By0+VqxmfraKAAAAAElFTkSuQmCC",
      "text/plain": [
       "<Figure size 600x450 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "gridworld = GridWorld()\n",
    "qfunction = QTable()\n",
    "QLearning(gridworld, EpsilonGreedy(), qfunction).execute(episodes=100)\n",
    "gridworld.visualise_q_function(qfunction, \"Q-Function\", grid_size=1.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'Qpolicy' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m policy \u001b[38;5;241m=\u001b[39m \u001b[43mQpolicy\u001b[49m(qfunction)\n\u001b[1;32m      2\u001b[0m gridworld\u001b[38;5;241m.\u001b[39mvisualise_policy(policy)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'Qpolicy' is not defined"
     ]
    }
   ],
   "source": [
    "policy = Qpolicy(qfunction)\n",
    "gridworld.visualise_policy(policy)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rl",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.1.undefined"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
