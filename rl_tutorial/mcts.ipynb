{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import math\n",
    "import time\n",
    "import random\n",
    "from collections import defaultdict\n",
    "from rendering_utils import *\n",
    "from plot import Plot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Offline Planning & Online Planning for MDPs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Value iteration is an offline planning method since it solves the problem offline for all possiable states and then uses the solution (a policy) online to act.\n",
    "\n",
    "* In online planning (like AlphaZero), planning is undertaken immediately before executing an action.\n",
    "    * For each state $s$ visited, the set of all available actions $A(s)$ partially evaluated.\n",
    "    * The quality of each action $a$ is approximated by averaging the expected reward of trajectories over $S$ obtained by repeated simulations, giving as an approximation for $Q(s,a)$.\n",
    "    * The chosen action is $\\text{argmax}_{a'} Q(s,a)$\n",
    "\n",
    "* In online planning, we need access to a simulator that approximates the transitions function $P_a(s' |s)$ and reward function $r$ of our MDP."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MCTS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Framework"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The basic framkwork is to build up a tree using simulation. The states that have been evaluated are stored in a search tree. The set of evaluated states is **incementally** built be interation over the following four steps:\n",
    "\n",
    "-   **Select**: Select a single node in the tree that is **not fully expanded**. By this, we mean at least one of its children is not yet explored.\n",
    "    \n",
    "-   **Expand**: Expand this node by applying one available action (as defined by the MDP) from the node.\n",
    "    \n",
    "-   **Simulate**: From one of the outcomes of the expanded, perform a complete random simulation of the MDP to a terminating state. This therefore assumes that the simulation is finite, but versions of MCTS exist in which we just execute for some time and then estimate the outcome.\n",
    "    \n",
    "-   **Backpropagate**: Finally, the value of the node is backpropagated to the root node, updating the value of each ancestor node on the way using expected value."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Algorithm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. **Selection**: The first loop progressively selects a branch in the tree using a multi-armed bandit algorithm using $Q(s,a)$. The outcome that occurs from an action is chosen according to $P(s' \\mid s)$ defined in the MDP.\n",
    "\n",
    "2. **Expansion**: Select an action $a$ to apply in  state $s$, either randomly or using an heuristic. Get an outcome state $s'$ from applying action $a$ in state $s$ according to the probability distribution $P(s' \\mid s)$. Expand a new environment node and a new state node for that outcome.\n",
    "\n",
    "3. **Simulation**: Perform a randomised simulation of the MDP until we reach a terminating state. That is, at each choice point, randomly select an possible action from the MDP, and use transition probabilities $P_a(s' \\mid s)$ to choose an outcome for each action. Heuristics can be used to improve the random simulation by guiding it towards more promising states. $G$ is the cumulative discounted reward received from the simulation starting at $s'$ until the simulation terminates. \n",
    "\n",
    "4. **Backpropagation**: The reward from the simulation is backpropagated from the selected node to its ancestors recursively. We must not forget the discount factor! For each state $s$ and action $a$ selected in the Select step, update the cumulative reward of that state."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once we have run out of computational time, we select the action that maximises are expected return, which is simply the one with the highest Q-value from our simulations: \n",
    "\n",
    "$$\\text{argmax}_{a \\in A(s)} Q(s_0, a)$$ \n",
    "\n",
    "We execute that action and wait to see which outcome occurs for the action.\n",
    "\n",
    "Once we see the outcome state, which we will call $s'$, we start the process all over again, except with $s_0 \\leftarrow s'$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Node:\n",
    "\n",
    "    # Record a unique node id to distinguish duplicated states\n",
    "    next_node_id = 0\n",
    "\n",
    "    # Records the number of times states have been visited\n",
    "    visits = defaultdict(lambda: 0)\n",
    "\n",
    "    def __init__(self, mdp, parent, state, qfunction, bandit, reward=0.0, action=None):\n",
    "        self.mdp = mdp\n",
    "        self.parent = parent\n",
    "        self.state = state\n",
    "        self.id = Node.next_node_id\n",
    "        Node.next_node_id += 1\n",
    "\n",
    "        # The Q function used to store state-action values\n",
    "        self.qfunction = qfunction\n",
    "\n",
    "        # A multi-armed bandit for this node\n",
    "        self.bandit = bandit\n",
    "\n",
    "        # The immediate reward received for reaching this state, used for backpropagation\n",
    "        self.reward = reward\n",
    "\n",
    "        # The action that generated this node\n",
    "        self.action = action\n",
    "\n",
    "    \"\"\" Select a node that is not fully expanded \"\"\"\n",
    "\n",
    "    def select(self): pass\n",
    "\n",
    "\n",
    "    \"\"\" Expand a node if it is not a terminal node \"\"\"\n",
    "\n",
    "    def expand(self): pass\n",
    "\n",
    "\n",
    "    \"\"\" Backpropogate the reward back to the parent node \"\"\"\n",
    "\n",
    "    def back_propagate(self, reward, child): pass\n",
    "\n",
    "\n",
    "    \"\"\" Return the value of this node \"\"\"\n",
    "\n",
    "    def get_value(self):\n",
    "        max_q_value = self.qfunction.get_max_q(\n",
    "            self.state, self.mdp.get_actions(self.state)\n",
    "        )\n",
    "        return max_q_value\n",
    "\n",
    "    \"\"\" Get the number of visits to this state \"\"\"\n",
    "\n",
    "    def get_visits(self):\n",
    "        return Node.visits[self.state]\n",
    "\n",
    "\n",
    "class SingleAgentNode(Node):\n",
    "    def __init__(\n",
    "        self,\n",
    "        mdp,\n",
    "        parent,\n",
    "        state,\n",
    "        qfunction,\n",
    "        bandit,\n",
    "        reward=0.0,\n",
    "        action=None,\n",
    "    ):\n",
    "        super().__init__(mdp, parent, state, qfunction, bandit, reward, action)\n",
    "\n",
    "        # A dictionary from actions to a set of node-probability pairs\n",
    "        self.children = {}\n",
    "\n",
    "    \"\"\" Return true if and only if all child actions have been expanded \"\"\"\n",
    "\n",
    "    def is_fully_expanded(self):\n",
    "        valid_actions = self.mdp.get_actions(self.state)\n",
    "        if len(valid_actions) == len(self.children):\n",
    "            return True\n",
    "        else:\n",
    "            return False\n",
    "\n",
    "    \"\"\" Select a node that is not fully expanded \"\"\"\n",
    "\n",
    "    def select(self):\n",
    "        if not self.is_fully_expanded() or self.mdp.is_terminal(self.state):\n",
    "            return self\n",
    "        else:\n",
    "            actions = list(self.children.keys())\n",
    "            action = self.bandit.select(self.state, actions, self.qfunction)\n",
    "            return self.get_outcome_child(action).select()\n",
    "\n",
    "    \"\"\" Expand a node if it is not a terminal node \"\"\"\n",
    "\n",
    "    def expand(self):\n",
    "        if not self.mdp.is_terminal(self.state):\n",
    "            # Randomly select an unexpanded action to expand\n",
    "            actions = self.mdp.get_actions(self.state) - self.children.keys()\n",
    "            action = random.choice(list(actions))\n",
    "\n",
    "            self.children[action] = []\n",
    "            return self.get_outcome_child(action)\n",
    "        return self\n",
    "\n",
    "    \"\"\" Backpropogate the reward back to the parent node \"\"\"\n",
    "\n",
    "    def back_propagate(self, reward, child):\n",
    "        action = child.action\n",
    "\n",
    "        Node.visits[self.state] = Node.visits[self.state] + 1\n",
    "        Node.visits[(self.state, action)] = Node.visits[(self.state, action)] + 1\n",
    "\n",
    "        q_value = self.qfunction.get_q_value(self.state, action)\n",
    "        delta = (1 / (Node.visits[(self.state, action)])) * (\n",
    "            reward - self.qfunction.get_q_value(self.state, action)\n",
    "        )\n",
    "        self.qfunction.update(self.state, action, delta)\n",
    "\n",
    "        if self.parent != None:\n",
    "            self.parent.back_propagate(self.reward + reward, self)\n",
    "\n",
    "    \"\"\" Simulate the outcome of an action, and return the child node \"\"\"\n",
    "\n",
    "    def get_outcome_child(self, action):\n",
    "        # Choose one outcome based on transition probabilities\n",
    "        (next_state, reward, done) = self.mdp.execute(self.state, action)\n",
    "\n",
    "        # Find the corresponding state and return if this already exists\n",
    "        for (child, _) in self.children[action]:\n",
    "            if next_state == child.state:\n",
    "                return child\n",
    "\n",
    "        # This outcome has not occured from this state-action pair previously\n",
    "        new_child = SingleAgentNode(\n",
    "            self.mdp, self, next_state, self.qfunction, self.bandit, reward, action\n",
    "        )\n",
    "\n",
    "        # Find the probability of this outcome (only possible for model-based) for visualising tree\n",
    "        probability = 0.0\n",
    "        for (outcome, probability) in self.mdp.get_transitions(self.state, action):\n",
    "            if outcome == next_state:\n",
    "                self.children[action] += [(new_child, probability)]\n",
    "                return new_child"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MCTS:\n",
    "    def __init__(self, mdp, qfunction, bandit):\n",
    "        self.mdp = mdp\n",
    "        self.qfunction = qfunction\n",
    "        self.bandit = bandit\n",
    "\n",
    "    \"\"\"\n",
    "    Execute the MCTS algorithm from the initial state given, with timeout in seconds\n",
    "    \"\"\"\n",
    "\n",
    "    def mcts(self, timeout=1, root_node=None):\n",
    "        if root_node is None:\n",
    "            root_node = self.create_root_node()\n",
    "\n",
    "        start_time = time.time()\n",
    "        current_time = time.time()\n",
    "        while current_time < start_time + timeout:\n",
    "\n",
    "            # Find a state node to expand\n",
    "            selected_node = root_node.select()\n",
    "            if not self.mdp.is_terminal(selected_node):\n",
    "\n",
    "                child = selected_node.expand()\n",
    "                reward = self.simulate(child)\n",
    "                selected_node.back_propagate(reward, child)\n",
    "\n",
    "            current_time = time.time()\n",
    "\n",
    "        return root_node\n",
    "\n",
    "    \"\"\" Create a root node representing an initial state \"\"\"\n",
    "\n",
    "    def create_root_node(self): pass\n",
    "\n",
    "\n",
    "    \"\"\" Choose a random action. Heustics can be used here to improve simulations. \"\"\"\n",
    "\n",
    "    def choose(self, state):\n",
    "        return random.choice(self.mdp.get_actions(state))\n",
    "\n",
    "    \"\"\" Simulate until a terminal state \"\"\"\n",
    "\n",
    "    def simulate(self, node):\n",
    "        state = node.state\n",
    "        cumulative_reward = 0.0\n",
    "        depth = 0\n",
    "        while not self.mdp.is_terminal(state):\n",
    "            # Choose an action to execute\n",
    "            action = self.choose(state)\n",
    "\n",
    "            # Execute the action\n",
    "            (next_state, reward, done) = self.mdp.execute(state, action)\n",
    "\n",
    "            # Discount the reward\n",
    "            cumulative_reward += pow(self.mdp.get_discount_factor(), depth) * reward\n",
    "            depth += 1\n",
    "\n",
    "            state = next_state\n",
    "\n",
    "        return cumulative_reward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SingleAgentMCTS(MCTS):\n",
    "    def create_root_node(self):\n",
    "        return SingleAgentNode(\n",
    "            self.mdp, None, self.mdp.get_initial_state(), self.qfunction, self.bandit\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### GridWorld Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MDP:\n",
    "    \"\"\"Return all states of this MDP\"\"\"\n",
    "\n",
    "    def get_states(self):\n",
    "        pass\n",
    "\n",
    "    \"\"\" Return all actions with non-zero probability from this state \"\"\"\n",
    "\n",
    "    def get_actions(self, state):\n",
    "        pass\n",
    "\n",
    "    \"\"\" Return all non-zero probability transitions for this action\n",
    "        from this state, as a list of (state, probability) pairs\n",
    "    \"\"\"\n",
    "\n",
    "    def get_transitions(self, state, action):\n",
    "        pass\n",
    "\n",
    "    \"\"\" Return the reward for transitioning from state to\n",
    "        nextState via action\n",
    "    \"\"\"\n",
    "\n",
    "    def get_reward(self, state, action, next_state):\n",
    "        pass\n",
    "\n",
    "    \"\"\" Return true if and only if state is a terminal state of this MDP \"\"\"\n",
    "\n",
    "    def is_terminal(self, state):\n",
    "        pass\n",
    "\n",
    "    \"\"\" Return the discount factor for this MDP \"\"\"\n",
    "\n",
    "    def get_discount_factor(self):\n",
    "        pass\n",
    "\n",
    "    \"\"\" Return the initial state of this MDP \"\"\"\n",
    "\n",
    "    def get_initial_state(self):\n",
    "        pass\n",
    "\n",
    "    \"\"\" Return all goal states of this MDP \"\"\"\n",
    "\n",
    "    def get_goal_states(self):\n",
    "        pass\n",
    "\n",
    "    \"\"\" Return a new state and a reward for executing action in state,\n",
    "    based on the underlying probability. This can be used for\n",
    "    model-free learning methods, but requires a model to operate.\n",
    "    Override for simulation-based learning\n",
    "    \"\"\"\n",
    "\n",
    "    def execute(self, state, action):\n",
    "        rand = random.random()\n",
    "        cumulative_probability = 0.0\n",
    "        for (new_state, probability) in self.get_transitions(state, action):\n",
    "            if cumulative_probability <= rand <= probability + cumulative_probability:\n",
    "                reward = self.get_reward(state, action, new_state)\n",
    "                return (new_state, reward, self.is_terminal(new_state))\n",
    "            cumulative_probability += probability\n",
    "            if cumulative_probability >= 1.0:\n",
    "                raise (\n",
    "                    \"Cumulative probability >= 1.0 for action \"\n",
    "                    + str(action)\n",
    "                    + \" from \"\n",
    "                    + str(state)\n",
    "                )\n",
    "\n",
    "        raise BaseException(\n",
    "            \"No outcome state in simulation for action \"\n",
    "            + str(action)\n",
    "            + \" from \"\n",
    "            + str(state)\n",
    "        )\n",
    "\n",
    "    \"\"\" \n",
    "    Execute a policy on this mdp for a number of episodes.\n",
    "    \"\"\"\n",
    "\n",
    "    def execute_policy(self, policy, episodes=100, max_step=100):\n",
    "        cumulative_rewards = []\n",
    "        states = set()\n",
    "        for _ in range(episodes):\n",
    "            cumulative_reward = 0.0\n",
    "            state = self.get_initial_state()\n",
    "            step = 0\n",
    "            while not self.is_terminal(state):\n",
    "                actions = self.get_actions(state)\n",
    "                action = policy.select_action(state, actions)\n",
    "                (next_state, reward, done) = self.execute(state, action)\n",
    "                cumulative_reward += reward * (self.discount_factor ** step)\n",
    "                state = next_state\n",
    "                step += 1\n",
    "                if step > max_step:\n",
    "                    break\n",
    "            cumulative_rewards += [cumulative_reward]\n",
    "        return cumulative_rewards"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GridWorld(MDP):\n",
    "    # labels for terminate action and terminal state\n",
    "    TERMINAL = (-1, -1)\n",
    "    TERMINATE = 0\n",
    "    LEFT = 1\n",
    "    UP = 2\n",
    "    RIGHT = 3\n",
    "    DOWN = 4\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        noise=0.1,\n",
    "        width=4,\n",
    "        height=3,\n",
    "        discount_factor=0.9,\n",
    "        blocked_states=[(1, 1)],\n",
    "        action_cost=0.0,\n",
    "        initial_state=(0, 0),\n",
    "        goals=None,\n",
    "    ):\n",
    "        self.noise = noise\n",
    "        self.width = width\n",
    "        self.height = height\n",
    "        self.blocked_states = blocked_states\n",
    "        self.discount_factor = discount_factor\n",
    "        self.action_cost = action_cost\n",
    "        self.initial_state = initial_state\n",
    "        if goals is None:\n",
    "            self.goal_states = dict(\n",
    "                [((width - 1, height - 1), 1), ((width - 1, height - 2), -1)]\n",
    "            )\n",
    "        else:\n",
    "            self.goal_states = dict(goals)\n",
    "\n",
    "        # A list of lists that records all rewards given at each step\n",
    "        # for each episode of a simulated gridworld\n",
    "        self.rewards = []\n",
    "\n",
    "        # A list of cumulative rewards for each episode\n",
    "        self.cumulative_rewards = []\n",
    "    \n",
    "        # The rewards for the current episode\n",
    "        self.episode_rewards = []\n",
    "\n",
    "\n",
    "    def get_states(self):\n",
    "        states = [self.TERMINAL]\n",
    "        for x in range(self.width):\n",
    "            for y in range(self.height):\n",
    "                if not (x, y) in self.blocked_states:\n",
    "                    states.append((x, y))\n",
    "        return states\n",
    "\n",
    "    def get_actions(self, state=None):\n",
    "\n",
    "        actions = [self.TERMINATE, self.LEFT, self.UP, self.RIGHT, self.DOWN]\n",
    "        if state is None:\n",
    "            return actions\n",
    "\n",
    "        valid_actions = []\n",
    "        for action in actions:\n",
    "            for (new_state, probability) in self.get_transitions(state, action):\n",
    "                if probability > 0:\n",
    "                    valid_actions.append(action)\n",
    "                    break\n",
    "        return valid_actions\n",
    "\n",
    "    def get_initial_state(self):\n",
    "        self.episode_rewards = []\n",
    "        return self.initial_state\n",
    "\n",
    "    def get_goal_states(self):\n",
    "        return self.goal_states\n",
    "\n",
    "    def valid_add(self, state, new_state, probability):\n",
    "        # If the next state is blocked, stay in the same state\n",
    "        if probability == 0.0:\n",
    "            return []\n",
    "\n",
    "        if new_state in self.blocked_states:\n",
    "            return [(state, probability)]\n",
    "\n",
    "        # Move to the next space if it is not off the grid\n",
    "        (x, y) = new_state\n",
    "        if x >= 0 and x < self.width and y >= 0 and y < self.height:\n",
    "            return [((x, y), probability)]\n",
    "\n",
    "        # If off the grid, state in the same state\n",
    "        return [(state, probability)]\n",
    "\n",
    "    def get_transitions(self, state, action):\n",
    "        transitions = []\n",
    "\n",
    "        if state == self.TERMINAL:\n",
    "            if action == self.TERMINATE:\n",
    "                return [(self.TERMINAL, 1.0)]\n",
    "            else:\n",
    "                return []\n",
    "\n",
    "        # Probability of not slipping left or right\n",
    "        straight = 1 - (2 * self.noise)\n",
    "\n",
    "        (x, y) = state\n",
    "        if state in self.get_goal_states().keys():\n",
    "            if action == self.TERMINATE:\n",
    "                transitions += [(self.TERMINAL, 1.0)]\n",
    "\n",
    "        elif action == self.UP:\n",
    "            transitions += self.valid_add(state, (x, y + 1), straight)\n",
    "            transitions += self.valid_add(state, (x - 1, y), self.noise)\n",
    "            transitions += self.valid_add(state, (x + 1, y), self.noise)\n",
    "\n",
    "        elif action == self.DOWN:\n",
    "            transitions += self.valid_add(state, (x, y - 1), straight)\n",
    "            transitions += self.valid_add(state, (x - 1, y), self.noise)\n",
    "            transitions += self.valid_add(state, (x + 1, y), self.noise)\n",
    "\n",
    "        elif action == self.RIGHT:\n",
    "            transitions += self.valid_add(state, (x + 1, y), straight)\n",
    "            transitions += self.valid_add(state, (x, y - 1), self.noise)\n",
    "            transitions += self.valid_add(state, (x, y + 1), self.noise)\n",
    "\n",
    "        elif action == self.LEFT:\n",
    "            transitions += self.valid_add(state, (x - 1, y), straight)\n",
    "            transitions += self.valid_add(state, (x, y - 1), self.noise)\n",
    "            transitions += self.valid_add(state, (x, y + 1), self.noise)\n",
    "\n",
    "        # Merge any duplicate outcomes\n",
    "        merged = defaultdict(lambda: 0.0)\n",
    "        for (state, probability) in transitions:\n",
    "            merged[state] = merged[state] + probability\n",
    "\n",
    "        transitions = []\n",
    "        for outcome in merged.keys():\n",
    "            transitions += [(outcome, merged[outcome])]\n",
    "\n",
    "        return transitions\n",
    "\n",
    "    def get_reward(self, state, action, new_state):\n",
    "        reward = 0.0\n",
    "        if state in self.get_goal_states().keys() and new_state == self.TERMINAL:\n",
    "            reward = self.get_goal_states().get(state)\n",
    "        else:\n",
    "            reward = self.action_cost\n",
    "        step = len(self.episode_rewards)\n",
    "        self.episode_rewards += [reward * (self.discount_factor ** step)]\n",
    "        return reward\n",
    "\n",
    "    def get_discount_factor(self):\n",
    "        return self.discount_factor\n",
    "\n",
    "    def is_terminal(self, state):\n",
    "        if state == self.TERMINAL:\n",
    "            return True\n",
    "        return False\n",
    "\n",
    "    \"\"\"\n",
    "        Returns a list of lists, which records all rewards given at each step\n",
    "        for each episode of a simulated gridworld\n",
    "    \"\"\"\n",
    "\n",
    "    def get_rewards(self):\n",
    "        return self.rewards\n",
    "    \n",
    "\n",
    "    \"\"\"\n",
    "        Returns a list of all cumulative rewards\n",
    "        for each episode of a simulated gridworld\n",
    "    \"\"\"\n",
    "\n",
    "    def get_cumulative_rewards(self):\n",
    "        return self.cumulative_rewards\n",
    "\n",
    "    \"\"\"\n",
    "        Create a gridworld from an array of strings: one for each line\n",
    "        - First line is rewards as a dictionary from cell to value: {'A': 1, ...}\n",
    "        - space is an empty cell\n",
    "        - # is a blocked cell\n",
    "        - @ is the agent (initial state)\n",
    "        - new 'line' is a new row\n",
    "        - a letter is a cell with a reward for transitioning\n",
    "          into that cell. The reward defined by the first line.\n",
    "    \"\"\"\n",
    "\n",
    "    @staticmethod\n",
    "    def create(string):\n",
    "        # Parse the reward on the first line\n",
    "        import ast\n",
    "\n",
    "        rewards = ast.literal_eval(string[0])\n",
    "\n",
    "        width = 0\n",
    "        height = len(string) - 1\n",
    "\n",
    "        blocked_cells = []\n",
    "        initial_state = (0, 0)\n",
    "        goals = []\n",
    "        row = 0\n",
    "        for next_row in string[1:]:\n",
    "            column = 0\n",
    "            for cell in next_row:\n",
    "                if cell == \"#\":\n",
    "                    blocked_cells += [(column, row)]\n",
    "                elif cell == \"@\":\n",
    "                    initial_state = (column, row)\n",
    "                elif cell.isalpha():\n",
    "                    goals += [((column, row), rewards[cell])]\n",
    "                column += 1\n",
    "            width = max(width, column)\n",
    "            row += 1\n",
    "        return GridWorld(\n",
    "            width=width,\n",
    "            height=height,\n",
    "            blocked_states=blocked_cells,\n",
    "            initial_state=initial_state,\n",
    "            goals=goals,\n",
    "        )\n",
    "\n",
    "    @staticmethod\n",
    "    def open(file):\n",
    "        file = open(file, \"r\")\n",
    "        string = file.read().splitlines()\n",
    "        file.close()\n",
    "        return GridWorld.create(string)\n",
    "\n",
    "    @staticmethod\n",
    "    def matplotlib_installed():\n",
    "        try:\n",
    "            import matplotlib as mpl\n",
    "            import matplotlib.pyplot as plt\n",
    "            return True\n",
    "        except ModuleNotFoundError:\n",
    "            return False\n",
    "\n",
    "    \"\"\" Visualise a Grid World problem \"\"\"\n",
    "\n",
    "    def visualise(self, agent_position=None, title=\"\", grid_size=1.0, gif=False):\n",
    "        if self.matplotlib_installed():\n",
    "            return self.visualise_as_image(agent_position=agent_position, title=title, grid_size=grid_size, gif=gif)\n",
    "        else:\n",
    "            print(self.to_string(title=title))\n",
    "\n",
    "    \"\"\" Visualise a Grid World value function \"\"\"\n",
    "    def visualise_value_function(self, value_function, title=\"\", grid_size=1.0, gif=False):\n",
    "        if self.matplotlib_installed():\n",
    "            return self.visualise_value_function_as_image(value_function, title=title, grid_size=grid_size, gif=gif)\n",
    "        else:\n",
    "            print(self.value_function_to_string(value_function, title=title))\n",
    "\n",
    "    def visualise_q_function(self, qfunction, title=\"\", grid_size=1.5, gif=False):\n",
    "        if self.matplotlib_installed():\n",
    "            return self.visualise_q_function_as_image(qfunction, title=title, grid_size=grid_size, gif=gif)\n",
    "        else:\n",
    "            print(self.q_function_to_string(qfunction, title=title))\n",
    "\n",
    "    def visualise_policy(self, policy, title=\"\", grid_size=1.0, gif=False):\n",
    "        if self.matplotlib_installed():\n",
    "            return self.visualise_policy_as_image(policy, title=title, grid_size=grid_size, gif=gif)\n",
    "        else:\n",
    "            print(self.policy_to_string(policy, title=title))\n",
    "\n",
    "    def visualise_stochastic_policy(self, policy, title=\"\", grid_size=1.0, gif=False):\n",
    "        if self.matplotlib_installed():\n",
    "            return self.visualise_stochastic_policy_as_image(policy, title=title, grid_size=grid_size, gif=gif)\n",
    "        else:\n",
    "            # TODO make a stochastic policy to string\n",
    "            pass\n",
    "\n",
    "    \"\"\" Visualise a grid world problem as a formatted string \"\"\"\n",
    "    def to_string(self, title=\"\"):\n",
    "        left_arrow = \"\\u25C4\"\n",
    "        up_arrow = \"\\u25B2\"\n",
    "        right_arrow = \"\\u25BA\"\n",
    "        down_arrow = \"\\u25BC\"\n",
    "\n",
    "\n",
    "        space = \" |              \"\n",
    "        block = \" | #############\"\n",
    "\n",
    "        line = \"  \"\n",
    "        for x in range(self.width):\n",
    "            line += \"--------------- \"\n",
    "        line += \"\\n\"\n",
    "\n",
    "        result = \" \" + title + \"\\n\"\n",
    "        result += line\n",
    "        for y in range(self.height - 1, -1, -1):\n",
    "            for x in range(self.width):\n",
    "                if (x, y) in self.get_goal_states().keys():\n",
    "                    result += space\n",
    "                elif (x, y) in self.blocked_states:\n",
    "                    result += block\n",
    "                else:\n",
    "                    result += \" |       {}      \".format(up_arrow)\n",
    "            result += \" |\\n\"\n",
    "\n",
    "            for x in range(self.width):\n",
    "                if (x, y) == self.get_initial_state():\n",
    "                    result += \" |     _____    \"\n",
    "                elif (x, y) in self.blocked_states:\n",
    "                    result += block\n",
    "                else:\n",
    "                    result += space\n",
    "            result += \" |\\n\"\n",
    "\n",
    "            for x in range(self.width):\n",
    "                if (x, y) == self.get_initial_state():\n",
    "                    result += \" |    ||o  o|   \"\n",
    "                elif (x, y) in self.blocked_states:\n",
    "                    result += block\n",
    "                else:\n",
    "                    result += space\n",
    "            result += \" |\\n\"\n",
    "\n",
    "            for x in range(self.width):\n",
    "                if (x, y) == self.get_initial_state():\n",
    "                    result += \" | {}  ||  * |  {}\".format(left_arrow, right_arrow)\n",
    "                elif (x, y) in self.blocked_states:\n",
    "                    result += block\n",
    "                elif (x, y) in self.get_goal_states().keys():\n",
    "                    result += \" |     {:+0.2f}    \".format(\n",
    "                        self.get_goal_states()[(x, y)]\n",
    "                    )\n",
    "                else:\n",
    "                    result += \" | {}           {}\".format(left_arrow, right_arrow)\n",
    "            result += \" |\\n\"\n",
    "\n",
    "            for x in range(self.width):\n",
    "                if (x, y) == self.get_initial_state():\n",
    "                    result += \" |    ||====|   \".format(left_arrow, right_arrow)\n",
    "                elif (x, y) in self.blocked_states:\n",
    "                    result += block\n",
    "                else:\n",
    "                    result += space\n",
    "            result += \" |\\n\"\n",
    "\n",
    "            for x in range(self.width):\n",
    "                if (x, y) == self.get_initial_state():\n",
    "                    result += \" |     -----    \"\n",
    "                elif (x, y) in self.blocked_states:\n",
    "                    result += block\n",
    "                else:\n",
    "                    result += space\n",
    "            result += \" |\\n\"\n",
    "\n",
    "            for x in range(self.width):\n",
    "                if (x, y) in self.get_goal_states().keys():\n",
    "                    result += space\n",
    "                elif (x, y) in self.blocked_states:\n",
    "                    result += block\n",
    "                else:\n",
    "                    result += \" |       {}      \".format(down_arrow)\n",
    "            result += \" |\\n\"\n",
    "            result += line\n",
    "        return result\n",
    "\n",
    "    \"\"\" Convert a grid world value function to a formatted string \"\"\"\n",
    "\n",
    "    def value_function_to_string(self, values, title=\"\"):\n",
    "        line = \" {:-^{n}}\\n\".format(\"\", n=len(\" | +0.00\") * self.width + 1)\n",
    "        result = \" \" + title + \"\\n\"\n",
    "        result += line\n",
    "        for y in range(self.height - 1, -1, -1):\n",
    "            for x in range(self.width):\n",
    "                if (x, y) in self.blocked_states:\n",
    "                    result += \" | #####\"\n",
    "                else:\n",
    "                    result += \" | {:+0.2f}\".format(values.get_value((x, y)))\n",
    "            result += \" |\\n\"\n",
    "            result += line\n",
    "\n",
    "        return result\n",
    "\n",
    "    \"\"\" Convert a grid world Q function to a formatted string \"\"\"\n",
    "\n",
    "    def q_function_to_string(self, qfunction, title=\"\"):\n",
    "        left_arrow = \"\\u25C4\"\n",
    "        up_arrow = \"\\u25B2\"\n",
    "        right_arrow = \"\\u25BA\"\n",
    "        down_arrow = \"\\u25BC\"\n",
    "\n",
    "        space = \" |               \"\n",
    "\n",
    "        line = \"  \"\n",
    "        for x in range(self.width):\n",
    "            line += \"---------------- \"\n",
    "        line += \"\\n\"\n",
    "\n",
    "        result = \" \" + title + \"\\n\"\n",
    "        result += line\n",
    "        for y in range(self.height - 1, -1, -1):\n",
    "            for x in range(self.width):\n",
    "                if (x, y) in self.blocked_states or (\n",
    "                    x,\n",
    "                    y,\n",
    "                ) in self.get_goal_states().keys():\n",
    "                    result += space\n",
    "                else:\n",
    "                    result += \" |       {}       \".format(up_arrow)\n",
    "            result += \" |\\n\"\n",
    "\n",
    "            for x in range(self.width):\n",
    "                if (x, y) in self.blocked_states or (\n",
    "                    x,\n",
    "                    y,\n",
    "                ) in self.get_goal_states().keys():\n",
    "                    result += space\n",
    "                else:\n",
    "                    result += \" |     {:+0.2f}     \".format(\n",
    "                        qfunction.get_q_value((x, y), self.UP)\n",
    "                    )\n",
    "            result += \" |\\n\"\n",
    "\n",
    "            for x in range(self.width):\n",
    "                result += space\n",
    "            result += \" |\\n\"\n",
    "\n",
    "            for x in range(self.width):\n",
    "                if (x, y) in self.blocked_states:\n",
    "                    result += \" |     #####     \"\n",
    "                elif (x, y) in self.get_goal_states().keys():\n",
    "                    result += \" |     {:+0.2f}     \".format(\n",
    "                        self.get_goal_states()[(x, y)]\n",
    "                    )\n",
    "                else:\n",
    "                    result += \" | {}{:+0.2f}  {:+0.2f}{}\".format(\n",
    "                        left_arrow,\n",
    "                        qfunction.get_q_value((x, y), self.LEFT),\n",
    "                        qfunction.get_q_value((x, y), self.RIGHT),\n",
    "                        right_arrow,\n",
    "                    )\n",
    "            result += \" |\\n\"\n",
    "\n",
    "            for x in range(self.width):\n",
    "                result += space\n",
    "            result += \" |\\n\"\n",
    "\n",
    "            for x in range(self.width):\n",
    "                if (x, y) in self.blocked_states or (\n",
    "                    x,\n",
    "                    y,\n",
    "                ) in self.get_goal_states().keys():\n",
    "                    result += space\n",
    "                else:\n",
    "                    result += \" |     {:+0.2f}     \".format(\n",
    "                        qfunction.get_q_value((x, y), self.DOWN)\n",
    "                    )\n",
    "            result += \" |\\n\"\n",
    "\n",
    "            for x in range(self.width):\n",
    "                if (x, y) in self.blocked_states or (\n",
    "                    x,\n",
    "                    y,\n",
    "                ) in self.get_goal_states().keys():\n",
    "                    result += space\n",
    "                else:\n",
    "                    result += \" |       {}       \".format(down_arrow)\n",
    "            result += \" |\\n\"\n",
    "            result += line\n",
    "        return result\n",
    "\n",
    "    \"\"\" Convert a grid world policy to a formatted string \"\"\"\n",
    "    def policy_to_string(self, policy, title=\"\"):\n",
    "        arrow_map = {self.UP:'\\u25B2',\n",
    "                     self.DOWN:'\\u25BC',\n",
    "                     self.LEFT:'\\u25C4',\n",
    "                     self.RIGHT:'\\u25BA',\n",
    "                    }\n",
    "        line = \" {:-^{n}}\\n\".format(\"\", n=len(\" |  N \") * self.width + 1)\n",
    "        result = \" \" + title + \"\\n\"\n",
    "        result += line\n",
    "        for y in range(self.height - 1, -1, -1):\n",
    "            for x in range(self.width):\n",
    "                if (x, y) in self.blocked_states:\n",
    "                    result += \" | ###\"\n",
    "                elif policy.select_action((x, y), self.get_actions((x, y))) == self.TERMINATE:\n",
    "                    result += \" | {:+0d} \".format(self.goal_states[(x, y)])\n",
    "                else:\n",
    "                    result += \" |  \" + arrow_map[policy.select_action((x, y), self.get_actions((x, y)))] + \" \"\n",
    "            result += \" |\\n\"\n",
    "            result += line\n",
    "\n",
    "        return result\n",
    "\n",
    "\n",
    "    \"\"\" Initialise a gridworld grid \"\"\"\n",
    "    def initialise_grid(self, grid_size=1.0):\n",
    "        fig = plt.figure(figsize=(self.width * grid_size, self.height * grid_size))\n",
    "\n",
    "        # Trim whitespace \n",
    "        plt.subplots_adjust(top=0.92, bottom=0.01, right=1, left=0, hspace=0, wspace=0)\n",
    "        ax = fig.add_subplot(1, 1, 1)\n",
    "\n",
    "        # Initialise the map to all white\n",
    "        img = [[COLOURS['white'] for _ in range(self.width)] for _ in range(self.height)]\n",
    "\n",
    "        # Render the grid\n",
    "        for y in range(0, self.height):\n",
    "            for x in range(0, self.width):\n",
    "                if (x, y) in self.goal_states:\n",
    "                    img[y][x] = COLOURS['red'] if self.goal_states[(x, y)] < 0 else COLOURS['green']\n",
    "                elif (x, y) in self.blocked_states:\n",
    "                    img[y][x] = COLOURS['grey']\n",
    "\n",
    "        ax.xaxis.set_ticklabels([])  # clear x tick labels\n",
    "        ax.axes.yaxis.set_ticklabels([])  # clear y tick labels\n",
    "        ax.tick_params(which='both', top=False, left=False, right=False, bottom=False)\n",
    "        ax.set_xticks([w - 0.5 for w in range(0, self.width, 1)])\n",
    "        ax.set_yticks([h - 0.5 for h in range(0, self.height, 1)])\n",
    "        ax.grid(color='lightgrey')\n",
    "        return fig, ax, img\n",
    "\n",
    "    \"\"\" visualise the gridworld problem as a matplotlib image \"\"\"\n",
    "\n",
    "    def visualise_as_image(self, agent_position=None, title=\"\", grid_size=1.0, gif=False):\n",
    "        fig, ax, img = self.initialise_grid(grid_size=grid_size)\n",
    "        current_position = (\n",
    "            self.get_initial_state() if agent_position is None else agent_position\n",
    "        )\n",
    "\n",
    "        # Render the grid\n",
    "        for y in range(0, self.height):\n",
    "            for x in range(0, self.width):\n",
    "                if (x, y) == current_position:\n",
    "                    ax.scatter(x, y, s=2000, marker='o', edgecolors='none')\n",
    "                elif (x, y) in self.goal_states:\n",
    "                    plt.text(\n",
    "                        x,\n",
    "                        y,\n",
    "                        f\"{self.get_goal_states()[(x, y)]:+0.2f}\",\n",
    "                        fontsize=\"x-large\",\n",
    "                        horizontalalignment=\"center\",\n",
    "                        verticalalignment=\"center\",\n",
    "                    )\n",
    "        im = plt.imshow(img, origin=\"lower\")\n",
    "        plt.title(title)\n",
    "        if gif:\n",
    "            return fig, ax, im\n",
    "        else:\n",
    "            return fig\n",
    "\n",
    "    \"\"\"Render each tile individually depending on the current state of the cell\"\"\"\n",
    "\n",
    "    def render_tile(self, x, y, tile_size, img, tile_type=None):\n",
    "        ymin = y * tile_size\n",
    "        ymax = (y + 1) * tile_size\n",
    "        xmin = x * tile_size\n",
    "        xmax = (x + 1) * tile_size\n",
    "\n",
    "        for i in range(ymin, ymax):\n",
    "            for j in range(xmin, xmax):\n",
    "                if i == ymin or i == ymax - 1 or j == xmin or j == xmax + 1:\n",
    "                    draw_grid_lines(i, j, img)\n",
    "                else:\n",
    "                    if tile_type == \"goal\":\n",
    "                        render_goal(\n",
    "                            i,\n",
    "                            j,\n",
    "                            img,\n",
    "                            reward=self.goal_states[(x, y)],\n",
    "                            reward_max=max(self.get_goal_states().values()),\n",
    "                            reward_min=min(self.get_goal_states().values()),\n",
    "                        )\n",
    "                    elif tile_type == \"blocked\":\n",
    "                        render_blocked_tile(i, j, img)\n",
    "                    elif tile_type == \"agent\":\n",
    "                        render_agent(\n",
    "                            i,\n",
    "                            j,\n",
    "                            img,\n",
    "                            center_x=xmin + tile_size / 2,\n",
    "                            center_y=ymin + tile_size / 2,\n",
    "                            radius=tile_size / 4,\n",
    "                        )\n",
    "                    elif tile_type == \"empty\":\n",
    "                        img[i][j] = [255, 255, 255]\n",
    "                    else:\n",
    "                        raise ValueError(\"Invalid tile type\")\n",
    "\n",
    "    \"\"\" Visualise the value function \"\"\"\n",
    "\n",
    "    def visualise_value_function_as_image(self, value_function, title=\"\", grid_size=1.0, gif=False):\n",
    "        if not gif:\n",
    "            fig, ax, img = self.initialise_grid(grid_size=grid_size)\n",
    "        texts = []\n",
    "        for y in range(self.height):\n",
    "            for x in range(self.width):\n",
    "                value = value_function.get_value((x, y))\n",
    "                if (x, y) not in self.blocked_states:\n",
    "                    text = plt.text(\n",
    "                        x,\n",
    "                        y,\n",
    "                        f\"{float(value):+0.2f}\",\n",
    "                        fontsize=\"medium\",\n",
    "                        horizontalalignment=\"center\",\n",
    "                        verticalalignment=\"center\",\n",
    "                        color='lightgrey' if value == 0.0 else 'black',\n",
    "                    )\n",
    "                    texts.append(text)\n",
    "        if gif:\n",
    "            return texts\n",
    "        else:\n",
    "            ax.imshow(img, origin=\"lower\")\n",
    "            plt.title(title, fontsize=\"large\")\n",
    "            plt.show()\n",
    "\n",
    "    \"\"\" Visualise the value function using a heat-map where green is high value and\n",
    "    red is low value\n",
    "    \"\"\"\n",
    "\n",
    "    def visualise_value_function_as_heatmap(self, value_function, title=\"\"):\n",
    "        values = [[0 for _ in range(self.width)] for _ in range(self.height)]\n",
    "        fig, ax = self.initialise_grid()\n",
    "        for y in range(self.height):\n",
    "            for x in range(self.width):\n",
    "                if (x, y) in self.blocked_states:\n",
    "                    plt.text(\n",
    "                        x,\n",
    "                        y,\n",
    "                        \"#\",\n",
    "                        horizontalalignment=\"center\",\n",
    "                        verticalalignment=\"center\",\n",
    "                    )\n",
    "                else:\n",
    "                    values[y][x] = value_function.get_value((x, y))\n",
    "                    plt.text(\n",
    "                        x,\n",
    "                        y,\n",
    "                        f\"{values[y][x]:.2f}\",\n",
    "                        horizontalalignment=\"center\",\n",
    "                        verticalalignment=\"center\",\n",
    "                    )\n",
    "        plt.imshow(values, origin=\"lower\", cmap=make_red_white_green_cmap())\n",
    "        plt.title(title)\n",
    "        plt.show()\n",
    "\n",
    "    \"\"\" Visualise the Q-function with matplotlib \"\"\"\n",
    "\n",
    "    def visualise_q_function_as_image(self, qfunction, title=\"\", grid_size=1.5, gif=False):\n",
    "        if not gif:\n",
    "            fig, ax, img = self.initialise_grid(grid_size=grid_size)\n",
    "        texts = []\n",
    "        for y in range(self.height):\n",
    "            for x in range(self.width):\n",
    "                if (x, y) in self.goal_states:\n",
    "                    # gif player handles goal state rendering\n",
    "                    if not gif:\n",
    "                        texts.append(plt.text(\n",
    "                            x,\n",
    "                            y,\n",
    "                            f\"{self.get_goal_states()[(x,y)]:+0.2f}\",\n",
    "                            fontsize=\"large\",\n",
    "                            horizontalalignment=\"center\",\n",
    "                            verticalalignment=\"center\",\n",
    "                        ))\n",
    "                elif (x, y) not in self.blocked_states:\n",
    "                    up_value = qfunction.get_q_value((x, y), self.UP)\n",
    "                    down_value = qfunction.get_q_value((x, y), self.DOWN)\n",
    "                    left_value = qfunction.get_q_value((x, y), self.LEFT)\n",
    "                    right_value = qfunction.get_q_value((x, y), self.RIGHT)\n",
    "                    texts.append(plt.text(\n",
    "                        x,\n",
    "                        y + 0.35,\n",
    "                        f\"{up_value:+0.2f}\",\n",
    "                        fontsize=\"medium\",\n",
    "                        horizontalalignment=\"center\",\n",
    "                        verticalalignment=\"top\",\n",
    "                        color='lightgrey' if up_value == 0.0 else 'black',\n",
    "                    ))\n",
    "                    texts.append(plt.text(\n",
    "                        x,\n",
    "                        y - 0.35,\n",
    "                        f\"{down_value:+0.2f}\",\n",
    "                        fontsize=\"medium\",\n",
    "                        horizontalalignment=\"center\",\n",
    "                        verticalalignment=\"bottom\",\n",
    "                        color='lightgrey' if down_value == 0.0 else 'black',\n",
    "                    ))\n",
    "                    texts.append(plt.text(\n",
    "                        x - 0.45,\n",
    "                        y,\n",
    "                        f\"{left_value:+0.2f}\",\n",
    "                        fontsize=\"medium\",\n",
    "                        horizontalalignment=\"left\",\n",
    "                        verticalalignment=\"center\",\n",
    "                        color='lightgrey' if left_value == 0.0 else 'black'\n",
    "                    ))\n",
    "                    texts.append(plt.text(\n",
    "                        x + 0.45,\n",
    "                        y,\n",
    "                        f\"{right_value:+0.2f}\",\n",
    "                        fontsize=\"medium\",\n",
    "                        horizontalalignment=\"right\",\n",
    "                        verticalalignment=\"center\",\n",
    "                        color='lightgrey' if right_value == 0.0 else 'black'\n",
    "                    ))\n",
    "                    plt.plot([x-0.5, x+0.5], [y-0.5, y+0.5], ls='-', lw=1, color='lightgrey')\n",
    "                    plt.plot([x + 0.5, x - 0.5], [y - 0.5, y + 0.5], ls='-', lw=1, color='lightgrey')\n",
    "        if gif:\n",
    "            return texts\n",
    "        ax.imshow(img, origin=\"lower\")\n",
    "        plt.title(title)\n",
    "        plt.show()\n",
    "\n",
    "    \"\"\" Visualise the Q-function with a matplotlib visual\"\"\"\n",
    "\n",
    "    def visualise_q_function_rendered(self, q_values, title=\"\", tile_size=32, show_text=False):\n",
    "        width_px = self.width * tile_size\n",
    "        height_px = self.height * tile_size\n",
    "        img = [[[0, 0, 0] for _ in range(width_px)] for _ in range(height_px)]\n",
    "\n",
    "        # provide these to scale the colours between the highest and lowest value\n",
    "        reward_max = max(self.get_goal_states().values())\n",
    "        reward_min = min(self.get_goal_states().values())\n",
    "        # Render the grid\n",
    "        for y in range(0, self.height):\n",
    "            for x in range(0, self.width):\n",
    "                # Draw in the blocked states as a black and white mesh\n",
    "                if (x, y) in self.blocked_states:\n",
    "                    render_full_blocked_tile(\n",
    "                        x * tile_size, y * tile_size, tile_size, img\n",
    "                    )\n",
    "                    continue\n",
    "                # Draw goal states\n",
    "                if (x, y) in self.goal_states:\n",
    "                    render_full_goal_tile(\n",
    "                        x * tile_size,\n",
    "                        y * tile_size,\n",
    "                        tile_size,\n",
    "                        img,\n",
    "                        reward=self.goal_states[(x, y)],\n",
    "                        rewardMax=reward_max,\n",
    "                        rewardMin=reward_min,\n",
    "                    )\n",
    "                    continue\n",
    "\n",
    "                # Draw the action value for action available in each cell\n",
    "                # Break the grid up into 4 sections, using triangles that meet\n",
    "                # in the middle. The base of the triangle points toward the\n",
    "                # direction of the action\n",
    "                render_action_q_value(\n",
    "                    tile_size,\n",
    "                    x,\n",
    "                    y,\n",
    "                    self.UP,\n",
    "                    q_values,\n",
    "                    img,\n",
    "                    show_text,\n",
    "                    v_text_offset=8,\n",
    "                    rewardMax=reward_max,\n",
    "                    rewardMin=reward_min,\n",
    "                )\n",
    "                render_action_q_value(\n",
    "                    tile_size,\n",
    "                    x,\n",
    "                    y,\n",
    "                    self.DOWN,\n",
    "                    q_values,\n",
    "                    img,\n",
    "                    show_text,\n",
    "                    v_text_offset=-8,\n",
    "                    rewardMax=reward_max,\n",
    "                    rewardMin=reward_min,\n",
    "                )\n",
    "                render_action_q_value(\n",
    "                    tile_size,\n",
    "                    x,\n",
    "                    y,\n",
    "                    self.LEFT,\n",
    "                    q_values,\n",
    "                    img,\n",
    "                    show_text,\n",
    "                    h_text_offset=-8,\n",
    "                    rewardMax=reward_max,\n",
    "                    rewardMin=reward_min,\n",
    "                )\n",
    "                render_action_q_value(\n",
    "                    tile_size,\n",
    "                    x,\n",
    "                    y,\n",
    "                    self.RIGHT,\n",
    "                    q_values,\n",
    "                    img,\n",
    "                    show_text,\n",
    "                    h_text_offset=8,\n",
    "                    rewardMax=reward_max,\n",
    "                    rewardMin=reward_min,\n",
    "                )\n",
    "\n",
    "        ax.imshow(img, origin=\"lower\", interpolation=\"bilinear\")\n",
    "        plt.title(title)\n",
    "        plt.axis(\"off\")\n",
    "        plt.show()\n",
    "\n",
    "    \"\"\" Visualise the policy of the agent with a matplotlib visual \"\"\"\n",
    "\n",
    "    def visualise_policy_as_image(self, policy, title=\"\", grid_size=1.0, gif=False):\n",
    "        # Map from action names to prettier arrows\n",
    "        arrow_map = {self.UP:'\\u2191',\n",
    "                     self.DOWN:'\\u2193',\n",
    "                     self.LEFT:'\\u2190',\n",
    "                     self.RIGHT:'\\u2192',\n",
    "                    }\n",
    "        if not gif:\n",
    "            fig, ax, img = self.initialise_grid(grid_size=grid_size)\n",
    "        texts = []\n",
    "        for y in range(self.height):\n",
    "            for x in range(self.width):\n",
    "                if (x, y) not in self.blocked_states and (x, y) not in self.goal_states:\n",
    "                    if policy.select_action((x, y), self.get_actions((x, y))) != self.TERMINATE:\n",
    "                        action = arrow_map[policy.select_action((x, y), self.get_actions((x, y)))]\n",
    "                        fontsize = \"xx-large\"\n",
    "                    texts.append(plt.text(\n",
    "                                x,\n",
    "                                y,\n",
    "                                action,\n",
    "                                fontsize=fontsize,\n",
    "                                horizontalalignment=\"center\",\n",
    "                                verticalalignment=\"center\",\n",
    "                            ))\n",
    "                elif (x, y) in self.goal_states:\n",
    "                    # gif player handles goal state rendering\n",
    "                    if not gif:\n",
    "                        plt.text(\n",
    "                            x,\n",
    "                            y,\n",
    "                            f\"{self.get_goal_states()[(x, y)]:+0.2f}\",\n",
    "                            fontsize=\"x-large\",\n",
    "                            horizontalalignment=\"center\",\n",
    "                            verticalalignment=\"center\",\n",
    "                        )\n",
    "        if gif:\n",
    "            return texts\n",
    "        ax.imshow(img, origin=\"lower\")\n",
    "        plt.title(title)\n",
    "        plt.show()\n",
    "\n",
    "    def execute(self, state, action):\n",
    "        if state in self.goal_states:\n",
    "            self.rewards += [self.episode_rewards]\n",
    "            self.cumulative_rewards += [sum(self.episode_rewards)]\n",
    "            return MDP.execute(self, state=state, action=self.TERMINATE)\n",
    "        return super().execute(state, action)\n",
    "\n",
    "    def visualise_stochastic_policy_as_image(self, policy, title=\"\", grid_size=1.0, gif=False):\n",
    "        if not gif:\n",
    "            fig, ax, img = self.initialise_grid(grid_size=grid_size)\n",
    "        texts = []\n",
    "\n",
    "        # Render the grid\n",
    "        for y in range(0, self.height):\n",
    "            for x in range(0, self.width):\n",
    "                prob_up = 0.0\n",
    "                prob_down = 0.0\n",
    "                prob_left = policy.get_probability((x, y), self.LEFT)\n",
    "                prob_right = policy.get_probability((x, y), self.RIGHT)\n",
    "                if self.height > 1:\n",
    "                    prob_up = policy.get_probability((x, y), self.UP)\n",
    "                    prob_down = policy.get_probability((x, y), self.DOWN)\n",
    "                # Normalise to account for the 'terminate' action that is not visualised\n",
    "                total = prob_left + prob_right + prob_down + prob_up\n",
    "                if total != 0:\n",
    "                    prob_left = prob_left / total\n",
    "                    prob_right = prob_right / total\n",
    "                    prob_down = prob_down / total\n",
    "                    prob_up = prob_up / total\n",
    "                if (x, y) in self.goal_states:\n",
    "                    # gif player handles goal state rendering\n",
    "                    if not gif:\n",
    "                        plt.text(\n",
    "                            x,\n",
    "                            y,\n",
    "                            f\"{self.get_goal_states()[(x, y)]:+0.2f}\",\n",
    "                            fontsize=\"x-large\",\n",
    "                            horizontalalignment=\"center\",\n",
    "                            verticalalignment=\"center\",\n",
    "                        )\n",
    "                elif (x, y) not in self.blocked_states:\n",
    "                    left_triangle = '\\u25C4'\n",
    "                    up_triangle = '\\u25B2'\n",
    "                    right_triangle = '\\u25BA'\n",
    "                    down_triangle = '\\u25BC'\n",
    "                    if self.height > 1:\n",
    "                        texts.append(plt.text(\n",
    "                            x,\n",
    "                            y,\n",
    "                            f\"{prob_up:0.2f}\\n{up_triangle}\\n{prob_left:0.2f}{left_triangle} {right_triangle}{prob_right:0.2f}\\n{down_triangle}\\n{prob_down:0.2f}\",\n",
    "                            fontsize=\"medium\",\n",
    "                            horizontalalignment=\"center\",\n",
    "                            verticalalignment=\"center\",\n",
    "                        ))\n",
    "                    else:\n",
    "                        texts.append(plt.text(\n",
    "                            x,\n",
    "                            y,\n",
    "                            f\"{prob_left:0.2f}{left_triangle} {right_triangle}{prob_right:0.2f}\",\n",
    "                            fontsize=\"medium\",\n",
    "                            horizontalalignment=\"center\",\n",
    "                            verticalalignment=\"center\",\n",
    "                        ))\n",
    "        if gif:\n",
    "            return texts\n",
    "        ax.imshow(img, origin=\"lower\")\n",
    "        plt.title(title)\n",
    "        plt.show()\n",
    "        return fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiArmedBandit():\n",
    "\n",
    "    \"\"\" Select an action for this state given from a list given a Q-function \"\"\"\n",
    "\n",
    "    def select(self, state, actions, qfunction):\n",
    "        pass\n",
    "\n",
    "    \"\"\" Reset a multi-armed bandit to its initial configuration \"\"\"\n",
    "\n",
    "    def reset(self):\n",
    "        self.__init__()\n",
    "\n",
    "\n",
    "class UpperConfidenceBounds(MultiArmedBandit):\n",
    "    def __init__(self):\n",
    "        self.total = 0\n",
    "        # number of times each action has been chosen\n",
    "        self.times_selected = {}\n",
    "\n",
    "    def select(self, state, actions, qfunction):\n",
    "\n",
    "        # First execute each action one time\n",
    "        for action in actions:\n",
    "            if action not in self.times_selected.keys():\n",
    "                self.times_selected[action] = 1\n",
    "                self.total += 1\n",
    "                return action\n",
    "\n",
    "        max_actions = []\n",
    "        max_value = float(\"-inf\")\n",
    "        for action in actions:\n",
    "            value = qfunction.get_q_value(state, action) + math.sqrt(\n",
    "                (2 * math.log(self.total)) / self.times_selected[action]\n",
    "            )\n",
    "            if value > max_value:\n",
    "                max_actions = [action]\n",
    "                max_value = value\n",
    "            elif value == max_value:\n",
    "                max_actions += [action]\n",
    "\n",
    "        # if there are multiple actions with the highest value\n",
    "        # choose one randomly\n",
    "        result = random.choice(max_actions)\n",
    "        self.times_selected[result] = self.times_selected[result] + 1\n",
    "        self.total += 1\n",
    "        return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class QFunction:\n",
    "\n",
    "    \"\"\" Update the Q-value of (state, action) by delta \"\"\"\n",
    "\n",
    "    def update(self, state, action, delta):\n",
    "        pass\n",
    "\n",
    "    \"\"\" Get a Q value for a given state-action pair \"\"\"\n",
    "\n",
    "    def get_q_value(self, state, action):\n",
    "        pass\n",
    "\n",
    "    \"\"\" Save a policy to a specified filename \"\"\"\n",
    "    def save_policy(self, filename):\n",
    "        pass\n",
    "\n",
    "    \"\"\" Load a policy from a specified filename \"\"\"\n",
    "    def load_policy(self, filename):\n",
    "        pass\n",
    "\n",
    "    \"\"\" Return the action with the maximum Q-value \"\"\"\n",
    "    def get_argmax_q(self, state, actions):\n",
    "        (argmax_q, max_q) = self.get_max_pair(state, actions)\n",
    "        return argmax_q\n",
    "\n",
    "    \"\"\" Return the maximum Q-value in this Q-function \"\"\"\n",
    "    def get_max_q(self, state, actions):\n",
    "        (argmax_q, max_q) = self.get_max_pair(state, actions)\n",
    "        return max_q\n",
    "\n",
    "    \"\"\" Return a pair containing the action and Q-value, where the\n",
    "        action has the maximum Q-value in state\n",
    "    \"\"\"\n",
    "    def get_max_pair(self, state, actions):\n",
    "        arg_max_q = None\n",
    "        max_q = float(\"-inf\")\n",
    "        for action in actions:\n",
    "            value = self.get_q_value(state, action)\n",
    "            if max_q < value:\n",
    "                arg_max_q = action\n",
    "                max_q = value\n",
    "        return (arg_max_q, max_q)\n",
    "\n",
    "\n",
    "class QTable(QFunction):\n",
    "    def __init__(self, alpha=0.1, default_q_value=0.0):\n",
    "        self.qtable = defaultdict(lambda: default_q_value)\n",
    "        self.alpha = alpha\n",
    "\n",
    "    def update(self, state, action, delta):\n",
    "        self.qtable[(state, action)] = self.qtable[(state, action)] + self.alpha * delta\n",
    "\n",
    "    def get_q_value(self, state, action):\n",
    "        return self.qtable[(state, action)]\n",
    "\n",
    "    def save(self, filename):\n",
    "        with open(filename, \"w\") as file:\n",
    "            serialised = {str(key): value for key, value in self.qtable.items()}\n",
    "            json.dump(serialised, file)\n",
    "\n",
    "    def load(self, filename, default=0.0):\n",
    "        with open(filename, \"r\") as file:\n",
    "            serialised = json.load(file)\n",
    "            self.qtable = defaultdict(\n",
    "                lambda: default,\n",
    "                {tuple(eval(key)): value for key, value in serialised.items()},\n",
    "            )\n",
    "\n",
    "\n",
    "class Policy:\n",
    "    def select_action(self, state, action):\n",
    "        pass\n",
    "\n",
    "\n",
    "class DeterministicPolicy(Policy):\n",
    "    def update(self, state, action):\n",
    "        pass                        \n",
    "\n",
    "\n",
    "class QPolicy(DeterministicPolicy):\n",
    "    def __init__(self, qfunction):\n",
    "        self.qfunction = qfunction\n",
    "\n",
    "    def select_action(self, state, actions):\n",
    "        return self.qfunction.get_argmax_q(state, actions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "gridworld = GridWorld()\n",
    "qfunction = QTable()\n",
    "root_node = SingleAgentMCTS(gridworld, qfunction, UpperConfidenceBounds()).mcts(timeout=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 600x450 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "gridworld.visualise_q_function(qfunction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYAAAAElCAYAAADtFjXiAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjguMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8g+/7EAAAACXBIWXMAAA9hAAAPYQGoP6dpAAATF0lEQVR4nO3cf2zU933H8dfd92zD+ezDoybB2BAOsGlSSEsIDpoS7JHJy7pMyrZMqRZpmpI2/Kiartr2T7N/qnZTxh9V1Uix3WUqabJuqtalmWmapAzyQ7XJGtogQsEgajC2AQO272zjH/e97/4AX3BtjH/d9/C9nw8JKdx9v8fn3rm75/d7Z1/A8zxPAABzgtleAAAgOwgAABhFAADAKAIAAEYRAAAwigAAgFEEAACMIgAAYFRoOhulUil1dnaqqKhIgUAg02sCAMyS53lKJBIqKytTMDj1Mf60AtDZ2amKiop5WRwAIPPa29tVXl4+5TbTCkBRUZEkqa2tTSUlJXNfGW7KdV2dOHFCVVVVchwn28vJaczaP2Oz/u6x72o0NZrt5eS00aujeu0rr6Vft6cyrQCMve1TXFys4uLiua0OU3JdV5FIRMXFxbwoZRiz9s/YrPPD+VIq26uxYTpv1/MhMAAYRQAAwCgCAABGEQAAMIoAAIBRBAAAjCIAAGAUAQAAowgAABhFAADAKAIAAEYRAAAwigAAgFEEAACMIgAAYBQBAACjCAAAGEUAAMAoAgAARhEAADCKAACAUQQAAIwiAABgFAEAAKMIAAAYRQAAwCgCAABGEQAAMIoAAIBRBAAAjCIAAGAUAQAAowgAABhFAADAqFC2FwAAfkglU2r9eat6z/TqStsVxTviSrkpbXl6i9bWrp3VbXa3duvoa0d1+dRluSOuiu4sUmxbTJV1lQoGJz++7jjcod/89DfqaeuRl/IULY9q3cPrFHsoNpe7NysEAIAJyeGkDv/gsCRpUXSRFi1ZpMHLg7O+vXO/PKf3vvOenDxHKx9YqYJIgToOd+jwK4fV3dqtB599cMI+J946oQ/3fqiCSIHu+v27FAwF1f5Bu1oaWtTb3qtNf7Vp1uuZDXMBcF1XjuNkexkmMGv/WJ716XdOq6WxRdu/vl133H3HTbdzChzV/H2NSlaVaHHJYh35ryM6+uOjs/o3RwdHdeilQwoEA9r+3HYtjS2VJG38i43a/0/71f5Bu9qa23TX1rvS+/R39+tX//4r5UfyVffNOkVKI5KkDX+2QT/7x5/p+E+Pq2JLhUrXlc5qTbNh6jOA119/XRs3blRHR0e2l5LzmLV/mPX0OCFHZZ8t0+KSxXO+rbMfnNVwfFirtq5Kv/hLkpPvaOPjGyVJp35+atw+p985rdRoSpV/WJl+8Zek/MJ83fOn91zbZ//4fTLNTAA8z9OePXt07Ngx1dTU8GTJIGbtH2adHReOXZAkLd+4fMJ1y9Yvk1PgqPtkt9xR95N9Pr6+z70T9ym7t2zcNn4xE4BAIKCmpibdf//9OnXqlGpra9XZ2ZntZeUkZu0fZp0d8a64JKl4efGE64JOUJHSiDzXU//F/on73Dlxn8UlixUqCGnwyqCSw8kMrXoiMwGQpGg0qrfeekubN2/WyZMnebJkELP2D7P23+jgqCQpb3HepNePXT4yODJxn/BN9rl++dh2fljQHwI/9dRT2rt374z38zxPktTa2qpHHnlEH3300XwvLecwa/8w65v7ybM/0cClgUmv2/+t/RMuW/3gam3dsTXTy1qwFnQAXNeV67q33nAKqVRqnlaT25i1f5j1zVX9UdW4o2pJ6j3Tq3MfntPqB1ersLRw3HUlq0oyso700frVyY/Wxy7PD+eP22c4MazRwVEVFBVM3OcWZwiZsKDfAvr+978vz/Nm9Kevr0/V1dWSpDVr1uiNN97I8r1YGJi1f5j1za1/ZL02/vnGcX/K7yuXJMUeik24rmJzRUbWMfbe/9j7+jdKuSn1d/cr4AQUWRaZuM/5iftc7bmq5HBS4d8LK1Tg33H5gg7ATMXjcdXV1enQoUNas2aNDh48qPLy8mwvKycxa/8wa/+N/b5B15GuCdddPH5R7rCr0nWlcvI++d2MO+65vs9HE/fp/Khz3DZ+MRMAz/P06KOPqqWlRbFYTAcOHOBJkiHM2j/MOrNGBkfU19mnqz1Xx12+cstKFRQV6EzzGV0+fTl9uTvi6siPjkiS1j48/uslYg/FFMwLqvXtVvV3f/LTQSMDI/r49Y+v7bN9dl9JMVsL+jOAmQgEAvrqV7+qCxcu6O2331ZFRWZODcGs/cSsZ+bj1z9WvPPaWzA9Z3okXfsFre4T3ZKk0qrScd8LdO7/zqmlsWXCh8l54TxteXqL3v/O+9r/zf1atXWV8gvz1XG4Q/GuuCq2VGjVA6vG/duRZRF97guf04cvf6g3n3tTKx9Ymf4qiMErg1r/x+t9/S1gyVAAJOmxxx7To48+qlDI1N3OCmbtH2Y9fV1HunTxNxfHXXbp5CVdOnkp/ffpfjFcxeYKPfzcwzr6k6M6+8FZpUZTitwR0aYnN6myrlKBQGDCPlV1VSosLdTxfcf12/d/K8/zFF0R1cbHN/JlcH7gSeIfZu0fy7OObYsptm16L54PP/fwvN52aVWpav+hdka3Wb6pXOWbbo+36cx8BgAAGI8AAIBRBAAAjCIAAGAUAQAAowgAABhFAADAKAIAAEYRAAAwigAAgFEEAACMIgAAYBQBAACjCAAAGEUAAMAoAgAARhEAADCKAACAUQQAAIwiAABgFAEAAKMIAAAYRQAAwCgCAABGEQAAMIoAAIBRBAAAjCIAAGAUAQAAowgAABhFAADAKAIAAEYRAAAwigAAgFEEAACMIgAAYBQBAACjCAAAGBWaycau68p13UytBVJ6vsw585i1f8ZmnB/Mz/JKDJjBYX3A8zzvVhvF43FFo1E1NzcrEonMZWkAgAzq7+/X1q1b1dfXp+Li4im3ndEZwNq1a1VSUjKnxWFqruuqtbVVhw4d4sg0wxzHUXV1tSorK+U4TraXk9PGHtcDzz4rDQ1lezk5bTCZnPa2MwqA4zg8UXzC223+4XHto6EhApBpM3jd4ENgADCKAACAUQQAAIwiAABgFAEAAKMIAAAYRQAAwCgCAABGEQAAMIoAAIBRBAAAjCIAAGAUAQAAowgAABhFAADAKAIAAEYRAAAwigAAgFEEAACMIgAAYBQBAACjCAAAGEUAAMAoAgAARhEAADCKAACAUQQAAIwiAABgFAEAAKMIAAAYRQAAwCgCAABG5WwAPM/Tnj179Pzzz8vzvGwvB5gXPK4xn0LZXkAmeJ6nXbt2qb6+XpJ0+vRp1dfXKxAIZHllwOzxuMZ8y7kAeJ6nnTt3qqGhIX1ZY2OjAoGAXnzxRZ4sWJB4XM/OxwMDeqe3V61Xr6p1cFBXkkmV5uXpfzZsmNXtDaVS+sH583q7p0fnR0ZU6DjaFIno6eXLtXrx4kn36Usm9W9dXXqnr0+XR0cVDYX0QHGxvrR8uZbl58/l7s1ZTr0F5HmeduzYoYaGBoXD4fSTorCwUA0NDdq1axenzVhweFzP3ltXrujlCxf0y0RCS/Py5nRbI6mUvnLypF46f16FjqO/XLZM9xcV6WBvr/7mxAkdHRiYsE9fMqkvnjih/+zuVnlBgZ5Ytkx3h8NqunxZf338uDqGh+e0prnKmQB4nqdnnnlGjY2NCofDampqUjB47e41NTUpHA6rvr5eu3fv5smCBYPH9dx8fulS7V2/XgfuvVc/+PSn53RbP7x4UUcGBvQHS5bopaoqfXnFCn1j9Wr9cyymoVRK3zpzRqnf+X/wYmenzg4P6wvLlumFdeu0e8UK/cuaNfrb8nL1JJPa094+pzXNVc4EIJVKKR6Pq7CwUPv27VNtbW36upqamvSTJR6P80TBgsHjem4qw2FVhcPKC87tpc7zPP33pUuSpC+vWKHgDW+5PbRkiT4biei3Q0P6VX9/+vJB19Ubly9rcTCop5cvH3d7j5eW6s78fLXE41k9C8iZzwAcx9Grr76qY8eOacMk7+/V1taqpaVFd999d/oICrjd8bi+PZwbHtb5kRGtLChQWUHBhOu3Fhfr1/39+mUiofuKiiRJRwcGNOx5qo5EVOg447YPBgJ6oLhYr126pA8TCa2Y5Db9kDMBkK49WSZ7koyZ6jrgdsXjOvvOXj9Kr7jJC/XY5WeHhibus2jR1Ptk8QyAQwYAuIV+15UkRX7nSH7M2BH+2Haz3cdvOXUGAMCW73V2Trjs80uXTvo2DSYiAAAWrJfOn59w2aaionkPQOQWR+sDkxztz2YfvxEAAAtWy6ZNvvw7K68Hpf0m79ePXb7yhvf70/vc8LnApPtk8WyFzwAA4BbKCwp0Z36+zg4Pq3OSCDTH45Kkzdd/AkiSPlNYqIJAQEcGBtJH+2NSnqdD1/e574Z9/EYAAOAG54aH1TY0pOQNv1cRCAT02Kc+JUl6oaNj3C98vdvbq1/392v1okX6XCSSvjzsOHpk6VJdTaX0r11d4/6NH3V3q2tkRA8UF2ftR0Al3gICkMPahob08u98TpBwXX2jrS3996+Ul2tJ6JOXwi+fPKnzIyP68T33jPss4QvLlun9vj79b2+vnjpxQpuLinRhZET7e3q0KBjU11etGvcLYpK0s6xMhxMJ/fDiRZ28elV3h8NqGxrSu319KgmF9HcVFZm549NEAADkrMujo/rplSvjLhtKpcZd9vTy5eMCcDP5waC+u26dXj5/Xm/19Og/Ll5UoeNo25Il+uJNvgwuGgrpe1VVeqmrS+/29enX/f2KOo7+ZOnS2+LL4AgAgJx1X1HRjD8ofu0zn7npdYuCQX2prExfKiub9u1FQyF9raJCX8vy0f5k+AwAAIzK6TOAZDKZ7SUA847HNeYLZwAAYBQBAACjCAAAGEUAAMAoAgAARhEAADCKAACAUQQAAIwiAABgFAEAAKMIAAAYRQAAwCgCAABGEQAAMIoAAIBRBAAAjCIAAGAUAQAAowgAABhFAADAKAIAAEYRAAAwigAAgFEEAACMIgAAYBQBAACjCAAAGEUAAMAoAgAARhEAADCKAACAUQQAAIwiAABgFAEAAKMIAAAYRQAAwKjQTDZ2XVeu62ZqLZDS83UcJ8sryX1jM+YxnXnpGS9alN2FWJBMTnvTgOd53q02isfjikajam5uViQSmdPaAACZ09/fr61bt6qvr0/FxcVTbjujM4C1a9eqpKRkTovD1FzXVWtrqyorKzkLyDBm7R9m7Z94PD7tbWcUAMdx+J/nE2btH2btH2adeTOZLx8CA4BRBAAAjCIAAGAUAQAAowgAABhFAADAKAIAAEYRAAAwigAAgFEEAACMIgAAYBQBAACjCAAAGEUAAMAoAgAARhEAADCKAACAUQQAAIwiAABgFAEAAKMIAAAYRQAAwCgCAABGEQAAMIoAAIBRBAAAjCIAAGAUAQAAowgAABhFAADAKAIAAEblbAA8z9OePXv0/PPPy/O8bC8HAG47oWwvIBM8z9OuXbtUX18vSTp9+rTq6+sVCASyvDIAuH3k3BmA53nauXNn+sVfkhobG7Vz507OBADgBjkVAM/ztGPHDjU0NCgcDqeP+AsLC9XQ0KBdu3YRAQC4LmcC4HmennnmGTU2NiocDqupqUnB4LW719TUpHA4rPr6eu3evZsIAIByKACpVErxeFyFhYXat2+famtr09fV1NSkIxCPxwnAPEgmk9leghnM2j/WZp0zAXAcR6+++qqam5tVU1Mz4fra2lq1tLRo79696TMDzE4ikdC2bdv0wgsvZHspOY9Z+8firHPqldBxHG3YsOGm12/YsEGO4/i4otyTSCRUV1enX/ziF/r2t7+twcHBbC8pZzFr/1iddU4FAJk19iRpbm5WLBbTgQMHFA6Hs72snMSs/WN51gQA0zLZk2TlypXZXlZOYtb+sT5rAoBpefLJJ9Xc3CxJamtrUywWUygUmtGf7du3Z/leLAzM2j/WZ52TvwmM+ZdKpSb975lwXXe+lpPTmLV/rM+aMwBMyyuvvKLq6mpJ0tq1a9Xe3i7P82b05+DBg9m9EwsEs/aP9VkTAExLNBrVm2++qerqap06dUq1tbU6d+5ctpeVk5i1f6zPmgBg2iZ7slj5cTm/MWv/WJ41nwFgRsaeLHV1dXriiSfM/LhcNjBr/1idNQHAjEWjUb333nvKy8vL9lJyHrP2j8VZ8xYQZsXSkyTbmLV/rM06p88ArH2xEwDMBGcAAGAUAQAAowgAABhFAADAKAIAAEYRAAAwigAAgFEEAACMIgAAYBQBAACjCAAAGEUAAMAoAgAARhEAADCKAACAUQQAAIwiAABgFAEAAKMIAAAYRQAAwCgCAABGEQAAMIoAAIBRBAAAjCIAAGAUAQAAowgAABhFAADAKAIAAEYRAAAwigAAgFEEAACMIgAAYBQBAACjCAAAGEUAAMAoAgAARoWms5HneZKk3t7eTK4FklzXVX9/v3p6euQ4TraXk9OYtX+YtX/i8bikT163pzKtACQSCUlSLBabw7IAAH5JJBKKRqNTbhPwppGJVCqlzs5OFRUVKRAIzNsCAQDzy/M8JRIJlZWVKRic+l3+aQUAAJB7+BAYAIwiAABgFAEAAKMIAAAYRQAAwCgCAABGEQAAMOr/ASNszWkMII1+AAAAAElFTkSuQmCC",
      "text/plain": [
       "<Figure size 400x300 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "policy = QPolicy(qfunction)\n",
    "gridworld.visualise_policy(policy)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rl",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
