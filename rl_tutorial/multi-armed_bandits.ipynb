{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import random\n",
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multi-armed Bandit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiArmedBandit():\n",
    "\n",
    "    \"\"\" Select an action for this state given from a list given a Q-function \"\"\"\n",
    "\n",
    "    def select(self, state, actions, qfunction):\n",
    "        pass\n",
    "\n",
    "    \"\"\" Reset a multi-armed bandit to its initial configuration \"\"\"\n",
    "\n",
    "    def reset(self):\n",
    "        self.__init__()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Simulation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To demonstrate the effect of different multi-armed bandit strategies and their parameters, we use the following simple simulation. The simulation is an implementation of a simple multi-armed bandit problem with five actions, ```actions = [0, 1, 2, 3, 4]```.  Each action has a probability associated with it: ```probabilities = [0.1, 0.3, 0.7, 0.2, 0.1]```. The simulation runs  2000 episodes of a bandit problem, with each episode being 1000 steps long. At each step, the agent must chose an action. For the action `a` it chooses,  it receives a reward of 5 with a probability `probability[a]`.  With a probability of ```1 - probability[a]``` it receives a reward of 0. At the beginning of each episode, the bandit strategies are reset.\n",
    "\n",
    "The simulation returns a list of lists, representing the reward received at each step of each episode. The aim for the bandit is to maximise the expected rewards over each episode."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class QFunction:\n",
    "\n",
    "    \"\"\" Update the Q-value of (state, action) by delta \"\"\"\n",
    "\n",
    "    def update(self, state, action, delta):\n",
    "        pass\n",
    "\n",
    "    \"\"\" Get a Q value for a given state-action pair \"\"\"\n",
    "\n",
    "    def get_q_value(self, state, action):\n",
    "        pass\n",
    "\n",
    "    \"\"\" Save a policy to a specified filename \"\"\"\n",
    "    def save_policy(self, filename):\n",
    "        pass\n",
    "\n",
    "    \"\"\" Load a policy from a specified filename \"\"\"\n",
    "    def load_policy(self, filename):\n",
    "        pass\n",
    "\n",
    "    \"\"\" Return the action with the maximum Q-value \"\"\"\n",
    "    def get_argmax_q(self, state, actions):\n",
    "        (argmax_q, max_q) = self.get_max_pair(state, actions)\n",
    "        return argmax_q\n",
    "\n",
    "    \"\"\" Return the maximum Q-value in this Q-function \"\"\"\n",
    "    def get_max_q(self, state, actions):\n",
    "        (argmax_q, max_q) = self.get_max_pair(state, actions)\n",
    "        return max_q\n",
    "\n",
    "    \"\"\" Return a pair containing the action and Q-value, where the\n",
    "        action has the maximum Q-value in state\n",
    "    \"\"\"\n",
    "    def get_max_pair(self, state, actions):\n",
    "        arg_max_q = None\n",
    "        max_q = float(\"-inf\")\n",
    "        for action in actions:\n",
    "            value = self.get_q_value(state, action)\n",
    "            if max_q < value:\n",
    "                arg_max_q = action\n",
    "                max_q = value\n",
    "        return (arg_max_q, max_q)\n",
    "\n",
    "\n",
    "class QTable(QFunction):\n",
    "    def __init__(self, alpha=0.1, default_q_value=0.0):\n",
    "        self.qtable = defaultdict(lambda: default_q_value)\n",
    "        self.alpha = alpha\n",
    "\n",
    "    def update(self, state, action, delta):\n",
    "        self.qtable[(state, action)] = self.qtable[(state, action)] + self.alpha * delta\n",
    "\n",
    "    def get_q_value(self, state, action):\n",
    "        return self.qtable[(state, action)]\n",
    "\n",
    "    def save(self, filename):\n",
    "        with open(filename, \"w\") as file:\n",
    "            serialised = {str(key): value for key, value in self.qtable.items()}\n",
    "            json.dump(serialised, file)\n",
    "\n",
    "    def load(self, filename, default=0.0):\n",
    "        with open(filename, \"r\") as file:\n",
    "            serialised = json.load(file)\n",
    "            self.qtable = defaultdict(\n",
    "                lambda: default,\n",
    "                {tuple(eval(key)): value for key, value in serialised.items()},\n",
    "            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\"\"\" Run a bandit algorithm for a number of episodes, with each episode\n",
    "being a set length.\n",
    "\"\"\"\n",
    "\n",
    "def run_bandit(bandit, episodes=200, episode_length=500, drift=True):\n",
    "\n",
    "    # The actions available\n",
    "    actions = [0, 1, 2, 3, 4]\n",
    "\n",
    "    # A dummy state\n",
    "    state = 1\n",
    "\n",
    "    rewards = []\n",
    "    for _ in range(0, episodes):\n",
    "        bandit.reset()\n",
    "\n",
    "        # The probability of receiving a payoff of 1 for each action\n",
    "        probabilities = [0.1, 0.3, 0.7, 0.2, 0.1]\n",
    "\n",
    "        # The number of times each arm has been selected\n",
    "        times_selected = defaultdict(lambda: 0)\n",
    "        qtable = QTable()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rl",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
